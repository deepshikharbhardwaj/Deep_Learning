{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gradient_Descent.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Gradient Descent"
      ],
      "metadata": {
        "id": "VIjeQkkZ6OoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "qfPiYwkr6Qpv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/codebasics/deep-learning-keras-tf-tutorial/3d99d9abbb654a02b1e747bee2c029e5c0712356/7_nn_from_scratch/insurance_data.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "w9CfHYuu6ciT",
        "outputId": "3232ef04-a019-4e7d-8f2f-10c7117c8729"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d6e40a9b-9607-4892-8dca-ccb5f8e4e560\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>affordibility</th>\n",
              "      <th>bought_insurance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>52</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>46</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6e40a9b-9607-4892-8dca-ccb5f8e4e560')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d6e40a9b-9607-4892-8dca-ccb5f8e4e560 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d6e40a9b-9607-4892-8dca-ccb5f8e4e560');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   age  affordibility  bought_insurance\n",
              "0   22              1                 0\n",
              "1   25              0                 0\n",
              "2   47              1                 1\n",
              "3   52              0                 0\n",
              "4   46              1                 1"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[['age','affordibility']], df.bought_insurance, test_size = 0.2, random_state = 27)"
      ],
      "metadata": {
        "id": "jkjs2Kw_7yf7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvEKDA5W8_tg",
        "outputId": "96672aea-b443-434c-9247-58758935b10a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled = X_train.copy()\n",
        "X_train_scaled['age'] = X_train_scaled['age']/100\n",
        "\n",
        "X_test_scaled = X_test.copy()\n",
        "X_test_scaled['age'] = X_test_scaled['age']/100"
      ],
      "metadata": {
        "id": "tPTSCY9C9HSj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "id": "GsAiPlYx9a_H",
        "outputId": "7a1516ca-07a8-40d8-cd41-3dc4a1838eec"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-dd8f48ca-59da-468a-b38d-8d6149309dae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>affordibility</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.26</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.55</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.40</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.22</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.28</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.52</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.55</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.46</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.21</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.19</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.49</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.25</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.18</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.47</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.58</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.56</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.25</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.23</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.62</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.18</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd8f48ca-59da-468a-b38d-8d6149309dae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dd8f48ca-59da-468a-b38d-8d6149309dae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dd8f48ca-59da-468a-b38d-8d6149309dae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     age  affordibility\n",
              "21  0.26              0\n",
              "15  0.55              1\n",
              "22  0.40              1\n",
              "0   0.22              1\n",
              "11  0.28              1\n",
              "3   0.52              0\n",
              "6   0.55              0\n",
              "4   0.46              1\n",
              "20  0.21              1\n",
              "18  0.19              0\n",
              "14  0.49              1\n",
              "1   0.25              0\n",
              "10  0.18              1\n",
              "2   0.47              1\n",
              "17  0.58              1\n",
              "13  0.29              0\n",
              "5   0.56              1\n",
              "16  0.25              0\n",
              "26  0.23              1\n",
              "8   0.62              1\n",
              "24  0.50              1\n",
              "19  0.18              1"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "                          keras.layers.Dense(1, input_shape = (2,), activation = 'sigmoid', kernel_initializer = 'ones', bias_initializer = 'zeros')\n",
        "])\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "model.fit(X_train_scaled, y_train, epochs = 1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpUXJn7_9kXd",
        "outputId": "74a95cdc-9d6d-4278-9fbe-0a2b4c6d7cda"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1/1 [==============================] - 0s 380ms/step - loss: 0.7507 - accuracy: 0.4545\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7503 - accuracy: 0.4545\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7498 - accuracy: 0.4545\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7493 - accuracy: 0.4545\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7488 - accuracy: 0.4545\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7484 - accuracy: 0.4545\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7479 - accuracy: 0.4545\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7474 - accuracy: 0.4545\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7470 - accuracy: 0.4545\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7465 - accuracy: 0.4545\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7461 - accuracy: 0.4545\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7456 - accuracy: 0.4545\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7451 - accuracy: 0.4545\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7447 - accuracy: 0.4545\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7442 - accuracy: 0.4545\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7437 - accuracy: 0.4545\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7433 - accuracy: 0.4545\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7428 - accuracy: 0.4545\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7424 - accuracy: 0.4545\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7419 - accuracy: 0.4545\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7415 - accuracy: 0.4545\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7410 - accuracy: 0.4545\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7406 - accuracy: 0.4545\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7401 - accuracy: 0.4545\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7397 - accuracy: 0.4545\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7392 - accuracy: 0.4545\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7388 - accuracy: 0.4545\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7383 - accuracy: 0.4545\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7379 - accuracy: 0.4545\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7374 - accuracy: 0.4545\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7370 - accuracy: 0.4545\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7365 - accuracy: 0.4545\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7361 - accuracy: 0.4545\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7357 - accuracy: 0.4545\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7352 - accuracy: 0.4545\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7348 - accuracy: 0.4545\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7343 - accuracy: 0.4545\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7339 - accuracy: 0.4545\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7335 - accuracy: 0.4545\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7330 - accuracy: 0.4545\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7326 - accuracy: 0.4545\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7322 - accuracy: 0.4545\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7317 - accuracy: 0.4545\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7313 - accuracy: 0.4545\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7309 - accuracy: 0.4545\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7305 - accuracy: 0.4545\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7300 - accuracy: 0.4545\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7296 - accuracy: 0.4545\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7292 - accuracy: 0.4545\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7288 - accuracy: 0.4545\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7283 - accuracy: 0.4545\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.7279 - accuracy: 0.4545\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7275 - accuracy: 0.4545\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7271 - accuracy: 0.4545\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7267 - accuracy: 0.4545\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7262 - accuracy: 0.4545\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7258 - accuracy: 0.4545\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7254 - accuracy: 0.4545\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7250 - accuracy: 0.4545\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7246 - accuracy: 0.4545\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7242 - accuracy: 0.4545\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7238 - accuracy: 0.4545\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7234 - accuracy: 0.4545\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7229 - accuracy: 0.4545\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7225 - accuracy: 0.4545\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7221 - accuracy: 0.4545\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7217 - accuracy: 0.4545\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7213 - accuracy: 0.4545\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7209 - accuracy: 0.4545\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7205 - accuracy: 0.4545\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7201 - accuracy: 0.4545\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7197 - accuracy: 0.4545\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7193 - accuracy: 0.4545\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7189 - accuracy: 0.4545\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7185 - accuracy: 0.4545\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7181 - accuracy: 0.4545\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7178 - accuracy: 0.4545\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7174 - accuracy: 0.4545\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7170 - accuracy: 0.4545\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7166 - accuracy: 0.4545\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7162 - accuracy: 0.4545\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7158 - accuracy: 0.4545\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7154 - accuracy: 0.4545\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7150 - accuracy: 0.4545\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7147 - accuracy: 0.4545\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7143 - accuracy: 0.4545\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7139 - accuracy: 0.4545\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7135 - accuracy: 0.4545\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7131 - accuracy: 0.4545\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7128 - accuracy: 0.4545\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7124 - accuracy: 0.4545\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7120 - accuracy: 0.4545\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7116 - accuracy: 0.4545\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7113 - accuracy: 0.4545\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7109 - accuracy: 0.4545\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7105 - accuracy: 0.4545\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7101 - accuracy: 0.4545\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7098 - accuracy: 0.4545\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7094 - accuracy: 0.4545\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7090 - accuracy: 0.4545\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7087 - accuracy: 0.4545\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7083 - accuracy: 0.4545\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7079 - accuracy: 0.4545\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7076 - accuracy: 0.4545\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7072 - accuracy: 0.4545\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7069 - accuracy: 0.4545\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7065 - accuracy: 0.4545\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7061 - accuracy: 0.4545\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7058 - accuracy: 0.4545\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7054 - accuracy: 0.4545\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7051 - accuracy: 0.4545\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7047 - accuracy: 0.4545\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7044 - accuracy: 0.4545\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7040 - accuracy: 0.4545\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7037 - accuracy: 0.4545\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7033 - accuracy: 0.4545\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7030 - accuracy: 0.4545\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7026 - accuracy: 0.4545\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7023 - accuracy: 0.4545\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7019 - accuracy: 0.4545\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7016 - accuracy: 0.4545\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7012 - accuracy: 0.4545\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7009 - accuracy: 0.4545\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7005 - accuracy: 0.4545\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7002 - accuracy: 0.4545\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6999 - accuracy: 0.4545\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6995 - accuracy: 0.4545\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6992 - accuracy: 0.4545\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6989 - accuracy: 0.4545\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6985 - accuracy: 0.4545\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6982 - accuracy: 0.4545\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6979 - accuracy: 0.4545\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6975 - accuracy: 0.4545\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6972 - accuracy: 0.4545\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6969 - accuracy: 0.4545\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6965 - accuracy: 0.4545\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6962 - accuracy: 0.4545\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6959 - accuracy: 0.4545\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6956 - accuracy: 0.4545\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6952 - accuracy: 0.4545\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6949 - accuracy: 0.4545\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6946 - accuracy: 0.4545\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6943 - accuracy: 0.4545\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6939 - accuracy: 0.4545\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.4545\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.4545\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.4545\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.4545\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6924 - accuracy: 0.4545\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6921 - accuracy: 0.4545\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6917 - accuracy: 0.4545\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6914 - accuracy: 0.4545\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6911 - accuracy: 0.4545\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6908 - accuracy: 0.4545\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6905 - accuracy: 0.4545\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6902 - accuracy: 0.4545\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6899 - accuracy: 0.4545\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6896 - accuracy: 0.4545\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.4545\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6890 - accuracy: 0.4545\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6887 - accuracy: 0.4545\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6884 - accuracy: 0.4545\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6881 - accuracy: 0.4545\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6878 - accuracy: 0.4545\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6875 - accuracy: 0.4545\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6872 - accuracy: 0.4545\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6869 - accuracy: 0.4545\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6866 - accuracy: 0.4545\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6863 - accuracy: 0.4545\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6860 - accuracy: 0.4545\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6857 - accuracy: 0.5000\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6854 - accuracy: 0.5000\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6851 - accuracy: 0.5000\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6848 - accuracy: 0.5000\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6845 - accuracy: 0.5000\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6843 - accuracy: 0.5000\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6840 - accuracy: 0.5000\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6837 - accuracy: 0.5000\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6834 - accuracy: 0.5000\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6831 - accuracy: 0.5000\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6828 - accuracy: 0.5000\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6826 - accuracy: 0.5000\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6823 - accuracy: 0.5000\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6820 - accuracy: 0.5000\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6817 - accuracy: 0.5000\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6814 - accuracy: 0.5000\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6812 - accuracy: 0.5000\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6809 - accuracy: 0.5000\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6806 - accuracy: 0.5000\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6803 - accuracy: 0.5000\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6801 - accuracy: 0.5000\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6798 - accuracy: 0.5000\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6795 - accuracy: 0.5000\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6793 - accuracy: 0.5000\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6790 - accuracy: 0.5000\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6787 - accuracy: 0.5000\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6784 - accuracy: 0.5000\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6782 - accuracy: 0.5000\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6779 - accuracy: 0.5000\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6777 - accuracy: 0.5000\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6774 - accuracy: 0.5000\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6771 - accuracy: 0.5000\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6769 - accuracy: 0.5000\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6766 - accuracy: 0.5000\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6763 - accuracy: 0.5000\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6761 - accuracy: 0.5000\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6758 - accuracy: 0.5000\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6756 - accuracy: 0.5000\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6753 - accuracy: 0.5000\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6751 - accuracy: 0.5000\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6748 - accuracy: 0.5000\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6746 - accuracy: 0.5000\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6743 - accuracy: 0.5000\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6741 - accuracy: 0.5000\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6738 - accuracy: 0.5000\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6736 - accuracy: 0.5000\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6733 - accuracy: 0.5000\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6731 - accuracy: 0.5000\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6728 - accuracy: 0.5000\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6726 - accuracy: 0.5000\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6723 - accuracy: 0.5000\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6721 - accuracy: 0.5000\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6718 - accuracy: 0.5000\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6716 - accuracy: 0.5000\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6714 - accuracy: 0.5000\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6711 - accuracy: 0.5000\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6709 - accuracy: 0.5455\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6706 - accuracy: 0.5455\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6704 - accuracy: 0.5455\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6702 - accuracy: 0.5455\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6699 - accuracy: 0.5455\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6697 - accuracy: 0.5455\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6695 - accuracy: 0.5455\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6692 - accuracy: 0.5455\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6690 - accuracy: 0.5455\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6688 - accuracy: 0.5455\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6685 - accuracy: 0.5455\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6683 - accuracy: 0.5455\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6681 - accuracy: 0.5455\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6679 - accuracy: 0.5455\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6676 - accuracy: 0.5455\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6674 - accuracy: 0.5455\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6672 - accuracy: 0.5455\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6670 - accuracy: 0.5455\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6667 - accuracy: 0.5455\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6665 - accuracy: 0.5455\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6663 - accuracy: 0.5455\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6661 - accuracy: 0.5455\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6658 - accuracy: 0.5455\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6656 - accuracy: 0.5455\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6654 - accuracy: 0.5909\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6652 - accuracy: 0.5909\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6650 - accuracy: 0.5909\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6648 - accuracy: 0.5909\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6645 - accuracy: 0.5909\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6643 - accuracy: 0.5909\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6641 - accuracy: 0.5909\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6639 - accuracy: 0.5909\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6637 - accuracy: 0.5909\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6635 - accuracy: 0.5909\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6633 - accuracy: 0.5909\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6631 - accuracy: 0.5909\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6629 - accuracy: 0.5909\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6626 - accuracy: 0.5909\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6624 - accuracy: 0.5909\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6622 - accuracy: 0.5909\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6620 - accuracy: 0.5909\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6618 - accuracy: 0.5909\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6616 - accuracy: 0.5909\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6614 - accuracy: 0.5909\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6612 - accuracy: 0.5909\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6610 - accuracy: 0.5909\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6608 - accuracy: 0.5909\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6606 - accuracy: 0.5909\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6604 - accuracy: 0.5909\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6602 - accuracy: 0.5909\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6600 - accuracy: 0.5909\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6598 - accuracy: 0.5909\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6596 - accuracy: 0.5909\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6594 - accuracy: 0.5909\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6592 - accuracy: 0.5909\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6590 - accuracy: 0.5909\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6589 - accuracy: 0.5909\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6587 - accuracy: 0.5909\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6585 - accuracy: 0.5909\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6583 - accuracy: 0.5909\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6581 - accuracy: 0.5909\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6579 - accuracy: 0.5909\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6577 - accuracy: 0.5909\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6575 - accuracy: 0.5909\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6573 - accuracy: 0.5909\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6572 - accuracy: 0.5909\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6570 - accuracy: 0.5909\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6568 - accuracy: 0.5909\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6566 - accuracy: 0.5909\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6564 - accuracy: 0.5909\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6562 - accuracy: 0.5909\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6561 - accuracy: 0.5909\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6559 - accuracy: 0.5909\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6557 - accuracy: 0.5909\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6555 - accuracy: 0.5909\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6553 - accuracy: 0.5909\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6552 - accuracy: 0.5909\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6550 - accuracy: 0.5909\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6548 - accuracy: 0.5909\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6546 - accuracy: 0.5909\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6545 - accuracy: 0.5909\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6543 - accuracy: 0.5909\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6541 - accuracy: 0.5909\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6539 - accuracy: 0.5909\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6538 - accuracy: 0.5909\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6536 - accuracy: 0.5909\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6534 - accuracy: 0.5909\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6533 - accuracy: 0.5909\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6531 - accuracy: 0.5909\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6529 - accuracy: 0.5909\n",
            "Epoch 317/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6528 - accuracy: 0.5909\n",
            "Epoch 318/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6526 - accuracy: 0.5909\n",
            "Epoch 319/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6524 - accuracy: 0.5909\n",
            "Epoch 320/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6523 - accuracy: 0.5909\n",
            "Epoch 321/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6521 - accuracy: 0.5909\n",
            "Epoch 322/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6519 - accuracy: 0.5909\n",
            "Epoch 323/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6518 - accuracy: 0.5909\n",
            "Epoch 324/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6516 - accuracy: 0.5909\n",
            "Epoch 325/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6514 - accuracy: 0.5909\n",
            "Epoch 326/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6513 - accuracy: 0.5909\n",
            "Epoch 327/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6511 - accuracy: 0.5909\n",
            "Epoch 328/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6510 - accuracy: 0.5909\n",
            "Epoch 329/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6508 - accuracy: 0.5909\n",
            "Epoch 330/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6506 - accuracy: 0.5909\n",
            "Epoch 331/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6505 - accuracy: 0.5909\n",
            "Epoch 332/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6503 - accuracy: 0.5909\n",
            "Epoch 333/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6502 - accuracy: 0.5909\n",
            "Epoch 334/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6500 - accuracy: 0.5909\n",
            "Epoch 335/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6499 - accuracy: 0.5909\n",
            "Epoch 336/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6497 - accuracy: 0.5909\n",
            "Epoch 337/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6495 - accuracy: 0.5909\n",
            "Epoch 338/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6494 - accuracy: 0.5909\n",
            "Epoch 339/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6492 - accuracy: 0.5909\n",
            "Epoch 340/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6491 - accuracy: 0.5909\n",
            "Epoch 341/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6489 - accuracy: 0.5909\n",
            "Epoch 342/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6488 - accuracy: 0.5909\n",
            "Epoch 343/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6486 - accuracy: 0.5909\n",
            "Epoch 344/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6485 - accuracy: 0.5909\n",
            "Epoch 345/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6483 - accuracy: 0.5909\n",
            "Epoch 346/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6482 - accuracy: 0.5909\n",
            "Epoch 347/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6480 - accuracy: 0.5909\n",
            "Epoch 348/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6479 - accuracy: 0.5909\n",
            "Epoch 349/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6477 - accuracy: 0.5909\n",
            "Epoch 350/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6476 - accuracy: 0.5909\n",
            "Epoch 351/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6475 - accuracy: 0.5909\n",
            "Epoch 352/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6473 - accuracy: 0.5909\n",
            "Epoch 353/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6472 - accuracy: 0.5909\n",
            "Epoch 354/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6470 - accuracy: 0.5909\n",
            "Epoch 355/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6469 - accuracy: 0.5909\n",
            "Epoch 356/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6467 - accuracy: 0.5909\n",
            "Epoch 357/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6466 - accuracy: 0.5909\n",
            "Epoch 358/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6464 - accuracy: 0.5909\n",
            "Epoch 359/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6463 - accuracy: 0.5909\n",
            "Epoch 360/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6462 - accuracy: 0.5909\n",
            "Epoch 361/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6460 - accuracy: 0.5909\n",
            "Epoch 362/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6459 - accuracy: 0.5909\n",
            "Epoch 363/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6457 - accuracy: 0.5909\n",
            "Epoch 364/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6456 - accuracy: 0.5909\n",
            "Epoch 365/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6455 - accuracy: 0.5909\n",
            "Epoch 366/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6453 - accuracy: 0.5909\n",
            "Epoch 367/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6452 - accuracy: 0.5909\n",
            "Epoch 368/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6451 - accuracy: 0.5909\n",
            "Epoch 369/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6449 - accuracy: 0.5909\n",
            "Epoch 370/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6448 - accuracy: 0.5909\n",
            "Epoch 371/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6447 - accuracy: 0.5909\n",
            "Epoch 372/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6445 - accuracy: 0.5909\n",
            "Epoch 373/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6444 - accuracy: 0.5909\n",
            "Epoch 374/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6443 - accuracy: 0.5909\n",
            "Epoch 375/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6441 - accuracy: 0.5909\n",
            "Epoch 376/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6440 - accuracy: 0.5909\n",
            "Epoch 377/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6439 - accuracy: 0.5909\n",
            "Epoch 378/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6437 - accuracy: 0.5909\n",
            "Epoch 379/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6436 - accuracy: 0.5909\n",
            "Epoch 380/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6435 - accuracy: 0.5909\n",
            "Epoch 381/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6433 - accuracy: 0.5909\n",
            "Epoch 382/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6432 - accuracy: 0.5909\n",
            "Epoch 383/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6431 - accuracy: 0.5909\n",
            "Epoch 384/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6430 - accuracy: 0.5909\n",
            "Epoch 385/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6428 - accuracy: 0.5909\n",
            "Epoch 386/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6427 - accuracy: 0.5909\n",
            "Epoch 387/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6426 - accuracy: 0.5909\n",
            "Epoch 388/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6425 - accuracy: 0.5909\n",
            "Epoch 389/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6423 - accuracy: 0.5909\n",
            "Epoch 390/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6422 - accuracy: 0.5909\n",
            "Epoch 391/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6421 - accuracy: 0.5909\n",
            "Epoch 392/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6420 - accuracy: 0.5909\n",
            "Epoch 393/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6418 - accuracy: 0.5909\n",
            "Epoch 394/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6417 - accuracy: 0.5909\n",
            "Epoch 395/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6416 - accuracy: 0.5909\n",
            "Epoch 396/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6415 - accuracy: 0.5909\n",
            "Epoch 397/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6414 - accuracy: 0.5909\n",
            "Epoch 398/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6412 - accuracy: 0.5909\n",
            "Epoch 399/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6411 - accuracy: 0.5909\n",
            "Epoch 400/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6410 - accuracy: 0.5909\n",
            "Epoch 401/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6409 - accuracy: 0.5909\n",
            "Epoch 402/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6408 - accuracy: 0.5909\n",
            "Epoch 403/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6406 - accuracy: 0.5909\n",
            "Epoch 404/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6405 - accuracy: 0.5909\n",
            "Epoch 405/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6404 - accuracy: 0.5909\n",
            "Epoch 406/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6403 - accuracy: 0.5909\n",
            "Epoch 407/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6402 - accuracy: 0.5909\n",
            "Epoch 408/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6401 - accuracy: 0.5909\n",
            "Epoch 409/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6399 - accuracy: 0.5909\n",
            "Epoch 410/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6398 - accuracy: 0.5909\n",
            "Epoch 411/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6397 - accuracy: 0.5909\n",
            "Epoch 412/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6396 - accuracy: 0.5909\n",
            "Epoch 413/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6395 - accuracy: 0.5909\n",
            "Epoch 414/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6394 - accuracy: 0.5909\n",
            "Epoch 415/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6393 - accuracy: 0.5909\n",
            "Epoch 416/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6392 - accuracy: 0.5909\n",
            "Epoch 417/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6390 - accuracy: 0.5909\n",
            "Epoch 418/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6389 - accuracy: 0.5909\n",
            "Epoch 419/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6388 - accuracy: 0.5909\n",
            "Epoch 420/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6387 - accuracy: 0.5909\n",
            "Epoch 421/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6386 - accuracy: 0.5909\n",
            "Epoch 422/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6385 - accuracy: 0.5909\n",
            "Epoch 423/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6384 - accuracy: 0.5909\n",
            "Epoch 424/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6383 - accuracy: 0.5909\n",
            "Epoch 425/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6382 - accuracy: 0.5909\n",
            "Epoch 426/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6381 - accuracy: 0.5909\n",
            "Epoch 427/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6380 - accuracy: 0.5909\n",
            "Epoch 428/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6378 - accuracy: 0.5909\n",
            "Epoch 429/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6377 - accuracy: 0.5909\n",
            "Epoch 430/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6376 - accuracy: 0.5909\n",
            "Epoch 431/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6375 - accuracy: 0.5909\n",
            "Epoch 432/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6374 - accuracy: 0.5909\n",
            "Epoch 433/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6373 - accuracy: 0.5909\n",
            "Epoch 434/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6372 - accuracy: 0.5909\n",
            "Epoch 435/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6371 - accuracy: 0.5909\n",
            "Epoch 436/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6370 - accuracy: 0.5909\n",
            "Epoch 437/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6369 - accuracy: 0.5909\n",
            "Epoch 438/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6368 - accuracy: 0.5909\n",
            "Epoch 439/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6367 - accuracy: 0.5909\n",
            "Epoch 440/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6366 - accuracy: 0.5909\n",
            "Epoch 441/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6365 - accuracy: 0.6364\n",
            "Epoch 442/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6364 - accuracy: 0.6364\n",
            "Epoch 443/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6363 - accuracy: 0.6364\n",
            "Epoch 444/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6362 - accuracy: 0.6364\n",
            "Epoch 445/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6361 - accuracy: 0.6364\n",
            "Epoch 446/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6360 - accuracy: 0.6364\n",
            "Epoch 447/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6359 - accuracy: 0.6364\n",
            "Epoch 448/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6358 - accuracy: 0.6364\n",
            "Epoch 449/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6357 - accuracy: 0.6364\n",
            "Epoch 450/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6356 - accuracy: 0.6364\n",
            "Epoch 451/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6355 - accuracy: 0.6364\n",
            "Epoch 452/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6354 - accuracy: 0.6364\n",
            "Epoch 453/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6353 - accuracy: 0.6364\n",
            "Epoch 454/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6352 - accuracy: 0.6364\n",
            "Epoch 455/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6351 - accuracy: 0.6364\n",
            "Epoch 456/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6350 - accuracy: 0.6364\n",
            "Epoch 457/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6349 - accuracy: 0.6364\n",
            "Epoch 458/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6348 - accuracy: 0.6364\n",
            "Epoch 459/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6347 - accuracy: 0.6364\n",
            "Epoch 460/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6346 - accuracy: 0.6364\n",
            "Epoch 461/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6345 - accuracy: 0.6364\n",
            "Epoch 462/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6345 - accuracy: 0.6364\n",
            "Epoch 463/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6344 - accuracy: 0.6364\n",
            "Epoch 464/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.6364\n",
            "Epoch 465/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6342 - accuracy: 0.6364\n",
            "Epoch 466/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6341 - accuracy: 0.6364\n",
            "Epoch 467/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6340 - accuracy: 0.6364\n",
            "Epoch 468/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6339 - accuracy: 0.6364\n",
            "Epoch 469/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6338 - accuracy: 0.6364\n",
            "Epoch 470/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6337 - accuracy: 0.6818\n",
            "Epoch 471/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6336 - accuracy: 0.6818\n",
            "Epoch 472/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6335 - accuracy: 0.6818\n",
            "Epoch 473/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6334 - accuracy: 0.6818\n",
            "Epoch 474/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6334 - accuracy: 0.6818\n",
            "Epoch 475/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6333 - accuracy: 0.6818\n",
            "Epoch 476/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6332 - accuracy: 0.6818\n",
            "Epoch 477/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6331 - accuracy: 0.6818\n",
            "Epoch 478/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6330 - accuracy: 0.6818\n",
            "Epoch 479/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6329 - accuracy: 0.6818\n",
            "Epoch 480/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6328 - accuracy: 0.6818\n",
            "Epoch 481/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6327 - accuracy: 0.6818\n",
            "Epoch 482/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6326 - accuracy: 0.6818\n",
            "Epoch 483/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6326 - accuracy: 0.6818\n",
            "Epoch 484/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6325 - accuracy: 0.6818\n",
            "Epoch 485/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6324 - accuracy: 0.6818\n",
            "Epoch 486/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6323 - accuracy: 0.6818\n",
            "Epoch 487/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6322 - accuracy: 0.6818\n",
            "Epoch 488/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6321 - accuracy: 0.6818\n",
            "Epoch 489/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6320 - accuracy: 0.6818\n",
            "Epoch 490/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6320 - accuracy: 0.6818\n",
            "Epoch 491/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6319 - accuracy: 0.6818\n",
            "Epoch 492/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6318 - accuracy: 0.6818\n",
            "Epoch 493/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6317 - accuracy: 0.6818\n",
            "Epoch 494/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6316 - accuracy: 0.6818\n",
            "Epoch 495/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6315 - accuracy: 0.6818\n",
            "Epoch 496/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6315 - accuracy: 0.6818\n",
            "Epoch 497/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6314 - accuracy: 0.6818\n",
            "Epoch 498/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6313 - accuracy: 0.6818\n",
            "Epoch 499/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6312 - accuracy: 0.6818\n",
            "Epoch 500/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6311 - accuracy: 0.6818\n",
            "Epoch 501/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6310 - accuracy: 0.6818\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6310 - accuracy: 0.6818\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6309 - accuracy: 0.6818\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6308 - accuracy: 0.6818\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6307 - accuracy: 0.6818\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6306 - accuracy: 0.6818\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6306 - accuracy: 0.6818\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6305 - accuracy: 0.6818\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6304 - accuracy: 0.6818\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6303 - accuracy: 0.6818\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6302 - accuracy: 0.6818\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6302 - accuracy: 0.6818\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6301 - accuracy: 0.6818\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6300 - accuracy: 0.6818\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6299 - accuracy: 0.6818\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6298 - accuracy: 0.6818\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6298 - accuracy: 0.6818\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6297 - accuracy: 0.6818\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6296 - accuracy: 0.6818\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6295 - accuracy: 0.6818\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6295 - accuracy: 0.6818\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6294 - accuracy: 0.6818\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6293 - accuracy: 0.6818\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6292 - accuracy: 0.6818\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6292 - accuracy: 0.6818\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6291 - accuracy: 0.6818\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6290 - accuracy: 0.6818\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6289 - accuracy: 0.6818\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6288 - accuracy: 0.6818\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6288 - accuracy: 0.6818\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6287 - accuracy: 0.6818\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6286 - accuracy: 0.6818\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6285 - accuracy: 0.6818\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6285 - accuracy: 0.6818\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6284 - accuracy: 0.6818\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6283 - accuracy: 0.6818\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6283 - accuracy: 0.6818\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6282 - accuracy: 0.6818\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6281 - accuracy: 0.6818\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6280 - accuracy: 0.6818\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6280 - accuracy: 0.6818\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6279 - accuracy: 0.6818\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6278 - accuracy: 0.6818\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6277 - accuracy: 0.6818\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6277 - accuracy: 0.6818\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6276 - accuracy: 0.6818\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6275 - accuracy: 0.6818\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6275 - accuracy: 0.6818\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6274 - accuracy: 0.6818\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6273 - accuracy: 0.6818\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6272 - accuracy: 0.6818\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6272 - accuracy: 0.6818\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6271 - accuracy: 0.6818\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6270 - accuracy: 0.6818\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6270 - accuracy: 0.6818\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6269 - accuracy: 0.6818\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6268 - accuracy: 0.6818\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6268 - accuracy: 0.6818\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6267 - accuracy: 0.6818\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6266 - accuracy: 0.6818\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6265 - accuracy: 0.6818\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6265 - accuracy: 0.6818\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6264 - accuracy: 0.6818\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6263 - accuracy: 0.6818\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6263 - accuracy: 0.6818\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6262 - accuracy: 0.6818\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6261 - accuracy: 0.6818\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6261 - accuracy: 0.6818\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6260 - accuracy: 0.6818\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6259 - accuracy: 0.6818\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6259 - accuracy: 0.6818\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6258 - accuracy: 0.6818\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6257 - accuracy: 0.6818\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6257 - accuracy: 0.6818\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6256 - accuracy: 0.6818\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6255 - accuracy: 0.6818\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6255 - accuracy: 0.6818\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6254 - accuracy: 0.6818\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6253 - accuracy: 0.6818\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6253 - accuracy: 0.6818\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6252 - accuracy: 0.6818\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6251 - accuracy: 0.6818\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6251 - accuracy: 0.6818\n",
            "Epoch 584/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6250 - accuracy: 0.6818\n",
            "Epoch 585/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6249 - accuracy: 0.6818\n",
            "Epoch 586/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6249 - accuracy: 0.6818\n",
            "Epoch 587/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6248 - accuracy: 0.6818\n",
            "Epoch 588/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6247 - accuracy: 0.6818\n",
            "Epoch 589/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6247 - accuracy: 0.6818\n",
            "Epoch 590/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6246 - accuracy: 0.6818\n",
            "Epoch 591/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6245 - accuracy: 0.6818\n",
            "Epoch 592/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6245 - accuracy: 0.6818\n",
            "Epoch 593/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6244 - accuracy: 0.6818\n",
            "Epoch 594/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6244 - accuracy: 0.6818\n",
            "Epoch 595/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6243 - accuracy: 0.6818\n",
            "Epoch 596/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6242 - accuracy: 0.6818\n",
            "Epoch 597/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6242 - accuracy: 0.6818\n",
            "Epoch 598/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6241 - accuracy: 0.6818\n",
            "Epoch 599/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6240 - accuracy: 0.6818\n",
            "Epoch 600/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6240 - accuracy: 0.6818\n",
            "Epoch 601/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6239 - accuracy: 0.6818\n",
            "Epoch 602/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6238 - accuracy: 0.6818\n",
            "Epoch 603/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6238 - accuracy: 0.6818\n",
            "Epoch 604/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6237 - accuracy: 0.6818\n",
            "Epoch 605/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6237 - accuracy: 0.6818\n",
            "Epoch 606/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6236 - accuracy: 0.6818\n",
            "Epoch 607/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6235 - accuracy: 0.6818\n",
            "Epoch 608/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6235 - accuracy: 0.6818\n",
            "Epoch 609/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6234 - accuracy: 0.6818\n",
            "Epoch 610/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6233 - accuracy: 0.6818\n",
            "Epoch 611/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6233 - accuracy: 0.6818\n",
            "Epoch 612/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6232 - accuracy: 0.6818\n",
            "Epoch 613/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6232 - accuracy: 0.6818\n",
            "Epoch 614/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6231 - accuracy: 0.6818\n",
            "Epoch 615/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6230 - accuracy: 0.6818\n",
            "Epoch 616/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6230 - accuracy: 0.6818\n",
            "Epoch 617/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6229 - accuracy: 0.6818\n",
            "Epoch 618/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6229 - accuracy: 0.6818\n",
            "Epoch 619/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6228 - accuracy: 0.6818\n",
            "Epoch 620/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6227 - accuracy: 0.6818\n",
            "Epoch 621/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6227 - accuracy: 0.6818\n",
            "Epoch 622/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6226 - accuracy: 0.6818\n",
            "Epoch 623/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6225 - accuracy: 0.6818\n",
            "Epoch 624/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6225 - accuracy: 0.6818\n",
            "Epoch 625/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6224 - accuracy: 0.6818\n",
            "Epoch 626/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6224 - accuracy: 0.6818\n",
            "Epoch 627/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6223 - accuracy: 0.6818\n",
            "Epoch 628/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6222 - accuracy: 0.6818\n",
            "Epoch 629/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6222 - accuracy: 0.6818\n",
            "Epoch 630/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6221 - accuracy: 0.6818\n",
            "Epoch 631/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6221 - accuracy: 0.6818\n",
            "Epoch 632/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6220 - accuracy: 0.6818\n",
            "Epoch 633/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6219 - accuracy: 0.6818\n",
            "Epoch 634/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6219 - accuracy: 0.6818\n",
            "Epoch 635/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6218 - accuracy: 0.6818\n",
            "Epoch 636/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6218 - accuracy: 0.6818\n",
            "Epoch 637/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6217 - accuracy: 0.6818\n",
            "Epoch 638/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6216 - accuracy: 0.6818\n",
            "Epoch 639/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6216 - accuracy: 0.6818\n",
            "Epoch 640/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6215 - accuracy: 0.6818\n",
            "Epoch 641/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6215 - accuracy: 0.6818\n",
            "Epoch 642/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6214 - accuracy: 0.6818\n",
            "Epoch 643/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6213 - accuracy: 0.6818\n",
            "Epoch 644/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6213 - accuracy: 0.6818\n",
            "Epoch 645/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6212 - accuracy: 0.6818\n",
            "Epoch 646/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6212 - accuracy: 0.6818\n",
            "Epoch 647/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6211 - accuracy: 0.6818\n",
            "Epoch 648/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6210 - accuracy: 0.6818\n",
            "Epoch 649/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6210 - accuracy: 0.6818\n",
            "Epoch 650/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6209 - accuracy: 0.6818\n",
            "Epoch 651/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6209 - accuracy: 0.6818\n",
            "Epoch 652/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6208 - accuracy: 0.6818\n",
            "Epoch 653/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6208 - accuracy: 0.6818\n",
            "Epoch 654/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6207 - accuracy: 0.6818\n",
            "Epoch 655/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6206 - accuracy: 0.6818\n",
            "Epoch 656/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6206 - accuracy: 0.6818\n",
            "Epoch 657/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6205 - accuracy: 0.6818\n",
            "Epoch 658/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6205 - accuracy: 0.6818\n",
            "Epoch 659/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6204 - accuracy: 0.6818\n",
            "Epoch 660/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6203 - accuracy: 0.6818\n",
            "Epoch 661/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6203 - accuracy: 0.6818\n",
            "Epoch 662/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6202 - accuracy: 0.6818\n",
            "Epoch 663/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6202 - accuracy: 0.6818\n",
            "Epoch 664/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6201 - accuracy: 0.6818\n",
            "Epoch 665/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6201 - accuracy: 0.6818\n",
            "Epoch 666/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6200 - accuracy: 0.6818\n",
            "Epoch 667/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6199 - accuracy: 0.6818\n",
            "Epoch 668/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6199 - accuracy: 0.6818\n",
            "Epoch 669/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6198 - accuracy: 0.6818\n",
            "Epoch 670/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6198 - accuracy: 0.6818\n",
            "Epoch 671/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6197 - accuracy: 0.6818\n",
            "Epoch 672/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6197 - accuracy: 0.6818\n",
            "Epoch 673/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6196 - accuracy: 0.6818\n",
            "Epoch 674/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6195 - accuracy: 0.6818\n",
            "Epoch 675/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6195 - accuracy: 0.6818\n",
            "Epoch 676/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6194 - accuracy: 0.6818\n",
            "Epoch 677/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6194 - accuracy: 0.6818\n",
            "Epoch 678/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6193 - accuracy: 0.6818\n",
            "Epoch 679/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6193 - accuracy: 0.6818\n",
            "Epoch 680/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6192 - accuracy: 0.6818\n",
            "Epoch 681/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6191 - accuracy: 0.6818\n",
            "Epoch 682/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6191 - accuracy: 0.6818\n",
            "Epoch 683/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6190 - accuracy: 0.6818\n",
            "Epoch 684/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6190 - accuracy: 0.6818\n",
            "Epoch 685/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6189 - accuracy: 0.6818\n",
            "Epoch 686/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6189 - accuracy: 0.6818\n",
            "Epoch 687/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6188 - accuracy: 0.6818\n",
            "Epoch 688/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6187 - accuracy: 0.6818\n",
            "Epoch 689/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6187 - accuracy: 0.6818\n",
            "Epoch 690/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6186 - accuracy: 0.6818\n",
            "Epoch 691/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6186 - accuracy: 0.6818\n",
            "Epoch 692/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6185 - accuracy: 0.6818\n",
            "Epoch 693/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6185 - accuracy: 0.6818\n",
            "Epoch 694/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6184 - accuracy: 0.6818\n",
            "Epoch 695/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6184 - accuracy: 0.6818\n",
            "Epoch 696/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6183 - accuracy: 0.6818\n",
            "Epoch 697/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6182 - accuracy: 0.6818\n",
            "Epoch 698/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6182 - accuracy: 0.6818\n",
            "Epoch 699/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6181 - accuracy: 0.6818\n",
            "Epoch 700/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6181 - accuracy: 0.6818\n",
            "Epoch 701/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6180 - accuracy: 0.6818\n",
            "Epoch 702/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6180 - accuracy: 0.6818\n",
            "Epoch 703/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6179 - accuracy: 0.6818\n",
            "Epoch 704/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6178 - accuracy: 0.6818\n",
            "Epoch 705/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6178 - accuracy: 0.6818\n",
            "Epoch 706/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6177 - accuracy: 0.6818\n",
            "Epoch 707/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6177 - accuracy: 0.6818\n",
            "Epoch 708/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6176 - accuracy: 0.6818\n",
            "Epoch 709/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6176 - accuracy: 0.6818\n",
            "Epoch 710/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6175 - accuracy: 0.6818\n",
            "Epoch 711/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6175 - accuracy: 0.6818\n",
            "Epoch 712/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6174 - accuracy: 0.6818\n",
            "Epoch 713/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6173 - accuracy: 0.6818\n",
            "Epoch 714/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6173 - accuracy: 0.6818\n",
            "Epoch 715/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6172 - accuracy: 0.6818\n",
            "Epoch 716/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6172 - accuracy: 0.6818\n",
            "Epoch 717/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6171 - accuracy: 0.6818\n",
            "Epoch 718/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6171 - accuracy: 0.6818\n",
            "Epoch 719/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6170 - accuracy: 0.6818\n",
            "Epoch 720/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6170 - accuracy: 0.6818\n",
            "Epoch 721/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6169 - accuracy: 0.6818\n",
            "Epoch 722/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6168 - accuracy: 0.6818\n",
            "Epoch 723/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6168 - accuracy: 0.6818\n",
            "Epoch 724/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6167 - accuracy: 0.6818\n",
            "Epoch 725/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6167 - accuracy: 0.6818\n",
            "Epoch 726/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6166 - accuracy: 0.6818\n",
            "Epoch 727/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6166 - accuracy: 0.6818\n",
            "Epoch 728/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6165 - accuracy: 0.6818\n",
            "Epoch 729/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6165 - accuracy: 0.6818\n",
            "Epoch 730/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6164 - accuracy: 0.6818\n",
            "Epoch 731/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6163 - accuracy: 0.6818\n",
            "Epoch 732/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6163 - accuracy: 0.6818\n",
            "Epoch 733/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6162 - accuracy: 0.6818\n",
            "Epoch 734/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6162 - accuracy: 0.6818\n",
            "Epoch 735/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6161 - accuracy: 0.6818\n",
            "Epoch 736/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6161 - accuracy: 0.6818\n",
            "Epoch 737/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6160 - accuracy: 0.6818\n",
            "Epoch 738/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6160 - accuracy: 0.6818\n",
            "Epoch 739/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6159 - accuracy: 0.6818\n",
            "Epoch 740/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6159 - accuracy: 0.6818\n",
            "Epoch 741/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6158 - accuracy: 0.6818\n",
            "Epoch 742/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6157 - accuracy: 0.6818\n",
            "Epoch 743/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6157 - accuracy: 0.6818\n",
            "Epoch 744/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6156 - accuracy: 0.6818\n",
            "Epoch 745/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6156 - accuracy: 0.6818\n",
            "Epoch 746/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6155 - accuracy: 0.6818\n",
            "Epoch 747/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6155 - accuracy: 0.6818\n",
            "Epoch 748/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6154 - accuracy: 0.6818\n",
            "Epoch 749/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6154 - accuracy: 0.6818\n",
            "Epoch 750/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6153 - accuracy: 0.6818\n",
            "Epoch 751/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6153 - accuracy: 0.6818\n",
            "Epoch 752/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6152 - accuracy: 0.6818\n",
            "Epoch 753/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6151 - accuracy: 0.6818\n",
            "Epoch 754/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6151 - accuracy: 0.6818\n",
            "Epoch 755/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6150 - accuracy: 0.6818\n",
            "Epoch 756/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6150 - accuracy: 0.6818\n",
            "Epoch 757/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6149 - accuracy: 0.6818\n",
            "Epoch 758/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6149 - accuracy: 0.6818\n",
            "Epoch 759/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6148 - accuracy: 0.6818\n",
            "Epoch 760/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6148 - accuracy: 0.6818\n",
            "Epoch 761/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6147 - accuracy: 0.6818\n",
            "Epoch 762/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6147 - accuracy: 0.6818\n",
            "Epoch 763/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6146 - accuracy: 0.6818\n",
            "Epoch 764/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6145 - accuracy: 0.6818\n",
            "Epoch 765/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6145 - accuracy: 0.6818\n",
            "Epoch 766/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6144 - accuracy: 0.6818\n",
            "Epoch 767/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6144 - accuracy: 0.6818\n",
            "Epoch 768/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6143 - accuracy: 0.6818\n",
            "Epoch 769/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6143 - accuracy: 0.6818\n",
            "Epoch 770/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6142 - accuracy: 0.6818\n",
            "Epoch 771/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6142 - accuracy: 0.6818\n",
            "Epoch 772/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6141 - accuracy: 0.6818\n",
            "Epoch 773/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6141 - accuracy: 0.6818\n",
            "Epoch 774/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6140 - accuracy: 0.6818\n",
            "Epoch 775/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6139 - accuracy: 0.6818\n",
            "Epoch 776/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6139 - accuracy: 0.6818\n",
            "Epoch 777/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6138 - accuracy: 0.6818\n",
            "Epoch 778/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6138 - accuracy: 0.6818\n",
            "Epoch 779/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6137 - accuracy: 0.6818\n",
            "Epoch 780/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6137 - accuracy: 0.6818\n",
            "Epoch 781/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6136 - accuracy: 0.6818\n",
            "Epoch 782/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6136 - accuracy: 0.6818\n",
            "Epoch 783/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6135 - accuracy: 0.6818\n",
            "Epoch 784/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6135 - accuracy: 0.6818\n",
            "Epoch 785/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6134 - accuracy: 0.6818\n",
            "Epoch 786/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6133 - accuracy: 0.6818\n",
            "Epoch 787/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6133 - accuracy: 0.6818\n",
            "Epoch 788/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6132 - accuracy: 0.6818\n",
            "Epoch 789/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6132 - accuracy: 0.6818\n",
            "Epoch 790/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6131 - accuracy: 0.6818\n",
            "Epoch 791/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6131 - accuracy: 0.6818\n",
            "Epoch 792/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6130 - accuracy: 0.6818\n",
            "Epoch 793/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6130 - accuracy: 0.6818\n",
            "Epoch 794/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6129 - accuracy: 0.6818\n",
            "Epoch 795/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6129 - accuracy: 0.6818\n",
            "Epoch 796/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6128 - accuracy: 0.6818\n",
            "Epoch 797/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6128 - accuracy: 0.6818\n",
            "Epoch 798/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6127 - accuracy: 0.6818\n",
            "Epoch 799/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6126 - accuracy: 0.6818\n",
            "Epoch 800/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6126 - accuracy: 0.6818\n",
            "Epoch 801/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6125 - accuracy: 0.6818\n",
            "Epoch 802/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6125 - accuracy: 0.6818\n",
            "Epoch 803/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6124 - accuracy: 0.6818\n",
            "Epoch 804/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6124 - accuracy: 0.6818\n",
            "Epoch 805/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6123 - accuracy: 0.6818\n",
            "Epoch 806/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6123 - accuracy: 0.6818\n",
            "Epoch 807/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6122 - accuracy: 0.6818\n",
            "Epoch 808/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6122 - accuracy: 0.6818\n",
            "Epoch 809/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6121 - accuracy: 0.6818\n",
            "Epoch 810/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6120 - accuracy: 0.6818\n",
            "Epoch 811/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6120 - accuracy: 0.6818\n",
            "Epoch 812/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6119 - accuracy: 0.6818\n",
            "Epoch 813/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6119 - accuracy: 0.6818\n",
            "Epoch 814/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6118 - accuracy: 0.6818\n",
            "Epoch 815/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6118 - accuracy: 0.6818\n",
            "Epoch 816/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6117 - accuracy: 0.6818\n",
            "Epoch 817/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6117 - accuracy: 0.6818\n",
            "Epoch 818/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6116 - accuracy: 0.6818\n",
            "Epoch 819/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6116 - accuracy: 0.6818\n",
            "Epoch 820/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6115 - accuracy: 0.6818\n",
            "Epoch 821/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6115 - accuracy: 0.6818\n",
            "Epoch 822/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6114 - accuracy: 0.6818\n",
            "Epoch 823/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6113 - accuracy: 0.6818\n",
            "Epoch 824/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6113 - accuracy: 0.6818\n",
            "Epoch 825/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6112 - accuracy: 0.6818\n",
            "Epoch 826/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6112 - accuracy: 0.6818\n",
            "Epoch 827/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6111 - accuracy: 0.6818\n",
            "Epoch 828/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6111 - accuracy: 0.6818\n",
            "Epoch 829/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6110 - accuracy: 0.6818\n",
            "Epoch 830/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6110 - accuracy: 0.6818\n",
            "Epoch 831/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6109 - accuracy: 0.6818\n",
            "Epoch 832/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6109 - accuracy: 0.6818\n",
            "Epoch 833/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6108 - accuracy: 0.6818\n",
            "Epoch 834/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6107 - accuracy: 0.6818\n",
            "Epoch 835/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6107 - accuracy: 0.6818\n",
            "Epoch 836/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6106 - accuracy: 0.6818\n",
            "Epoch 837/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6106 - accuracy: 0.6818\n",
            "Epoch 838/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6105 - accuracy: 0.6818\n",
            "Epoch 839/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6105 - accuracy: 0.6818\n",
            "Epoch 840/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6104 - accuracy: 0.6818\n",
            "Epoch 841/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6104 - accuracy: 0.6818\n",
            "Epoch 842/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6103 - accuracy: 0.6818\n",
            "Epoch 843/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6103 - accuracy: 0.6818\n",
            "Epoch 844/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6102 - accuracy: 0.6818\n",
            "Epoch 845/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6102 - accuracy: 0.6818\n",
            "Epoch 846/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6101 - accuracy: 0.6818\n",
            "Epoch 847/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6100 - accuracy: 0.6818\n",
            "Epoch 848/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6100 - accuracy: 0.6818\n",
            "Epoch 849/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6099 - accuracy: 0.6818\n",
            "Epoch 850/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6099 - accuracy: 0.6818\n",
            "Epoch 851/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6098 - accuracy: 0.6818\n",
            "Epoch 852/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6098 - accuracy: 0.6818\n",
            "Epoch 853/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6097 - accuracy: 0.6818\n",
            "Epoch 854/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6097 - accuracy: 0.6818\n",
            "Epoch 855/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6096 - accuracy: 0.6818\n",
            "Epoch 856/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6096 - accuracy: 0.6818\n",
            "Epoch 857/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6095 - accuracy: 0.6818\n",
            "Epoch 858/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6095 - accuracy: 0.6818\n",
            "Epoch 859/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6094 - accuracy: 0.6818\n",
            "Epoch 860/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6093 - accuracy: 0.6818\n",
            "Epoch 861/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6093 - accuracy: 0.6818\n",
            "Epoch 862/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6092 - accuracy: 0.6818\n",
            "Epoch 863/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6092 - accuracy: 0.6818\n",
            "Epoch 864/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6091 - accuracy: 0.6818\n",
            "Epoch 865/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6091 - accuracy: 0.6818\n",
            "Epoch 866/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6090 - accuracy: 0.6818\n",
            "Epoch 867/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6090 - accuracy: 0.6818\n",
            "Epoch 868/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6089 - accuracy: 0.6818\n",
            "Epoch 869/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6089 - accuracy: 0.6818\n",
            "Epoch 870/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6088 - accuracy: 0.6818\n",
            "Epoch 871/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6087 - accuracy: 0.6818\n",
            "Epoch 872/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6087 - accuracy: 0.6818\n",
            "Epoch 873/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6086 - accuracy: 0.6818\n",
            "Epoch 874/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6086 - accuracy: 0.6818\n",
            "Epoch 875/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6085 - accuracy: 0.6818\n",
            "Epoch 876/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6085 - accuracy: 0.6818\n",
            "Epoch 877/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6084 - accuracy: 0.6818\n",
            "Epoch 878/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6084 - accuracy: 0.6818\n",
            "Epoch 879/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6083 - accuracy: 0.6818\n",
            "Epoch 880/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6083 - accuracy: 0.6818\n",
            "Epoch 881/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6082 - accuracy: 0.6818\n",
            "Epoch 882/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6081 - accuracy: 0.6818\n",
            "Epoch 883/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6081 - accuracy: 0.6818\n",
            "Epoch 884/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6080 - accuracy: 0.6818\n",
            "Epoch 885/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6080 - accuracy: 0.6818\n",
            "Epoch 886/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6079 - accuracy: 0.6818\n",
            "Epoch 887/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6079 - accuracy: 0.6818\n",
            "Epoch 888/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6078 - accuracy: 0.6818\n",
            "Epoch 889/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6078 - accuracy: 0.6818\n",
            "Epoch 890/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6077 - accuracy: 0.6818\n",
            "Epoch 891/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6077 - accuracy: 0.6818\n",
            "Epoch 892/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6076 - accuracy: 0.6818\n",
            "Epoch 893/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6076 - accuracy: 0.6818\n",
            "Epoch 894/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6075 - accuracy: 0.6818\n",
            "Epoch 895/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6074 - accuracy: 0.6818\n",
            "Epoch 896/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6074 - accuracy: 0.6818\n",
            "Epoch 897/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6073 - accuracy: 0.6818\n",
            "Epoch 898/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6073 - accuracy: 0.6818\n",
            "Epoch 899/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6072 - accuracy: 0.6818\n",
            "Epoch 900/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6072 - accuracy: 0.6818\n",
            "Epoch 901/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6071 - accuracy: 0.6818\n",
            "Epoch 902/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6071 - accuracy: 0.6818\n",
            "Epoch 903/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6070 - accuracy: 0.6818\n",
            "Epoch 904/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6070 - accuracy: 0.6818\n",
            "Epoch 905/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6069 - accuracy: 0.6818\n",
            "Epoch 906/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6068 - accuracy: 0.6818\n",
            "Epoch 907/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6068 - accuracy: 0.6818\n",
            "Epoch 908/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6067 - accuracy: 0.6818\n",
            "Epoch 909/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6067 - accuracy: 0.6818\n",
            "Epoch 910/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6066 - accuracy: 0.6818\n",
            "Epoch 911/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6066 - accuracy: 0.6818\n",
            "Epoch 912/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6065 - accuracy: 0.6818\n",
            "Epoch 913/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6065 - accuracy: 0.6818\n",
            "Epoch 914/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6064 - accuracy: 0.6818\n",
            "Epoch 915/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6064 - accuracy: 0.6818\n",
            "Epoch 916/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6063 - accuracy: 0.6818\n",
            "Epoch 917/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6062 - accuracy: 0.6818\n",
            "Epoch 918/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6062 - accuracy: 0.6818\n",
            "Epoch 919/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6061 - accuracy: 0.6818\n",
            "Epoch 920/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6061 - accuracy: 0.6818\n",
            "Epoch 921/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6060 - accuracy: 0.6818\n",
            "Epoch 922/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6060 - accuracy: 0.6818\n",
            "Epoch 923/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6059 - accuracy: 0.6818\n",
            "Epoch 924/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6059 - accuracy: 0.6818\n",
            "Epoch 925/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6058 - accuracy: 0.6818\n",
            "Epoch 926/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6058 - accuracy: 0.6818\n",
            "Epoch 927/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6057 - accuracy: 0.6818\n",
            "Epoch 928/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6056 - accuracy: 0.6818\n",
            "Epoch 929/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6056 - accuracy: 0.6818\n",
            "Epoch 930/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6055 - accuracy: 0.6818\n",
            "Epoch 931/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6055 - accuracy: 0.6818\n",
            "Epoch 932/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6054 - accuracy: 0.6818\n",
            "Epoch 933/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6054 - accuracy: 0.6818\n",
            "Epoch 934/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6053 - accuracy: 0.6818\n",
            "Epoch 935/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6053 - accuracy: 0.6818\n",
            "Epoch 936/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6052 - accuracy: 0.6818\n",
            "Epoch 937/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6052 - accuracy: 0.6818\n",
            "Epoch 938/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6051 - accuracy: 0.6818\n",
            "Epoch 939/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6050 - accuracy: 0.6818\n",
            "Epoch 940/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6050 - accuracy: 0.6818\n",
            "Epoch 941/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6049 - accuracy: 0.6818\n",
            "Epoch 942/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6049 - accuracy: 0.6818\n",
            "Epoch 943/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6048 - accuracy: 0.6818\n",
            "Epoch 944/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6048 - accuracy: 0.6818\n",
            "Epoch 945/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6047 - accuracy: 0.6818\n",
            "Epoch 946/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6047 - accuracy: 0.6818\n",
            "Epoch 947/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6046 - accuracy: 0.6818\n",
            "Epoch 948/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6046 - accuracy: 0.6818\n",
            "Epoch 949/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6045 - accuracy: 0.6818\n",
            "Epoch 950/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6044 - accuracy: 0.6818\n",
            "Epoch 951/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6044 - accuracy: 0.6818\n",
            "Epoch 952/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6043 - accuracy: 0.6818\n",
            "Epoch 953/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6043 - accuracy: 0.6818\n",
            "Epoch 954/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6042 - accuracy: 0.6818\n",
            "Epoch 955/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6042 - accuracy: 0.6818\n",
            "Epoch 956/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6041 - accuracy: 0.6818\n",
            "Epoch 957/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6041 - accuracy: 0.6818\n",
            "Epoch 958/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6040 - accuracy: 0.6818\n",
            "Epoch 959/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6039 - accuracy: 0.6818\n",
            "Epoch 960/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6039 - accuracy: 0.6818\n",
            "Epoch 961/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6038 - accuracy: 0.6818\n",
            "Epoch 962/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6038 - accuracy: 0.6818\n",
            "Epoch 963/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6037 - accuracy: 0.6818\n",
            "Epoch 964/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6037 - accuracy: 0.6818\n",
            "Epoch 965/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6036 - accuracy: 0.6818\n",
            "Epoch 966/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6036 - accuracy: 0.6818\n",
            "Epoch 967/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6035 - accuracy: 0.6818\n",
            "Epoch 968/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6035 - accuracy: 0.6818\n",
            "Epoch 969/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6034 - accuracy: 0.6818\n",
            "Epoch 970/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6033 - accuracy: 0.6818\n",
            "Epoch 971/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6033 - accuracy: 0.6818\n",
            "Epoch 972/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6032 - accuracy: 0.6818\n",
            "Epoch 973/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6032 - accuracy: 0.6818\n",
            "Epoch 974/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6031 - accuracy: 0.6818\n",
            "Epoch 975/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6031 - accuracy: 0.6818\n",
            "Epoch 976/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6030 - accuracy: 0.6818\n",
            "Epoch 977/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6030 - accuracy: 0.6818\n",
            "Epoch 978/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6029 - accuracy: 0.6818\n",
            "Epoch 979/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6028 - accuracy: 0.6818\n",
            "Epoch 980/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6028 - accuracy: 0.6818\n",
            "Epoch 981/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6027 - accuracy: 0.6818\n",
            "Epoch 982/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6027 - accuracy: 0.6818\n",
            "Epoch 983/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6026 - accuracy: 0.6818\n",
            "Epoch 984/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6026 - accuracy: 0.6818\n",
            "Epoch 985/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6025 - accuracy: 0.6818\n",
            "Epoch 986/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6025 - accuracy: 0.6818\n",
            "Epoch 987/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6024 - accuracy: 0.6818\n",
            "Epoch 988/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6024 - accuracy: 0.6818\n",
            "Epoch 989/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6023 - accuracy: 0.6818\n",
            "Epoch 990/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6022 - accuracy: 0.6818\n",
            "Epoch 991/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6022 - accuracy: 0.6818\n",
            "Epoch 992/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6021 - accuracy: 0.6818\n",
            "Epoch 993/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6021 - accuracy: 0.6818\n",
            "Epoch 994/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6020 - accuracy: 0.6818\n",
            "Epoch 995/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6020 - accuracy: 0.6818\n",
            "Epoch 996/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6019 - accuracy: 0.6818\n",
            "Epoch 997/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6019 - accuracy: 0.6818\n",
            "Epoch 998/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6018 - accuracy: 0.6818\n",
            "Epoch 999/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6017 - accuracy: 0.6818\n",
            "Epoch 1000/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6017 - accuracy: 0.6818\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f21454ff4d0>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nADLLC1VFGhM",
        "outputId": "730599ce-5779-4b3c-8ce5-fd21e6dec4cc"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 112ms/step - loss: 0.6033 - accuracy: 0.6667\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6033335328102112, 0.6666666865348816]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(X_test_scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnHqYUAvFLEM",
        "outputId": "5c4d5736-4b23-4d79-d072-a0405a1b02f5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.59917784],\n",
              "       [0.6351106 ],\n",
              "       [0.39213923],\n",
              "       [0.60145974],\n",
              "       [0.46891758],\n",
              "       [0.6195487 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coef, intercept = model.get_weights()"
      ],
      "metadata": {
        "id": "zcqS8it0F0e1"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coef, intercept"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xn1WePuLF9hZ",
        "outputId": "10720bb0-c400-47c9-fed6-7526c25960f7"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.9510262],\n",
              "        [0.6691849]], dtype=float32), array([-0.695106], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Scratch"
      ],
      "metadata": {
        "id": "QRbFQqlOUirQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    import math\n",
        "    return 1/(1+math.exp(-x))"
      ],
      "metadata": {
        "id": "N3cmItdwF-5q"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction_function(age, affordibility):\n",
        "    weighted_sum = coef[0]*age + coef[1]*affordibility + intercept\n",
        "    return sigmoid(weighted_sum)"
      ],
      "metadata": {
        "id": "L9kEf07ZF_zx"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_function(0.47,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTKZZ56AU-Cj",
        "outputId": "85c8d26b-969f-46a1-df38-1abbdaa3c181"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6916949164361127"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Descent from scratch"
      ],
      "metadata": {
        "id": "hsOZYlzvVZPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log_loss(y_true, y_predicted):\n",
        "    epsilon = 1e-15\n",
        "    y_predicted_new = [max(i, epsilon) for i in y_predicted]\n",
        "    y_predicted_new = [min(i, 1 - epsilon) for i in y_predicted]\n",
        "    y_predicted_new = np.array(y_predicted_new)\n",
        "    return -np.mean( y_true*np.log(y_predicted_new) + (1 - y_true) * np.log(1 - y_predicted_new))"
      ],
      "metadata": {
        "id": "I95mw7fAVBrp"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid_numpy(X):\n",
        "    return 1/(1+ np.exp(-X))\n",
        "\n",
        "sigmoid_numpy(np.array([12,0,1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlbjKuN2WG_N",
        "outputId": "11a9df41-2511-4d23-a85b-884c694610db"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.99999386, 0.5       , 0.73105858])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(age, affordibility, y_true, epochs):\n",
        "    w1 = w2 = 1\n",
        "    bias = 0\n",
        "    rate = 0.01\n",
        "    n = len(age)\n",
        "\n",
        "    for i in range(epochs):\n",
        "        weighted_sum = w1*age + w2*affordibility + bias\n",
        "        y_predicted = sigmoid_numpy(weighted_sum)\n",
        "\n",
        "        loss = log_loss(y_true, y_predicted)\n",
        "\n",
        "        w1d = (1/n)*np.dot(np.transpose(age),(y_predicted - y_true))\n",
        "        w2d = (1/n)*np.dot(np.transpose(affordibility),(y_predicted - y_true))\n",
        "\n",
        "        bias_d = np.mean(y_predicted - y_true)\n",
        "\n",
        "        w1 = w1 - rate*w1d\n",
        "        w2 = w2 - rate*w2d\n",
        "        bias = bias - rate * bias_d\n",
        "\n",
        "        print(f'Epoch:{i}, w1:{w1}, w2:{w2}, bias:{bias}, loss:{loss}')\n",
        "\n",
        "    return w1, w2, bias"
      ],
      "metadata": {
        "id": "RSttsFDsWdV-"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradient_descent(X_train_scaled['age'], X_train_scaled['affordibility'], y_train,1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qgNsM3IuQnr",
        "outputId": "7368e532-af8d-4a23-92e9-cb63132d6691"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0, w1:0.9994106012341517, w2:0.9986344455057053, bias:-0.0027608392224643323, loss:0.750728371337802\n",
            "Epoch:1, w1:0.9988237710266822, w2:0.9972736199817122, bias:-0.005514671444354724, loss:0.7497463003825988\n",
            "Epoch:2, w1:0.9982395073630282, w2:0.9959175218523879, bias:-0.008261503199352954, loss:0.7487696800116163\n",
            "Epoch:3, w1:0.9976578081871769, w2:0.9945661494476083, bias:-0.011001341127791917, loss:0.7477984903474536\n",
            "Epoch:4, w1:0.9970786714018849, w2:0.9932195010031427, bias:-0.013734191976018916, loss:0.7468327114592935\n",
            "Epoch:5, w1:0.9965020948689008, w2:0.9918775746610453, bias:-0.016460062595753392, loss:0.7458723233643885\n",
            "Epoch:6, w1:0.9959280764091897, w2:0.9905403684700536, bias:-0.019178959943439197, loss:0.7449173060295408\n",
            "Epoch:7, w1:0.9953566138031593, w2:0.9892078803859925, bias:-0.021890891079591527, loss:0.7439676393725808\n",
            "Epoch:8, w1:0.9947877047908894, w2:0.9878801082721854, bias:-0.024595863168138627, loss:0.7430233032638398\n",
            "Epoch:9, w1:0.9942213470723628, w2:0.9865570498998706, bias:-0.027293883475758385, loss:0.7420842775276177\n",
            "Epoch:10, w1:0.9936575383076984, w2:0.9852387029486243, bias:-0.02998495937120993, loss:0.7411505419436497\n",
            "Epoch:11, w1:0.9930962761173873, w2:0.9839250650067893, bias:-0.032669098324660334, loss:0.7402220762485626\n",
            "Epoch:12, w1:0.9925375580825294, w2:0.98261613357191, bias:-0.03534630790700657, loss:0.7392988601373317\n",
            "Epoch:13, w1:0.9919813817450738, w2:0.9813119060511724, bias:-0.03801659578919279, loss:0.7383808732647291\n",
            "Epoch:14, w1:0.9914277446080595, w2:0.9800123797618502, bias:-0.04067996974152309, loss:0.737468095246768\n",
            "Epoch:15, w1:0.9908766441358595, w2:0.9787175519317569, bias:-0.043336437632969835, loss:0.7365605056621408\n",
            "Epoch:16, w1:0.9903280777544259, w2:0.9774274196997021, bias:-0.045986007430477656, loss:0.7356580840536516\n",
            "Epoch:17, w1:0.989782042851537, w2:0.9761419801159548, bias:-0.0486286871982633, loss:0.7347608099296448\n",
            "Epoch:18, w1:0.9892385367770469, w2:0.9748612301427102, bias:-0.051264485097111345, loss:0.733868662765423\n",
            "Epoch:19, w1:0.9886975568431354, w2:0.9735851666545632, bias:-0.053893409383666005, loss:0.7329816220046644\n",
            "Epoch:20, w1:0.9881591003245616, w2:0.9723137864389861, bias:-0.05651546840971902, loss:0.7320996670608289\n",
            "Epoch:21, w1:0.9876231644589172, w2:0.9710470861968116, bias:-0.059130670621493873, loss:0.7312227773185604\n",
            "Epoch:22, w1:0.9870897464468831, w2:0.9697850625427199, bias:-0.06173902455892631, loss:0.7303509321350817\n",
            "Epoch:23, w1:0.9865588434524866, w2:0.9685277120057322, bias:-0.06434053885494144, loss:0.729484110841582\n",
            "Epoch:24, w1:0.9860304526033603, w2:0.9672750310297068, bias:-0.06693522223472734, loss:0.7286222927445979\n",
            "Epoch:25, w1:0.985504570991003, w2:0.9660270159738417, bias:-0.06952308351500543, loss:0.7277654571273868\n",
            "Epoch:26, w1:0.9849811956710415, w2:0.96478366311318, bias:-0.0721041316032977, loss:0.7269135832512936\n",
            "Epoch:27, w1:0.9844603236634941, w2:0.9635449686391209, bias:-0.07467837549719084, loss:0.726066650357107\n",
            "Epoch:28, w1:0.9839419519530357, w2:0.9623109286599342, bias:-0.07724582428359736, loss:0.7252246376664145\n",
            "Epoch:29, w1:0.9834260774892637, w2:0.9610815392012791, bias:-0.07980648713801403, loss:0.7243875243829418\n",
            "Epoch:30, w1:0.9829126971869657, w2:0.9598567962067277, bias:-0.08236037332377746, loss:0.723555289693889\n",
            "Epoch:31, w1:0.9824018079263883, w2:0.9586366955382911, bias:-0.08490749219131713, loss:0.7227279127712593\n",
            "Epoch:32, w1:0.9818934065535069, w2:0.9574212329769508, bias:-0.08744785317740587, loss:0.7219053727731737\n",
            "Epoch:33, w1:0.981387489880297, w2:0.956210404223193, bias:-0.08998146580440801, loss:0.7210876488451866\n",
            "Epoch:34, w1:0.9808840546850066, w2:0.9550042048975468, bias:-0.09250833967952515, loss:0.7202747201215828\n",
            "Epoch:35, w1:0.9803830977124295, w2:0.9538026305411257, bias:-0.09502848449403992, loss:0.7194665657266742\n",
            "Epoch:36, w1:0.9798846156741796, w2:0.9526056766161732, bias:-0.09754191002255742, loss:0.718663164776082\n",
            "Epoch:37, w1:0.9793886052489669, w2:0.9514133385066111, bias:-0.10004862612224498, loss:0.7178644963780124\n",
            "Epoch:38, w1:0.9788950630828731, w2:0.9502256115185912, bias:-0.10254864273206983, loss:0.7170705396345255\n",
            "Epoch:39, w1:0.9784039857896297, w2:0.9490424908810503, bias:-0.10504196987203517, loss:0.716281273642789\n",
            "Epoch:40, w1:0.9779153699508961, w2:0.9478639717462685, bias:-0.10752861764241452, loss:0.7154966774963301\n",
            "Epoch:41, w1:0.9774292121165383, w2:0.9466900491904296, bias:-0.1100085962229846, loss:0.7147167302862715\n",
            "Epoch:42, w1:0.9769455088049093, w2:0.9455207182141857, bias:-0.11248191587225673, loss:0.7139414111025628\n",
            "Epoch:43, w1:0.9764642565031293, w2:0.9443559737432231, bias:-0.11494858692670686, loss:0.7131706990351989\n",
            "Epoch:44, w1:0.9759854516673677, w2:0.9431958106288318, bias:-0.11740861980000449, loss:0.7124045731754316\n",
            "Epoch:45, w1:0.9755090907231246, w2:0.9420402236484778, bias:-0.11986202498224038, loss:0.7116430126169692\n",
            "Epoch:46, w1:0.9750351700655139, w2:0.9408892075063767, bias:-0.1223088130391533, loss:0.7108859964571673\n",
            "Epoch:47, w1:0.9745636860595462, w2:0.939742756834071, bias:-0.1247489946113557, loss:0.7101335037982107\n",
            "Epoch:48, w1:0.9740946350404134, w2:0.9386008661910089, bias:-0.12718258041355884, loss:0.7093855137482826\n",
            "Epoch:49, w1:0.9736280133137725, w2:0.9374635300651256, bias:-0.1296095812337969, loss:0.7086420054227267\n",
            "Epoch:50, w1:0.9731638171560307, w2:0.9363307428734264, bias:-0.13203000793265066, loss:0.7079029579451969\n",
            "Epoch:51, w1:0.9727020428146312, w2:0.9352024989625725, bias:-0.13444387144247064, loss:0.7071683504487986\n",
            "Epoch:52, w1:0.9722426865083382, w2:0.9340787926094677, bias:-0.1368511827665997, loss:0.706438162077217\n",
            "Epoch:53, w1:0.9717857444275239, w2:0.9329596180218479, bias:-0.13925195297859536, loss:0.7057123719858398\n",
            "Epoch:54, w1:0.9713312127344542, w2:0.9318449693388717, bias:-0.14164619322145197, loss:0.7049909593428633\n",
            "Epoch:55, w1:0.9708790875635763, w2:0.9307348406317131, bias:-0.1440339147068226, loss:0.7042739033303923\n",
            "Epoch:56, w1:0.9704293650218052, w2:0.929629225904155, bias:-0.146415128714241, loss:0.70356118314553\n",
            "Epoch:57, w1:0.9699820411888114, w2:0.9285281190931853, bias:-0.14878984659034344, loss:0.7028527780014525\n",
            "Epoch:58, w1:0.9695371121173079, w2:0.9274315140695937, bias:-0.15115807974809084, loss:0.7021486671284776\n",
            "Epoch:59, w1:0.9690945738333385, w2:0.9263394046385692, bias:-0.15351983966599111, loss:0.7014488297751212\n",
            "Epoch:60, w1:0.9686544223365652, w2:0.9252517845403004, bias:-0.15587513788732169, loss:0.7007532452091414\n",
            "Epoch:61, w1:0.968216653600556, w2:0.9241686474505753, bias:-0.15822398601935253, loss:0.7000618927185734\n",
            "Epoch:62, w1:0.9677812635730731, w2:0.9230899869813828, bias:-0.1605663957325697, loss:0.6993747516127541\n",
            "Epoch:63, w1:0.9673482481763608, w2:0.9220157966815157, bias:-0.16290237875989935, loss:0.6986918012233327\n",
            "Epoch:64, w1:0.9669176033074329, w2:0.9209460700371735, bias:-0.1652319468959325, loss:0.698013020905276\n",
            "Epoch:65, w1:0.9664893248383615, w2:0.9198808004725669, bias:-0.1675551119961505, loss:0.6973383900378548\n",
            "Epoch:66, w1:0.9660634086165638, w2:0.9188199813505221, bias:-0.16987188597615133, loss:0.6966678880256275\n",
            "Epoch:67, w1:0.9656398504650907, w2:0.9177636059730866, bias:-0.17218228081087678, loss:0.6960014942994065\n",
            "Epoch:68, w1:0.9652186461829136, w2:0.916711667582135, bias:-0.17448630853384076, loss:0.6953391883172166\n",
            "Epoch:69, w1:0.9647997915452122, w2:0.9156641593599752, bias:-0.17678398123635847, loss:0.6946809495652418\n",
            "Epoch:70, w1:0.9643832823036613, w2:0.9146210744299559, bias:-0.17907531106677693, loss:0.6940267575587594\n",
            "Epoch:71, w1:0.9639691141867179, w2:0.9135824058570724, bias:-0.18136031022970658, loss:0.6933765918430663\n",
            "Epoch:72, w1:0.9635572828999078, w2:0.912548146648575, bias:-0.1836389909852543, loss:0.6927304319943903\n",
            "Epoch:73, w1:0.9631477841261119, w2:0.9115182897545756, bias:-0.18591136564825775, loss:0.6920882576207925\n",
            "Epoch:74, w1:0.9627406135258518, w2:0.910492828068656, bias:-0.1881774465875212, loss:0.6914500483630582\n",
            "Epoch:75, w1:0.962335766737576, w2:0.9094717544284744, bias:-0.1904372462250529, loss:0.6908157838955769\n",
            "Epoch:76, w1:0.9619332393779448, w2:0.9084550616163736, bias:-0.19269077703530404, loss:0.6901854439272087\n",
            "Epoch:77, w1:0.9615330270421149, w2:0.9074427423599875, bias:-0.19493805154440946, loss:0.6895590082021433\n",
            "Epoch:78, w1:0.9611351253040238, w2:0.9064347893328486, bias:-0.19717908232942993, loss:0.6889364565007452\n",
            "Epoch:79, w1:0.960739529716674, w2:0.9054311951549945, bias:-0.19941388201759647, loss:0.6883177686403875\n",
            "Epoch:80, w1:0.9603462358124158, w2:0.9044319523935739, bias:-0.2016424632855565, loss:0.6877029244762767\n",
            "Epoch:81, w1:0.9599552391032306, w2:0.9034370535634527, bias:-0.20386483885862178, loss:0.6870919039022637\n",
            "Epoch:82, w1:0.9595665350810122, w2:0.9024464911278195, bias:-0.2060810215100187, loss:0.6864846868516449\n",
            "Epoch:83, w1:0.9591801192178496, w2:0.9014602574987898, bias:-0.2082910240601403, loss:0.6858812532979527\n",
            "Epoch:84, w1:0.9587959869663073, w2:0.9004783450380105, bias:-0.21049485937580079, loss:0.6852815832557332\n",
            "Epoch:85, w1:0.9584141337597055, w2:0.899500746057263, bias:-0.212692540369492, loss:0.6846856567813139\n",
            "Epoch:86, w1:0.9580345550124002, w2:0.8985274528190661, bias:-0.21488407999864234, loss:0.68409345397356\n",
            "Epoch:87, w1:0.957657246120062, w2:0.897558457537277, bias:-0.2170694912648779, loss:0.683504954974619\n",
            "Epoch:88, w1:0.9572822024599543, w2:0.8965937523776931, bias:-0.21924878721328617, loss:0.6829201399706553\n",
            "Epoch:89, w1:0.9569094193912109, w2:0.895633329458651, bias:-0.22142198093168206, loss:0.6823389891925725\n",
            "Epoch:90, w1:0.9565388922551125, w2:0.8946771808516256, bias:-0.22358908554987653, loss:0.681761482916725\n",
            "Epoch:91, w1:0.9561706163753628, w2:0.8937252985818278, bias:-0.22575011423894772, loss:0.6811876014656192\n",
            "Epoch:92, w1:0.955804587058364, w2:0.8927776746288009, bias:-0.2279050802105149, loss:0.6806173252086029\n",
            "Epoch:93, w1:0.9554407995934902, w2:0.8918343009270158, bias:-0.2300539967160148, loss:0.6800506345625434\n",
            "Epoch:94, w1:0.9550792492533613, w2:0.8908951693664654, bias:-0.23219687704598105, loss:0.6794875099924956\n",
            "Epoch:95, w1:0.9547199312941158, w2:0.8899602717932569, bias:-0.2343337345293261, loss:0.6789279320123593\n",
            "Epoch:96, w1:0.9543628409556818, w2:0.8890296000102031, bias:-0.23646458253262623, loss:0.6783718811855234\n",
            "Epoch:97, w1:0.9540079734620481, w2:0.8881031457774127, bias:-0.2385894344594093, loss:0.6778193381255015\n",
            "Epoch:98, w1:0.9536553240215337, w2:0.8871809008128778, bias:-0.24070830374944557, loss:0.6772702834965573\n",
            "Epoch:99, w1:0.9533048878270567, w2:0.8862628567930615, bias:-0.2428212038780414, loss:0.6767246980143152\n",
            "Epoch:100, w1:0.9529566600564018, w2:0.8853490053534824, bias:-0.24492814835533616, loss:0.6761825624463652\n",
            "Epoch:101, w1:0.9526106358724874, w2:0.8844393380892985, bias:-0.24702915072560203, loss:0.6756438576128535\n",
            "Epoch:102, w1:0.9522668104236311, w2:0.8835338465558891, bias:-0.24912422456654712, loss:0.6751085643870627\n",
            "Epoch:103, w1:0.9519251788438143, w2:0.8826325222694341, bias:-0.2512133834886217, loss:0.6745766636959848\n",
            "Epoch:104, w1:0.9515857362529461, w2:0.8817353567074931, bias:-0.25329664113432776, loss:0.6740481365208777\n",
            "Epoch:105, w1:0.9512484777571252, w2:0.8808423413095813, bias:-0.25537401117753145, loss:0.673522963897818\n",
            "Epoch:106, w1:0.9509133984489019, w2:0.8799534674777437, bias:-0.2574455073227795, loss:0.673001126918237\n",
            "Epoch:107, w1:0.9505804934075383, w2:0.8790687265771281, bias:-0.25951114330461833, loss:0.6724826067294501\n",
            "Epoch:108, w1:0.9502497576992669, w2:0.8781881099365552, bias:-0.2615709328869171, loss:0.671967384535176\n",
            "Epoch:109, w1:0.9499211863775493, w2:0.8773116088490872, bias:-0.2636248898621937, loss:0.6714554415960414\n",
            "Epoch:110, w1:0.9495947744833324, w2:0.8764392145725941, bias:-0.2656730280509446, loss:0.6709467592300818\n",
            "Epoch:111, w1:0.9492705170453044, w2:0.875570918330318, bias:-0.26771536130097806, loss:0.6704413188132258\n",
            "Epoch:112, w1:0.9489484090801491, w2:0.8747067113114348, bias:-0.2697519034867507, loss:0.6699391017797736\n",
            "Epoch:113, w1:0.948628445592799, w2:0.8738465846716147, bias:-0.2717826685087081, loss:0.6694400896228636\n",
            "Epoch:114, w1:0.9483106215766873, w2:0.8729905295335788, bias:-0.2738076702926284, loss:0.6689442638949291\n",
            "Epoch:115, w1:0.9479949320139986, w2:0.8721385369876554, bias:-0.27582692278897025, loss:0.6684516062081444\n",
            "Epoch:116, w1:0.9476813718759184, w2:0.8712905980923322, bias:-0.2778404399722236, loss:0.667962098234863\n",
            "Epoch:117, w1:0.9473699361228811, w2:0.8704467038748073, bias:-0.27984823584026497, loss:0.6674757217080438\n",
            "Epoch:118, w1:0.9470606197048171, w2:0.869606845331537, bias:-0.2818503244137162, loss:0.6669924584216677\n",
            "Epoch:119, w1:0.9467534175613984, w2:0.8687710134287819, bias:-0.28384671973530656, loss:0.666512290231146\n",
            "Epoch:120, w1:0.9464483246222823, w2:0.8679391991031501, bias:-0.28583743586923915, loss:0.6660351990537187\n",
            "Epoch:121, w1:0.9461453358073552, w2:0.8671113932621374, bias:-0.287822486900561, loss:0.6655611668688401\n",
            "Epoch:122, w1:0.9458444460269733, w2:0.866287586784666, bias:-0.2898018869345369, loss:0.6650901757185608\n",
            "Epoch:123, w1:0.9455456501822035, w2:0.8654677705216203, bias:-0.2917756500960272, loss:0.6646222077078935\n",
            "Epoch:124, w1:0.945248943165062, w2:0.8646519352963793, bias:-0.2937437905288693, loss:0.6641572450051755\n",
            "Epoch:125, w1:0.9449543198587519, w2:0.8638400719053474, bias:-0.2957063223952634, loss:0.6636952698424169\n",
            "Epoch:126, w1:0.944661775137899, w2:0.8630321711184819, bias:-0.29766325987516196, loss:0.6632362645156431\n",
            "Epoch:127, w1:0.9443713038687868, w2:0.862228223679818, bias:-0.299614617165663, loss:0.6627802113852259\n",
            "Epoch:128, w1:0.9440829009095899, w2:0.8614282203079913, bias:-0.3015604084804078, loss:0.6623270928762066\n",
            "Epoch:129, w1:0.9437965611106058, w2:0.8606321516967569, bias:-0.3035006480489822, loss:0.6618768914786094\n",
            "Epoch:130, w1:0.9435122793144853, w2:0.8598400085155066, bias:-0.30543535011632184, loss:0.6614295897477466\n",
            "Epoch:131, w1:0.9432300503564616, w2:0.8590517814097824, bias:-0.3073645289421221, loss:0.6609851703045134\n",
            "Epoch:132, w1:0.9429498690645777, w2:0.858267461001788, bias:-0.3092881988002512, loss:0.6605436158356762\n",
            "Epoch:133, w1:0.942671730259913, w2:0.8574870378908965, bias:-0.31120637397816814, loss:0.6601049090941494\n",
            "Epoch:134, w1:0.9423956287568079, w2:0.8567105026541565, bias:-0.3131190687763442, loss:0.6596690328992659\n",
            "Epoch:135, w1:0.9421215593630868, w2:0.8559378458467939, bias:-0.3150262975076888, loss:0.6592359701370373\n",
            "Epoch:136, w1:0.9418495168802798, w2:0.8551690580027116, bias:-0.3169280744969794, loss:0.6588057037604069\n",
            "Epoch:137, w1:0.9415794961038435, w2:0.8544041296349864, bias:-0.31882441408029555, loss:0.6583782167894926\n",
            "Epoch:138, w1:0.9413114918233793, w2:0.8536430512363622, bias:-0.32071533060445706, loss:0.6579534923118231\n",
            "Epoch:139, w1:0.9410454988228509, w2:0.852885813279741, bias:-0.32260083842646636, loss:0.657531513482565\n",
            "Epoch:140, w1:0.9407815118808005, w2:0.8521324062186703, bias:-0.32448095191295484, loss:0.6571122635247414\n",
            "Epoch:141, w1:0.9405195257705623, w2:0.8513828204878275, bias:-0.32635568543963367, loss:0.6566957257294426\n",
            "Epoch:142, w1:0.9402595352604761, w2:0.8506370465035024, bias:-0.3282250533907486, loss:0.6562818834560292\n",
            "Epoch:143, w1:0.9400015351140982, w2:0.8498950746640742, bias:-0.33008907015853894, loss:0.6558707201323265\n",
            "Epoch:144, w1:0.9397455200904113, w2:0.8491568953504885, bias:-0.33194775014270095, loss:0.6554622192548121\n",
            "Epoch:145, w1:0.9394914849440329, w2:0.8484224989267287, bias:-0.33380110774985494, loss:0.6550563643887926\n",
            "Epoch:146, w1:0.9392394244254216, w2:0.8476918757402854, bias:-0.3356491573930172, loss:0.6546531391685767\n",
            "Epoch:147, w1:0.9389893332810829, w2:0.8469650161226226, bias:-0.3374919134910758, loss:0.654252527297639\n",
            "Epoch:148, w1:0.9387412062537724, w2:0.846241910389641, bias:-0.3393293904682707, loss:0.6538545125487737\n",
            "Epoch:149, w1:0.9384950380826984, w2:0.8455225488421373, bias:-0.3411616027536779, loss:0.6534590787642449\n",
            "Epoch:150, w1:0.9382508235037219, w2:0.844806921766261, bias:-0.34298856478069817, loss:0.6530662098559269\n",
            "Epoch:151, w1:0.9380085572495562, w2:0.8440950194339687, bias:-0.34481029098654964, loss:0.6526758898054369\n",
            "Epoch:152, w1:0.9377682340499643, w2:0.8433868321034732, bias:-0.346626795811765, loss:0.6522881026642631\n",
            "Epoch:153, w1:0.9375298486319547, w2:0.8426823500196917, bias:-0.3484380936996926, loss:0.6519028325538807\n",
            "Epoch:154, w1:0.9372933957199757, w2:0.8419815634146893, bias:-0.35024419909600196, loss:0.6515200636658678\n",
            "Epoch:155, w1:0.937058870036109, w2:0.8412844625081198, bias:-0.35204512644819363, loss:0.6511397802620059\n",
            "Epoch:156, w1:0.93682626630026, w2:0.8405910375076633, bias:-0.353840890205113, loss:0.6507619666743817\n",
            "Epoch:157, w1:0.9365955792303483, w2:0.8399012786094603, bias:-0.3556315048164685, loss:0.6503866073054754\n",
            "Epoch:158, w1:0.9363668035424957, w2:0.8392151759985432, bias:-0.35741698473235417, loss:0.6500136866282457\n",
            "Epoch:159, w1:0.9361399339512126, w2:0.838532719849264, bias:-0.3591973444027762, loss:0.6496431891862073\n",
            "Epoch:160, w1:0.9359149651695837, w2:0.8378539003257187, bias:-0.3609725982771838, loss:0.6492750995935022\n",
            "Epoch:161, w1:0.9356918919094509, w2:0.8371787075821688, bias:-0.3627427608040047, loss:0.6489094025349629\n",
            "Epoch:162, w1:0.9354707088815954, w2:0.8365071317634595, bias:-0.36450784643018397, loss:0.6485460827661711\n",
            "Epoch:163, w1:0.9352514107959187, w2:0.8358391630054344, bias:-0.36626786960072805, loss:0.6481851251135077\n",
            "Epoch:164, w1:0.9350339923616204, w2:0.835174791435347, bias:-0.36802284475825237, loss:0.6478265144741999\n",
            "Epoch:165, w1:0.9348184482873768, w2:0.8345140071722694, bias:-0.3697727863425334, loss:0.6474702358163578\n",
            "Epoch:166, w1:0.9346047732815156, w2:0.8338568003274971, bias:-0.3715177087900649, loss:0.6471162741790079\n",
            "Epoch:167, w1:0.9343929620521906, w2:0.8332031610049506, bias:-0.37325762653361827, loss:0.6467646146721203\n",
            "Epoch:168, w1:0.934183009307554, w2:0.8325530793015744, bias:-0.37499255400180725, loss:0.6464152424766272\n",
            "Epoch:169, w1:0.9339749097559282, w2:0.8319065453077317, bias:-0.3767225056186567, loss:0.6460681428444399\n",
            "Epoch:170, w1:0.9337686581059744, w2:0.8312635491075967, bias:-0.37844749580317577, loss:0.6457233010984553\n",
            "Epoch:171, w1:0.9335642490668614, w2:0.8306240807795432, bias:-0.3801675389689347, loss:0.6453807026325605\n",
            "Epoch:172, w1:0.9333616773484315, w2:0.8299881303965302, bias:-0.3818826495236464, loss:0.645040332911628\n",
            "Epoch:173, w1:0.9331609376613655, w2:0.8293556880264836, bias:-0.38359284186875203, loss:0.6447021774715093\n",
            "Epoch:174, w1:0.9329620247173466, w2:0.8287267437326755, bias:-0.38529813039901034, loss:0.64436622191902\n",
            "Epoch:175, w1:0.9327649332292213, w2:0.8281012875740997, bias:-0.3869985295020917, loss:0.6440324519319205\n",
            "Epoch:176, w1:0.9325696579111603, w2:0.8274793096058439, bias:-0.38869405355817577, loss:0.6437008532588903\n",
            "Epoch:177, w1:0.9323761934788173, w2:0.8268607998794588, bias:-0.39038471693955373, loss:0.6433714117194996\n",
            "Epoch:178, w1:0.9321845346494857, w2:0.8262457484433241, bias:-0.3920705340102342, loss:0.6430441132041719\n",
            "Epoch:179, w1:0.9319946761422548, w2:0.8256341453430107, bias:-0.39375151912555345, loss:0.6427189436741446\n",
            "Epoch:180, w1:0.9318066126781637, w2:0.8250259806216405, bias:-0.3954276866317899, loss:0.6423958891614243\n",
            "Epoch:181, w1:0.9316203389803537, w2:0.8244212443202418, bias:-0.3970990508657822, loss:0.6420749357687335\n",
            "Epoch:182, w1:0.93143584977422, w2:0.8238199264781026, bias:-0.39876562615455174, loss:0.641756069669457\n",
            "Epoch:183, w1:0.931253139787561, w2:0.82322201713312, bias:-0.40042742681492927, loss:0.641439277107581\n",
            "Epoch:184, w1:0.9310722037507261, w2:0.8226275063221464, bias:-0.402084467153185, loss:0.6411245443976274\n",
            "Epoch:185, w1:0.9308930363967627, w2:0.8220363840813326, bias:-0.40373676146466353, loss:0.6408118579245846\n",
            "Epoch:186, w1:0.9307156324615611, w2:0.8214486404464678, bias:-0.4053843240334219, loss:0.6405012041438316\n",
            "Epoch:187, w1:0.9305399866839982, w2:0.8208642654533163, bias:-0.4070271691318724, loss:0.6401925695810606\n",
            "Epoch:188, w1:0.9303660938060792, w2:0.8202832491379504, bias:-0.40866531102042897, loss:0.6398859408321911\n",
            "Epoch:189, w1:0.9301939485730787, w2:0.8197055815370812, bias:-0.4102987639471574, loss:0.6395813045632841\n",
            "Epoch:190, w1:0.9300235457336795, w2:0.8191312526883855, bias:-0.41192754214743005, loss:0.6392786475104472\n",
            "Epoch:191, w1:0.9298548800401104, w2:0.8185602526308294, bias:-0.4135516598435838, loss:0.6389779564797404\n",
            "Epoch:192, w1:0.9296879462482822, w2:0.8179925714049893, bias:-0.4151711312445823, loss:0.6386792183470728\n",
            "Epoch:193, w1:0.9295227391179224, w2:0.8174281990533687, bias:-0.4167859705456823, loss:0.6383824200580988\n",
            "Epoch:194, w1:0.9293592534127083, w2:0.8168671256207135, bias:-0.41839619192810323, loss:0.6380875486281082\n",
            "Epoch:195, w1:0.9291974839003994, w2:0.8163093411543224, bias:-0.4200018095587014, loss:0.6377945911419142\n",
            "Epoch:196, w1:0.9290374253529666, w2:0.815754835704355, bias:-0.4216028375896475, loss:0.6375035347537342\n",
            "Epoch:197, w1:0.9288790725467223, w2:0.8152035993241371, bias:-0.4231992901581079, loss:0.6372143666870711\n",
            "Epoch:198, w1:0.9287224202624468, w2:0.814655622070462, bias:-0.4247911813859304, loss:0.6369270742345866\n",
            "Epoch:199, w1:0.9285674632855148, w2:0.8141108940038894, bias:-0.4263785253793329, loss:0.6366416447579734\n",
            "Epoch:200, w1:0.9284141964060197, w2:0.8135694051890404, bias:-0.42796133622859656, loss:0.6363580656878232\n",
            "Epoch:201, w1:0.9282626144188971, w2:0.813031145694891, bias:-0.4295396280077623, loss:0.6360763245234909\n",
            "Epoch:202, w1:0.9281127121240461, w2:0.8124961055950602, bias:-0.4311134147743312, loss:0.6357964088329542\n",
            "Epoch:203, w1:0.9279644843264496, w2:0.8119642749680972, bias:-0.43268271056896856, loss:0.6355183062526725\n",
            "Epoch:204, w1:0.9278179258362935, w2:0.8114356438977641, bias:-0.4342475294152118, loss:0.6352420044874392\n",
            "Epoch:205, w1:0.927673031469084, w2:0.8109102024733162, bias:-0.43580788531918174, loss:0.634967491310233\n",
            "Epoch:206, w1:0.9275297960457635, w2:0.8103879407897794, bias:-0.4373637922692979, loss:0.6346947545620643\n",
            "Epoch:207, w1:0.9273882143928257, w2:0.8098688489482236, bias:-0.4389152642359972, loss:0.6344237821518199\n",
            "Epoch:208, w1:0.9272482813424286, w2:0.8093529170560346, bias:-0.44046231517145634, loss:0.634154562056104\n",
            "Epoch:209, w1:0.9271099917325069, w2:0.8088401352271816, bias:-0.44200495900931785, loss:0.6338870823190738\n",
            "Epoch:210, w1:0.9269733404068816, w2:0.8083304935824823, bias:-0.4435432096644196, loss:0.6336213310522778\n",
            "Epoch:211, w1:0.9268383222153704, w2:0.8078239822498656, bias:-0.44507708103252813, loss:0.6333572964344838\n",
            "Epoch:212, w1:0.9267049320138949, w2:0.8073205913646302, bias:-0.4466065869900751, loss:0.6330949667115101\n",
            "Epoch:213, w1:0.9265731646645873, w2:0.8068203110697008, bias:-0.44813174139389766, loss:0.6328343301960514\n",
            "Epoch:214, w1:0.9264430150358953, w2:0.8063231315158815, bias:-0.44965255808098215, loss:0.6325753752675\n",
            "Epoch:215, w1:0.9263144780026866, w2:0.8058290428621065, bias:-0.4511690508682112, loss:0.6323180903717686\n",
            "Epoch:216, w1:0.9261875484463508, w2:0.805338035275687, bias:-0.4526812335521146, loss:0.6320624640211064\n",
            "Epoch:217, w1:0.9260622212549008, w2:0.804850098932556, bias:-0.45418911990862315, loss:0.6318084847939155\n",
            "Epoch:218, w1:0.9259384913230728, w2:0.8043652240175097, bias:-0.45569272369282643, loss:0.6315561413345626\n",
            "Epoch:219, w1:0.925816353552425, w2:0.8038834007244468, bias:-0.45719205863873347, loss:0.6313054223531894\n",
            "Epoch:220, w1:0.9256958028514343, w2:0.8034046192566041, bias:-0.45868713845903725, loss:0.631056316625521\n",
            "Epoch:221, w1:0.9255768341355932, w2:0.8029288698267898, bias:-0.4601779768448823, loss:0.6308088129926698\n",
            "Epoch:222, w1:0.9254594423275039, w2:0.8024561426576136, bias:-0.46166458746563566, loss:0.6305629003609394\n",
            "Epoch:223, w1:0.9253436223569718, w2:0.8019864279817142, bias:-0.4631469839686611, loss:0.6303185677016253\n",
            "Epoch:224, w1:0.925229369161098, w2:0.8015197160419842, bias:-0.46462517997909697, loss:0.6300758040508135\n",
            "Epoch:225, w1:0.9251166776843701, w2:0.801055997091792, bias:-0.46609918909963677, loss:0.6298345985091754\n",
            "Epoch:226, w1:0.9250055428787519, w2:0.8005952613952007, bias:-0.4675690249103134, loss:0.6295949402417644\n",
            "Epoch:227, w1:0.9248959597037716, w2:0.8001374992271846, bias:-0.4690347009682865, loss:0.629356818477806\n",
            "Epoch:228, w1:0.9247879231266092, w2:0.7996827008738433, bias:-0.47049623080763303, loss:0.6291202225104882\n",
            "Epoch:229, w1:0.9246814281221827, w2:0.7992308566326123, bias:-0.4719536279391409, loss:0.6288851416967511\n",
            "Epoch:230, w1:0.9245764696732326, w2:0.7987819568124711, bias:-0.4734069058501059, loss:0.6286515654570711\n",
            "Epoch:231, w1:0.9244730427704054, w2:0.7983359917341494, bias:-0.47485607800413177, loss:0.6284194832752468\n",
            "Epoch:232, w1:0.9243711424123363, w2:0.7978929517303293, bias:-0.47630115784093313, loss:0.628188884698181\n",
            "Epoch:233, w1:0.9242707636057298, w2:0.7974528271458462, bias:-0.4777421587761421, loss:0.6279597593356614\n",
            "Epoch:234, w1:0.9241719013654401, w2:0.7970156083378862, bias:-0.47917909420111726, loss:0.6277320968601399\n",
            "Epoch:235, w1:0.92407455071455, w2:0.796581285676181, bias:-0.48061197748275614, loss:0.6275058870065106\n",
            "Epoch:236, w1:0.9239787066844479, w2:0.7961498495432008, bias:-0.4820408219633106, loss:0.6272811195718837\n",
            "Epoch:237, w1:0.9238843643149051, w2:0.7957212903343434, bias:-0.4834656409602053, loss:0.6270577844153622\n",
            "Epoch:238, w1:0.9237915186541501, w2:0.795295598458122, bias:-0.48488644776585876, loss:0.6268358714578129\n",
            "Epoch:239, w1:0.9237001647589437, w2:0.7948727643363502, bias:-0.4863032556475082, loss:0.6266153706816389\n",
            "Epoch:240, w1:0.9236102976946515, w2:0.7944527784043234, bias:-0.48771607784703636, loss:0.626396272130547\n",
            "Epoch:241, w1:0.9235219125353159, w2:0.794035631110999, bias:-0.48912492758080195, loss:0.6261785659093199\n",
            "Epoch:242, w1:0.9234350043637268, w2:0.7936213129191735, bias:-0.49052981803947254, loss:0.6259622421835801\n",
            "Epoch:243, w1:0.9233495682714913, w2:0.7932098143056573, bias:-0.49193076238786076, loss:0.6257472911795565\n",
            "Epoch:244, w1:0.9232655993591022, w2:0.7928011257614465, bias:-0.49332777376476283, loss:0.6255337031838502\n",
            "Epoch:245, w1:0.9231830927360056, w2:0.792395237791893, bias:-0.4947208652828004, loss:0.6253214685431951\n",
            "Epoch:246, w1:0.9231020435206668, w2:0.7919921409168721, bias:-0.4961100500282649, loss:0.625110577664224\n",
            "Epoch:247, w1:0.9230224468406363, w2:0.7915918256709465, bias:-0.49749534106096477, loss:0.6249010210132245\n",
            "Epoch:248, w1:0.9229442978326131, w2:0.79119428260353, bias:-0.4988767514140754, loss:0.6246927891159039\n",
            "Epoch:249, w1:0.9228675916425086, w2:0.7907995022790466, bias:-0.5002542940939919, loss:0.6244858725571442\n",
            "Epoch:250, w1:0.9227923234255084, w2:0.7904074752770889, bias:-0.5016279820801846, loss:0.6242802619807626\n",
            "Epoch:251, w1:0.922718488346133, w2:0.7900181921925733, bias:-0.5029978283250568, loss:0.6240759480892661\n",
            "Epoch:252, w1:0.9226460815782983, w2:0.7896316436358931, bias:-0.5043638457538061, loss:0.6238729216436097\n",
            "Epoch:253, w1:0.9225750983053741, w2:0.7892478202330692, bias:-0.5057260472642876, loss:0.6236711734629493\n",
            "Epoch:254, w1:0.9225055337202422, w2:0.7888667126258986, bias:-0.5070844457268798, loss:0.6234706944243972\n",
            "Epoch:255, w1:0.9224373830253535, w2:0.7884883114721007, bias:-0.5084390539843536, loss:0.6232714754627747\n",
            "Epoch:256, w1:0.9223706414327834, w2:0.7881126074454613, bias:-0.5097898848517433, loss:0.6230735075703655\n",
            "Epoch:257, w1:0.9223053041642871, w2:0.7877395912359737, bias:-0.5111369511162204, loss:0.6228767817966664\n",
            "Epoch:258, w1:0.9222413664513537, w2:0.7873692535499789, bias:-0.5124802655369703, loss:0.6226812892481388\n",
            "Epoch:259, w1:0.9221788235352582, w2:0.7870015851103024, bias:-0.5138198408450708, loss:0.6224870210879602\n",
            "Epoch:260, w1:0.9221176706671143, w2:0.7866365766563892, bias:-0.5151556897433737, loss:0.6222939685357715\n",
            "Epoch:261, w1:0.9220579031079251, w2:0.7862742189444368, bias:-0.5164878249063883, loss:0.6221021228674287\n",
            "Epoch:262, w1:0.9219995161286331, w2:0.7859145027475262, bias:-0.5178162589801683, loss:0.6219114754147502\n",
            "Epoch:263, w1:0.9219425050101691, w2:0.7855574188557496, bias:-0.5191410045821997, loss:0.6217220175652645\n",
            "Epoch:264, w1:0.9218868650435005, w2:0.7852029580763377, bias:-0.5204620743012928, loss:0.6215337407619591\n",
            "Epoch:265, w1:0.9218325915296784, w2:0.7848511112337835, bias:-0.5217794806974752, loss:0.6213466365030258\n",
            "Epoch:266, w1:0.921779679779884, w2:0.7845018691699647, bias:-0.5230932363018875, loss:0.6211606963416082\n",
            "Epoch:267, w1:0.9217281251154734, w2:0.7841552227442639, bias:-0.5244033536166822, loss:0.6209759118855481\n",
            "Epoch:268, w1:0.9216779228680227, w2:0.7838111628336862, bias:-0.5257098451149237, loss:0.6207922747971311\n",
            "Epoch:269, w1:0.9216290683793711, w2:0.7834696803329763, bias:-0.5270127232404911, loss:0.6206097767928315\n",
            "Epoch:270, w1:0.9215815570016634, w2:0.783130766154731, bias:-0.5283120004079837, loss:0.6204284096430579\n",
            "Epoch:271, w1:0.9215353840973923, w2:0.7827944112295125, bias:-0.529607689002628, loss:0.6202481651718984\n",
            "Epoch:272, w1:0.9214905450394385, w2:0.782460606505958, bias:-0.5308998013801877, loss:0.620069035256864\n",
            "Epoch:273, w1:0.9214470352111109, w2:0.7821293429508873, bias:-0.5321883498668752, loss:0.6198910118286336\n",
            "Epoch:274, w1:0.9214048500061862, w2:0.7818006115494095, bias:-0.5334733467592659, loss:0.6197140868707988\n",
            "Epoch:275, w1:0.9213639848289464, w2:0.7814744033050267, bias:-0.5347548043242142, loss:0.6195382524196061\n",
            "Epoch:276, w1:0.9213244350942167, w2:0.7811507092397365, bias:-0.5360327347987718, loss:0.6193635005637025\n",
            "Epoch:277, w1:0.9212861962274018, w2:0.7808295203941319, bias:-0.5373071503901083, loss:0.6191898234438772\n",
            "Epoch:278, w1:0.9212492636645218, w2:0.7805108278275003, bias:-0.538578063275434, loss:0.6190172132528073\n",
            "Epoch:279, w1:0.9212136328522466, w2:0.7801946226179192, bias:-0.5398454856019242, loss:0.6188456622347993\n",
            "Epoch:280, w1:0.9211792992479308, w2:0.7798808958623518, bias:-0.5411094294866462, loss:0.6186751626855336\n",
            "Epoch:281, w1:0.9211462583196464, w2:0.7795696386767391, bias:-0.542369907016488, loss:0.6185057069518076\n",
            "Epoch:282, w1:0.9211145055462151, w2:0.7792608421960913, bias:-0.5436269302480892, loss:0.618337287431279\n",
            "Epoch:283, w1:0.9210840364172405, w2:0.7789544975745766, bias:-0.5448805112077738, loss:0.618169896572209\n",
            "Epoch:284, w1:0.9210548464331385, w2:0.778650595985609, bias:-0.5461306618914852, loss:0.6180035268732064\n",
            "Epoch:285, w1:0.9210269311051678, w2:0.778349128621934, bias:-0.5473773942647226, loss:0.61783817088297\n",
            "Epoch:286, w1:0.9210002859554586, w2:0.7780500866957116, bias:-0.5486207202624804, loss:0.6176738212000338\n",
            "Epoch:287, w1:0.9209749065170418, w2:0.7777534614385995, bias:-0.5498606517891882, loss:0.617510470472509\n",
            "Epoch:288, w1:0.9209507883338767, w2:0.7774592441018326, bias:-0.5510972007186539, loss:0.6173481113978287\n",
            "Epoch:289, w1:0.9209279269608773, w2:0.7771674259563025, bias:-0.5523303788940078, loss:0.617186736722492\n",
            "Epoch:290, w1:0.9209063179639397, w2:0.7768779982926337, bias:-0.5535601981276493, loss:0.617026339241808\n",
            "Epoch:291, w1:0.920885956919967, w2:0.7765909524212591, bias:-0.554786670201195, loss:0.6168669117996403\n",
            "Epoch:292, w1:0.920866839416894, w2:0.776306279672494, bias:-0.5560098068654286, loss:0.6167084472881513\n",
            "Epoch:293, w1:0.9208489610537117, w2:0.7760239713966075, bias:-0.5572296198402528, loss:0.6165509386475465\n",
            "Epoch:294, w1:0.9208323174404907, w2:0.7757440189638933, bias:-0.5584461208146432, loss:0.6163943788658224\n",
            "Epoch:295, w1:0.9208169041984035, w2:0.7754664137647382, bias:-0.5596593214466032, loss:0.6162387609785077\n",
            "Epoch:296, w1:0.9208027169597468, w2:0.7751911472096892, bias:-0.560869233363122, loss:0.6160840780684124\n",
            "Epoch:297, w1:0.9207897513679628, w2:0.774918210729519, bias:-0.5620758681601326, loss:0.6159303232653718\n",
            "Epoch:298, w1:0.9207780030776597, w2:0.7746475957752903, bias:-0.5632792374024728, loss:0.6157774897459941\n",
            "Epoch:299, w1:0.9207674677546314, w2:0.7743792938184174, bias:-0.5644793526238479, loss:0.6156255707334066\n",
            "Epoch:300, w1:0.9207581410758773, w2:0.7741132963507281, bias:-0.5656762253267942, loss:0.6154745594970022\n",
            "Epoch:301, w1:0.9207500187296206, w2:0.7738495948845222, bias:-0.566869866982645, loss:0.6153244493521884\n",
            "Epoch:302, w1:0.920743096415326, w2:0.7735881809526296, bias:-0.5680602890314976, loss:0.6151752336601332\n",
            "Epoch:303, w1:0.9207373698437175, w2:0.7733290461084668, bias:-0.5692475028821828, loss:0.6150269058275153\n",
            "Epoch:304, w1:0.9207328347367943, w2:0.7730721819260913, bias:-0.5704315199122347, loss:0.6148794593062707\n",
            "Epoch:305, w1:0.9207294868278477, w2:0.7728175800002555, bias:-0.5716123514678636, loss:0.6147328875933449\n",
            "Epoch:306, w1:0.9207273218614759, w2:0.7725652319464581, bias:-0.5727900088639291, loss:0.6145871842304393\n",
            "Epoch:307, w1:0.9207263355935986, w2:0.7723151294009951, bias:-0.5739645033839157, loss:0.6144423428037638\n",
            "Epoch:308, w1:0.9207265237914717, w2:0.7720672640210084, bias:-0.5751358462799098, loss:0.6142983569437853\n",
            "Epoch:309, w1:0.9207278822337004, w2:0.7718216274845339, bias:-0.5763040487725775, loss:0.6141552203249818\n",
            "Epoch:310, w1:0.9207304067102521, w2:0.7715782114905471, bias:-0.577469122051145, loss:0.6140129266655913\n",
            "Epoch:311, w1:0.920734093022469, w2:0.7713370077590087, bias:-0.5786310772733795, loss:0.6138714697273648\n",
            "Epoch:312, w1:0.9207389369830796, w2:0.7710980080309078, bias:-0.5797899255655723, loss:0.61373084331532\n",
            "Epoch:313, w1:0.92074493441621, w2:0.7708612040683037, bias:-0.5809456780225228, loss:0.6135910412774945\n",
            "Epoch:314, w1:0.920752081157394, w2:0.7706265876543676, bias:-0.5820983457075244, loss:0.6134520575046986\n",
            "Epoch:315, w1:0.920760373053584, w2:0.7703941505934214, bias:-0.5832479396523513, loss:0.6133138859302708\n",
            "Epoch:316, w1:0.9207698059631595, w2:0.770163884710976, bias:-0.5843944708572474, loss:0.6131765205298335\n",
            "Epoch:317, w1:0.9207803757559363, w2:0.7699357818537682, bias:-0.5855379502909157, loss:0.6130399553210467\n",
            "Epoch:318, w1:0.9207920783131752, w2:0.7697098338897969, bias:-0.58667838889051, loss:0.6129041843633675\n",
            "Epoch:319, w1:0.9208049095275892, w2:0.7694860327083565, bias:-0.5878157975616274, loss:0.6127692017578039\n",
            "Epoch:320, w1:0.920818865303351, w2:0.7692643702200708, bias:-0.5889501871783019, loss:0.612635001646676\n",
            "Epoch:321, w1:0.9208339415560997, w2:0.7690448383569243, bias:-0.5900815685830001, loss:0.6125015782133709\n",
            "Epoch:322, w1:0.9208501342129468, w2:0.7688274290722933, bias:-0.5912099525866175, loss:0.6123689256821037\n",
            "Epoch:323, w1:0.9208674392124823, w2:0.7686121343409751, bias:-0.5923353499684764, loss:0.6122370383176783\n",
            "Epoch:324, w1:0.9208858525047791, w2:0.7683989461592162, bias:-0.5934577714763251, loss:0.6121059104252451\n",
            "Epoch:325, w1:0.9209053700513982, w2:0.7681878565447394, bias:-0.5945772278263383, loss:0.6119755363500645\n",
            "Epoch:326, w1:0.9209259878253928, w2:0.7679788575367698, bias:-0.5956937297031184, loss:0.6118459104772683\n",
            "Epoch:327, w1:0.9209477018113116, w2:0.767771941196059, bias:-0.5968072877596988, loss:0.6117170272316209\n",
            "Epoch:328, w1:0.9209705080052021, w2:0.7675670996049094, bias:-0.5979179126175478, loss:0.6115888810772852\n",
            "Epoch:329, w1:0.9209944024146133, w2:0.7673643248671963, bias:-0.5990256148665735, loss:0.6114614665175844\n",
            "Epoch:330, w1:0.9210193810585978, w2:0.7671636091083889, bias:-0.6001304050651307, loss:0.6113347780947685\n",
            "Epoch:331, w1:0.9210454399677135, w2:0.7669649444755708, bias:-0.6012322937400285, loss:0.6112088103897787\n",
            "Epoch:332, w1:0.9210725751840247, w2:0.7667683231374595, bias:-0.6023312913865385, loss:0.6110835580220153\n",
            "Epoch:333, w1:0.9211007827611033, w2:0.7665737372844234, bias:-0.6034274084684054, loss:0.6109590156491037\n",
            "Epoch:334, w1:0.9211300587640283, w2:0.7663811791284997, bias:-0.6045206554178573, loss:0.610835177966663\n",
            "Epoch:335, w1:0.9211603992693865, w2:0.7661906409034099, bias:-0.6056110426356185, loss:0.6107120397080736\n",
            "Epoch:336, w1:0.9211918003652715, w2:0.7660021148645748, bias:-0.6066985804909221, loss:0.6105895956442497\n",
            "Epoch:337, w1:0.9212242581512824, w2:0.765815593289128, bias:-0.6077832793215246, loss:0.6104678405834063\n",
            "Epoch:338, w1:0.9212577687385229, w2:0.7656310684759289, bias:-0.6088651494337215, loss:0.6103467693708331\n",
            "Epoch:339, w1:0.9212923282495992, w2:0.7654485327455747, bias:-0.6099442011023629, loss:0.6102263768886648\n",
            "Epoch:340, w1:0.9213279328186171, w2:0.7652679784404108, bias:-0.6110204445708718, loss:0.6101066580556549\n",
            "Epoch:341, w1:0.9213645785911803, w2:0.7650893979245409, bias:-0.6120938900512618, loss:0.6099876078269498\n",
            "Epoch:342, w1:0.9214022617243863, w2:0.7649127835838353, bias:-0.6131645477241573, loss:0.6098692211938624\n",
            "Epoch:343, w1:0.9214409783868235, w2:0.7647381278259396, bias:-0.6142324277388134, loss:0.6097514931836483\n",
            "Epoch:344, w1:0.9214807247585668, w2:0.764565423080281, bias:-0.6152975402131374, loss:0.6096344188592818\n",
            "Epoch:345, w1:0.9215214970311734, w2:0.7643946617980742, bias:-0.6163598952337117, loss:0.6095179933192333\n",
            "Epoch:346, w1:0.9215632914076779, w2:0.7642258364523271, bias:-0.6174195028558164, loss:0.6094022116972468\n",
            "Epoch:347, w1:0.9216061041025875, w2:0.7640589395378441, bias:-0.6184763731034542, loss:0.6092870691621202\n",
            "Epoch:348, w1:0.9216499313418761, w2:0.7638939635712299, bias:-0.6195305159693754, loss:0.6091725609174833\n",
            "Epoch:349, w1:0.9216947693629786, w2:0.7637309010908915, bias:-0.620581941415104, loss:0.6090586822015797\n",
            "Epoch:350, w1:0.9217406144147844, w2:0.7635697446570401, bias:-0.6216306593709651, loss:0.608945428287048\n",
            "Epoch:351, w1:0.9217874627576311, w2:0.7634104868516909, bias:-0.6226766797361122, loss:0.6088327944807048\n",
            "Epoch:352, w1:0.9218353106632972, w2:0.7632531202786637, bias:-0.6237200123785567, loss:0.6087207761233268\n",
            "Epoch:353, w1:0.9218841544149946, w2:0.7630976375635808, bias:-0.6247606671351971, loss:0.6086093685894366\n",
            "Epoch:354, w1:0.9219339903073613, w2:0.7629440313538661, bias:-0.6257986538118498, loss:0.6084985672870868\n",
            "Epoch:355, w1:0.9219848146464533, w2:0.7627922943187414, bias:-0.6268339821832805, loss:0.6083883676576471\n",
            "Epoch:356, w1:0.9220366237497356, w2:0.762642419149223, bias:-0.6278666619932362, loss:0.6082787651755899\n",
            "Epoch:357, w1:0.9220894139460741, w2:0.7624943985581176, bias:-0.6288967029544783, loss:0.6081697553482793\n",
            "Epoch:358, w1:0.9221431815757262, w2:0.7623482252800167, bias:-0.6299241147488167, loss:0.6080613337157603\n",
            "Epoch:359, w1:0.9221979229903312, w2:0.7622038920712905, bias:-0.6309489070271441, loss:0.6079534958505476\n",
            "Epoch:360, w1:0.9222536345529012, w2:0.7620613917100816, bias:-0.6319710894094714, loss:0.6078462373574164\n",
            "Epoch:361, w1:0.9223103126378104, w2:0.761920716996297, bias:-0.6329906714849644, loss:0.607739553873195\n",
            "Epoch:362, w1:0.9223679536307849, w2:0.7617818607515999, bias:-0.6340076628119798, loss:0.6076334410665563\n",
            "Epoch:363, w1:0.9224265539288922, w2:0.7616448158194005, bias:-0.635022072918104, loss:0.6075278946378114\n",
            "Epoch:364, w1:0.9224861099405298, w2:0.7615095750648462, bias:-0.6360339113001905, loss:0.6074229103187053\n",
            "Epoch:365, w1:0.9225466180854144, w2:0.7613761313748115, bias:-0.6370431874243998, loss:0.6073184838722105\n",
            "Epoch:366, w1:0.9226080747945697, w2:0.7612444776578862, bias:-0.6380499107262388, loss:0.6072146110923252\n",
            "Epoch:367, w1:0.9226704765103153, w2:0.7611146068443635, bias:-0.6390540906106018, loss:0.6071112878038677\n",
            "Epoch:368, w1:0.9227338196862537, w2:0.7609865118862277, bias:-0.6400557364518111, loss:0.6070085098622792\n",
            "Epoch:369, w1:0.9227981007872581, w2:0.7608601857571403, bias:-0.6410548575936597, loss:0.6069062731534178\n",
            "Epoch:370, w1:0.9228633162894601, w2:0.7607356214524267, bias:-0.6420514633494532, loss:0.6068045735933625\n",
            "Epoch:371, w1:0.922929462680236, w2:0.7606128119890605, bias:-0.6430455630020537, loss:0.6067034071282124\n",
            "Epoch:372, w1:0.9229965364581939, w2:0.7604917504056491, bias:-0.6440371658039235, loss:0.6066027697338892\n",
            "Epoch:373, w1:0.9230645341331599, w2:0.7603724297624171, bias:-0.6450262809771692, loss:0.6065026574159401\n",
            "Epoch:374, w1:0.9231334522261644, w2:0.76025484314119, bias:-0.6460129177135877, loss:0.6064030662093421\n",
            "Epoch:375, w1:0.923203287269428, w2:0.7601389836453761, bias:-0.6469970851747114, loss:0.6063039921783062\n",
            "Epoch:376, w1:0.923274035806347, w2:0.7600248443999499, bias:-0.6479787924918549, loss:0.6062054314160842\n",
            "Epoch:377, w1:0.9233456943914792, w2:0.7599124185514323, bias:-0.6489580487661617, loss:0.6061073800447739\n",
            "Epoch:378, w1:0.9234182595905281, w2:0.7598016992678722, bias:-0.6499348630686524, loss:0.6060098342151291\n",
            "Epoch:379, w1:0.9234917279803291, w2:0.7596926797388264, bias:-0.6509092444402724, loss:0.6059127901063665\n",
            "Epoch:380, w1:0.923566096148833, w2:0.7595853531753393, bias:-0.6518812018919405, loss:0.605816243925976\n",
            "Epoch:381, w1:0.9236413606950911, w2:0.759479712809922, bias:-0.652850744404599, loss:0.6057201919095314\n",
            "Epoch:382, w1:0.9237175182292389, w2:0.7593757518965312, bias:-0.6538178809292626, loss:0.6056246303205022\n",
            "Epoch:383, w1:0.9237945653724805, w2:0.7592734637105463, bias:-0.6547826203870697, loss:0.6055295554500657\n",
            "Epoch:384, w1:0.923872498757072, w2:0.7591728415487474, bias:-0.6557449716693325, loss:0.6054349636169207\n",
            "Epoch:385, w1:0.9239513150263052, w2:0.7590738787292921, bias:-0.6567049436375892, loss:0.605340851167102\n",
            "Epoch:386, w1:0.9240310108344908, w2:0.7589765685916914, bias:-0.6576625451236556, loss:0.6052472144737959\n",
            "Epoch:387, w1:0.9241115828469412, w2:0.7588809044967858, bias:-0.6586177849296777, loss:0.6051540499371565\n",
            "Epoch:388, w1:0.9241930277399537, w2:0.7587868798267204, bias:-0.6595706718281844, loss:0.6050613539841236\n",
            "Epoch:389, w1:0.9242753422007931, w2:0.7586944879849197, bias:-0.6605212145621415, loss:0.6049691230682398\n",
            "Epoch:390, w1:0.924358522927674, w2:0.7586037223960614, bias:-0.6614694218450051, loss:0.6048773536694709\n",
            "Epoch:391, w1:0.9244425666297428, w2:0.7585145765060508, bias:-0.6624153023607765, loss:0.6047860422940258\n",
            "Epoch:392, w1:0.9245274700270604, w2:0.7584270437819933, bias:-0.6633588647640567, loss:0.6046951854741776\n",
            "Epoch:393, w1:0.9246132298505834, w2:0.7583411177121675, bias:-0.6643001176801019, loss:0.6046047797680852\n",
            "Epoch:394, w1:0.9246998428421459, w2:0.7582567918059974, bias:-0.6652390697048793, loss:0.6045148217596181\n",
            "Epoch:395, w1:0.9247873057544411, w2:0.7581740595940238, bias:-0.6661757294051234, loss:0.6044253080581784\n",
            "Epoch:396, w1:0.9248756153510026, w2:0.7580929146278764, bias:-0.6671101053183921, loss:0.6043362352985274\n",
            "Epoch:397, w1:0.9249647684061851, w2:0.7580133504802437, bias:-0.6680422059531246, loss:0.6042476001406101\n",
            "Epoch:398, w1:0.9250547617051459, w2:0.7579353607448438, bias:-0.6689720397886982, loss:0.6041593992693838\n",
            "Epoch:399, w1:0.9251455920438248, w2:0.7578589390363947, bias:-0.6698996152754866, loss:0.6040716293946445\n",
            "Epoch:400, w1:0.9252372562289256, w2:0.7577840789905832, bias:-0.6708249408349178, loss:0.603984287250857\n",
            "Epoch:401, w1:0.9253297510778957, w2:0.7577107742640342, bias:-0.6717480248595332, loss:0.6038973695969828\n",
            "Epoch:402, w1:0.9254230734189068, w2:0.7576390185342796, bias:-0.6726688757130462, loss:0.6038108732163127\n",
            "Epoch:403, w1:0.9255172200908347, w2:0.7575688054997262, bias:-0.673587501730402, loss:0.6037247949162977\n",
            "Epoch:404, w1:0.9256121879432393, w2:0.7575001288796235, bias:-0.6745039112178373, loss:0.6036391315283814\n",
            "Epoch:405, w1:0.9257079738363443, w2:0.7574329824140315, bias:-0.6754181124529398, loss:0.6035538799078342\n",
            "Epoch:406, w1:0.9258045746410167, w2:0.7573673598637873, bias:-0.6763301136847099, loss:0.603469036933586\n",
            "Epoch:407, w1:0.9259019872387465, w2:0.7573032550104724, bias:-0.6772399231336205, loss:0.6033845995080641\n",
            "Epoch:408, w1:0.9260002085216256, w2:0.757240661656378, bias:-0.6781475489916787, loss:0.6033005645570274\n",
            "Epoch:409, w1:0.9260992353923271, w2:0.7571795736244719, bias:-0.6790529994224872, loss:0.6032169290294056\n",
            "Epoch:410, w1:0.9261990647640844, w2:0.757119984758363, bias:-0.6799562825613059, loss:0.6031336898971357\n",
            "Epoch:411, w1:0.9262996935606699, w2:0.7570618889222673, bias:-0.6808574065151145, loss:0.6030508441550014\n",
            "Epoch:412, w1:0.9264011187163735, w2:0.7570052800009726, bias:-0.6817563793626744, loss:0.6029683888204743\n",
            "Epoch:413, w1:0.9265033371759819, w2:0.7569501518998021, bias:-0.6826532091545918, loss:0.602886320933554\n",
            "Epoch:414, w1:0.926606345894756, w2:0.7568964985445796, bias:-0.6835479039133807, loss:0.6028046375566093\n",
            "Epoch:415, w1:0.92671014183841, w2:0.7568443138815929, bias:-0.6844404716335263, loss:0.602723335774223\n",
            "Epoch:416, w1:0.9268147219830895, w2:0.7567935918775567, bias:-0.6853309202815483, loss:0.6026424126930338\n",
            "Epoch:417, w1:0.9269200833153489, w2:0.7567443265195763, bias:-0.6862192577960652, loss:0.6025618654415814\n",
            "Epoch:418, w1:0.9270262228321303, w2:0.7566965118151104, bias:-0.6871054920878582, loss:0.602481691170153\n",
            "Epoch:419, w1:0.9271331375407406, w2:0.7566501417919331, bias:-0.6879896310399357, loss:0.6024018870506286\n",
            "Epoch:420, w1:0.9272408244588293, w2:0.7566052104980966, bias:-0.688871682507598, loss:0.6023224502763285\n",
            "Epoch:421, w1:0.9273492806143664, w2:0.7565617120018925, bias:-0.6897516543185022, loss:0.6022433780618629\n",
            "Epoch:422, w1:0.9274585030456196, w2:0.756519640391814, bias:-0.6906295542727272, loss:0.6021646676429789\n",
            "Epoch:423, w1:0.9275684888011317, w2:0.7564789897765165, bias:-0.6915053901428395, loss:0.6020863162764131\n",
            "Epoch:424, w1:0.927679234939698, w2:0.7564397542847792, bias:-0.6923791696739586, loss:0.6020083212397402\n",
            "Epoch:425, w1:0.927790738530343, w2:0.7564019280654652, bias:-0.6932509005838229, loss:0.6019306798312261\n",
            "Epoch:426, w1:0.927902996652298, w2:0.7563655052874827, bias:-0.6941205905628556, loss:0.6018533893696812\n",
            "Epoch:427, w1:0.9280160063949778, w2:0.7563304801397442, bias:-0.6949882472742313, loss:0.601776447194313\n",
            "Epoch:428, w1:0.9281297648579575, w2:0.7562968468311272, bias:-0.6958538783539424, loss:0.6016998506645809\n",
            "Epoch:429, w1:0.9282442691509492, w2:0.7562645995904331, bias:-0.6967174914108659, loss:0.6016235971600518\n",
            "Epoch:430, w1:0.9283595163937788, w2:0.7562337326663475, bias:-0.69757909402683, loss:0.6015476840802564\n",
            "Epoch:431, w1:0.9284755037163626, w2:0.7562042403273985, bias:-0.6984386937566817, loss:0.6014721088445466\n",
            "Epoch:432, w1:0.9285922282586836, w2:0.7561761168619159, bias:-0.6992962981283535, loss:0.6013968688919532\n",
            "Epoch:433, w1:0.928709687170768, w2:0.7561493565779898, bias:-0.7001519146429314, loss:0.6013219616810445\n",
            "Epoch:434, w1:0.9288278776126614, w2:0.7561239538034291, bias:-0.7010055507747223, loss:0.6012473846897873\n",
            "Epoch:435, w1:0.9289467967544052, w2:0.7560999028857196, bias:-0.7018572139713216, loss:0.6011731354154061\n",
            "Epoch:436, w1:0.9290664417760125, w2:0.7560771981919818, bias:-0.7027069116536818, loss:0.6010992113742458\n",
            "Epoch:437, w1:0.9291868098674445, w2:0.7560558341089291, bias:-0.70355465121618, loss:0.6010256101016336\n",
            "Epoch:438, w1:0.9293078982285861, w2:0.7560358050428246, bias:-0.7044004400266863, loss:0.6009523291517417\n",
            "Epoch:439, w1:0.9294297040692219, w2:0.7560171054194391, bias:-0.7052442854266329, loss:0.6008793660974526\n",
            "Epoch:440, w1:0.9295522246090124, w2:0.7559997296840077, bias:-0.7060861947310816, loss:0.6008067185302234\n",
            "Epoch:441, w1:0.9296754570774695, w2:0.755983672301187, bias:-0.7069261752287934, loss:0.600734384059951\n",
            "Epoch:442, w1:0.9297993987139318, w2:0.7559689277550117, bias:-0.7077642341822972, loss:0.6006623603148399\n",
            "Epoch:443, w1:0.9299240467675409, w2:0.7559554905488509, bias:-0.7086003788279582, loss:0.6005906449412685\n",
            "Epoch:444, w1:0.9300493984972168, w2:0.755943355205365, bias:-0.7094346163760481, loss:0.6005192356036585\n",
            "Epoch:445, w1:0.9301754511716331, w2:0.7559325162664611, bias:-0.7102669540108133, loss:0.6004481299843432\n",
            "Epoch:446, w1:0.9303022020691928, w2:0.7559229682932493, bias:-0.7110973988905447, loss:0.6003773257834374\n",
            "Epoch:447, w1:0.9304296484780034, w2:0.7559147058659988, bias:-0.7119259581476473, loss:0.6003068207187099\n",
            "Epoch:448, w1:0.9305577876958523, w2:0.755907723584093, bias:-0.7127526388887094, loss:0.6002366125254522\n",
            "Epoch:449, w1:0.9306866170301824, w2:0.755902016065985, bias:-0.7135774481945729, loss:0.6001666989563537\n",
            "Epoch:450, w1:0.9308161337980669, w2:0.7558975779491531, bias:-0.7144003931204023, loss:0.6000970777813728\n",
            "Epoch:451, w1:0.9309463353261846, w2:0.7558944038900561, bias:-0.715221480695755, loss:0.6000277467876126\n",
            "Epoch:452, w1:0.9310772189507951, w2:0.7558924885640876, bias:-0.7160407179246513, loss:0.5999587037791951\n",
            "Epoch:453, w1:0.9312087820177136, w2:0.7558918266655315, bias:-0.7168581117856443, loss:0.5998899465771367\n",
            "Epoch:454, w1:0.9313410218822865, w2:0.755892412907516, bias:-0.7176736692318901, loss:0.5998214730192244\n",
            "Epoch:455, w1:0.9314739359093658, w2:0.7558942420219689, bias:-0.718487397191218, loss:0.5997532809598941\n",
            "Epoch:456, w1:0.9316075214732843, w2:0.7558973087595714, bias:-0.7192993025662007, loss:0.5996853682701082\n",
            "Epoch:457, w1:0.9317417759578304, w2:0.7559016078897126, bias:-0.7201093922342247, loss:0.599617732837234\n",
            "Epoch:458, w1:0.931876696756223, w2:0.7559071342004436, bias:-0.7209176730475607, loss:0.5995503725649237\n",
            "Epoch:459, w1:0.9320122812710865, w2:0.7559138824984314, bias:-0.7217241518334342, loss:0.5994832853729949\n",
            "Epoch:460, w1:0.9321485269144251, w2:0.7559218476089127, bias:-0.7225288353940957, loss:0.5994164691973117\n",
            "Epoch:461, w1:0.932285431107598, w2:0.7559310243756479, bias:-0.7233317305068917, loss:0.5993499219896673\n",
            "Epoch:462, w1:0.932422991281294, w2:0.7559414076608745, bias:-0.7241328439243351, loss:0.5992836417176653\n",
            "Epoch:463, w1:0.9325612048755061, w2:0.7559529923452609, bias:-0.7249321823741758, loss:0.5992176263646048\n",
            "Epoch:464, w1:0.932700069339506, w2:0.7559657733278594, bias:-0.7257297525594716, loss:0.599151873929364\n",
            "Epoch:465, w1:0.9328395821318192, w2:0.7559797455260598, bias:-0.726525561158659, loss:0.5990863824262848\n",
            "Epoch:466, w1:0.932979740720199, w2:0.7559949038755427, bias:-0.7273196148256237, loss:0.5990211498850595\n",
            "Epoch:467, w1:0.9331205425816015, w2:0.756011243330232, bias:-0.7281119201897719, loss:0.5989561743506171\n",
            "Epoch:468, w1:0.93326198520216, w2:0.7560287588622485, bias:-0.7289024838561006, loss:0.5988914538830106\n",
            "Epoch:469, w1:0.9334040660771593, w2:0.7560474454618628, bias:-0.7296913124052689, loss:0.5988269865573044\n",
            "Epoch:470, w1:0.9335467827110108, w2:0.7560672981374476, bias:-0.7304784123936686, loss:0.5987627704634647\n",
            "Epoch:471, w1:0.9336901326172261, w2:0.756088311915431, bias:-0.7312637903534956, loss:0.5986988037062472\n",
            "Epoch:472, w1:0.9338341133183923, w2:0.756110481840249, bias:-0.7320474527928204, loss:0.5986350844050887\n",
            "Epoch:473, w1:0.9339787223461458, w2:0.7561338029742977, bias:-0.732829406195659, loss:0.5985716106939979\n",
            "Epoch:474, w1:0.9341239572411472, w2:0.7561582703978861, bias:-0.7336096570220442, loss:0.5985083807214463\n",
            "Epoch:475, w1:0.9342698155530552, w2:0.7561838792091886, bias:-0.7343882117080964, loss:0.5984453926502628\n",
            "Epoch:476, w1:0.9344162948405016, w2:0.7562106245241974, bias:-0.7351650766660947, loss:0.5983826446575239\n",
            "Epoch:477, w1:0.9345633926710651, w2:0.7562385014766742, bias:-0.7359402582845473, loss:0.5983201349344499\n",
            "Epoch:478, w1:0.9347111066212461, w2:0.756267505218103, bias:-0.7367137629282634, loss:0.5982578616862991\n",
            "Epoch:479, w1:0.9348594342764407, w2:0.7562976309176422, bias:-0.7374855969384233, loss:0.598195823132263\n",
            "Epoch:480, w1:0.9350083732309152, w2:0.7563288737620764, bias:-0.7382557666326498, loss:0.5981340175053617\n",
            "Epoch:481, w1:0.9351579210877807, w2:0.7563612289557684, bias:-0.7390242783050791, loss:0.5980724430523416\n",
            "Epoch:482, w1:0.935308075458967, w2:0.7563946917206117, bias:-0.7397911382264315, loss:0.5980110980335728\n",
            "Epoch:483, w1:0.935458833965197, w2:0.7564292572959819, bias:-0.7405563526440825, loss:0.5979499807229467\n",
            "Epoch:484, w1:0.9356101942359615, w2:0.7564649209386887, bias:-0.7413199277821337, loss:0.5978890894077751\n",
            "Epoch:485, w1:0.9357621539094927, w2:0.7565016779229278, bias:-0.7420818698414835, loss:0.59782842238869\n",
            "Epoch:486, w1:0.9359147106327392, w2:0.7565395235402328, bias:-0.7428421849998981, loss:0.5977679779795438\n",
            "Epoch:487, w1:0.9360678620613402, w2:0.7565784530994268, bias:-0.7436008794120819, loss:0.59770775450731\n",
            "Epoch:488, w1:0.9362216058595993, w2:0.7566184619265741, bias:-0.7443579592097489, loss:0.5976477503119842\n",
            "Epoch:489, w1:0.9363759397004596, w2:0.7566595453649317, bias:-0.7451134305016931, loss:0.5975879637464886\n",
            "Epoch:490, w1:0.9365308612654775, w2:0.7567016987749016, bias:-0.745867299373859, loss:0.5975283931765717\n",
            "Epoch:491, w1:0.9366863682447969, w2:0.7567449175339814, bias:-0.7466195718894125, loss:0.5974690369807147\n",
            "Epoch:492, w1:0.9368424583371242, w2:0.7567891970367169, bias:-0.7473702540888116, loss:0.5974098935500342\n",
            "Epoch:493, w1:0.9369991292497019, w2:0.7568345326946528, bias:-0.7481193519898768, loss:0.5973509612881875\n",
            "Epoch:494, w1:0.9371563786982833, w2:0.756880919936285, bias:-0.7488668715878615, loss:0.5972922386112793\n",
            "Epoch:495, w1:0.9373142044071069, w2:0.7569283542070115, bias:-0.7496128188555228, loss:0.5972337239477656\n",
            "Epoch:496, w1:0.9374726041088705, w2:0.7569768309690843, bias:-0.7503571997431918, loss:0.5971754157383627\n",
            "Epoch:497, w1:0.9376315755447057, w2:0.7570263457015604, bias:-0.7511000201788439, loss:0.5971173124359539\n",
            "Epoch:498, w1:0.9377911164641524, w2:0.7570768939002538, bias:-0.7518412860681691, loss:0.597059412505498\n",
            "Epoch:499, w1:0.9379512246251328, w2:0.7571284710776868, bias:-0.7525810032946424, loss:0.5970017144239373\n",
            "Epoch:500, w1:0.9381118977939263, w2:0.757181072763041, bias:-0.7533191777195939, loss:0.5969442166801084\n",
            "Epoch:501, w1:0.9382731337451435, w2:0.7572346945021096, bias:-0.7540558151822788, loss:0.5968869177746506\n",
            "Epoch:502, w1:0.938434930261701, w2:0.7572893318572477, bias:-0.7547909214999479, loss:0.5968298162199188\n",
            "Epoch:503, w1:0.9385972851347952, w2:0.7573449804073249, bias:-0.755524502467917, loss:0.5967729105398925\n",
            "Epoch:504, w1:0.9387601961638775, w2:0.7574016357476759, bias:-0.7562565638596374, loss:0.5967161992700896\n",
            "Epoch:505, w1:0.9389236611566283, w2:0.7574592934900523, bias:-0.7569871114267653, loss:0.5966596809574773\n",
            "Epoch:506, w1:0.9390876779289316, w2:0.7575179492625737, bias:-0.757716150899232, loss:0.596603354160388\n",
            "Epoch:507, w1:0.9392522443048495, w2:0.7575775987096794, bias:-0.7584436879853135, loss:0.5965472174484293\n",
            "Epoch:508, w1:0.939417358116597, w2:0.7576382374920801, bias:-0.7591697283716997, loss:0.5964912694024016\n",
            "Epoch:509, w1:0.939583017204516, w2:0.7576998612867089, bias:-0.7598942777235647, loss:0.5964355086142122\n",
            "Epoch:510, w1:0.9397492194170501, w2:0.7577624657866724, bias:-0.7606173416846357, loss:0.59637993368679\n",
            "Epoch:511, w1:0.9399159626107195, w2:0.7578260467012033, bias:-0.7613389258772627, loss:0.596324543234002\n",
            "Epoch:512, w1:0.9400832446500951, w2:0.7578905997556111, bias:-0.7620590359024877, loss:0.5962693358805718\n",
            "Epoch:513, w1:0.9402510634077733, w2:0.7579561206912335, bias:-0.762777677340114, loss:0.5962143102619949\n",
            "Epoch:514, w1:0.940419416764351, w2:0.7580226052653883, bias:-0.7634948557487753, loss:0.5961594650244576\n",
            "Epoch:515, w1:0.9405883026083999, w2:0.7580900492513248, bias:-0.7642105766660047, loss:0.5961047988247551\n",
            "Epoch:516, w1:0.9407577188364411, w2:0.7581584484381755, bias:-0.7649248456083036, loss:0.5960503103302112\n",
            "Epoch:517, w1:0.9409276633529202, w2:0.7582277986309073, bias:-0.765637668071211, loss:0.5959959982185975\n",
            "Epoch:518, w1:0.941098134070182, w2:0.7582980956502734, bias:-0.7663490495293717, loss:0.5959418611780548\n",
            "Epoch:519, w1:0.9412691289084446, w2:0.7583693353327651, bias:-0.7670589954366053, loss:0.595887897907012\n",
            "Epoch:520, w1:0.9414406457957755, w2:0.758441513530563, bias:-0.7677675112259748, loss:0.5958341071141091\n",
            "Epoch:521, w1:0.9416126826680651, w2:0.758514626111489, bias:-0.7684746023098548, loss:0.5957804875181186\n",
            "Epoch:522, w1:0.9417852374690026, w2:0.7585886689589582, bias:-0.7691802740800003, loss:0.595727037847868\n",
            "Epoch:523, w1:0.9419583081500501, w2:0.75866363797193, bias:-0.769884531907615, loss:0.5956737568421633\n",
            "Epoch:524, w1:0.9421318926704182, w2:0.7587395290648608, bias:-0.7705873811434185, loss:0.5956206432497122\n",
            "Epoch:525, w1:0.9423059889970404, w2:0.7588163381676548, bias:-0.771288827117716, loss:0.5955676958290481\n",
            "Epoch:526, w1:0.9424805951045485, w2:0.7588940612256169, bias:-0.7719888751404647, loss:0.5955149133484556\n",
            "Epoch:527, w1:0.9426557089752473, w2:0.7589726941994037, bias:-0.7726875305013425, loss:0.5954622945858954\n",
            "Epoch:528, w1:0.94283132859909, w2:0.7590522330649763, bias:-0.773384798469816, loss:0.5954098383289291\n",
            "Epoch:529, w1:0.943007451973653, w2:0.7591326738135514, bias:-0.7740806842952073, loss:0.5953575433746479\n",
            "Epoch:530, w1:0.943184077104111, w2:0.7592140124515542, bias:-0.774775193206762, loss:0.5953054085295969\n",
            "Epoch:531, w1:0.9433612020032125, w2:0.7592962450005697, bias:-0.7754683304137168, loss:0.5952534326097042\n",
            "Epoch:532, w1:0.9435388246912546, w2:0.7593793674972954, bias:-0.7761601011053663, loss:0.5952016144402084\n",
            "Epoch:533, w1:0.9437169431960585, w2:0.7594633759934931, bias:-0.7768505104511306, loss:0.5951499528555865\n",
            "Epoch:534, w1:0.9438955555529446, w2:0.7595482665559413, bias:-0.7775395636006224, loss:0.5950984466994833\n",
            "Epoch:535, w1:0.9440746598047078, w2:0.7596340352663875, bias:-0.7782272656837134, loss:0.5950470948246417\n",
            "Epoch:536, w1:0.9442542540015931, w2:0.7597206782215004, bias:-0.7789136218106016, loss:0.5949958960928309\n",
            "Epoch:537, w1:0.9444343362012707, w2:0.7598081915328222, bias:-0.7795986370718783, loss:0.5949448493747783\n",
            "Epoch:538, w1:0.9446149044688112, w2:0.7598965713267215, bias:-0.7802823165385936, loss:0.5948939535501002\n",
            "Epoch:539, w1:0.9447959568766618, w2:0.759985813744345, bias:-0.7809646652623241, loss:0.5948432075072329\n",
            "Epoch:540, w1:0.9449774915046211, w2:0.7600759149415709, bias:-0.7816456882752385, loss:0.5947926101433655\n",
            "Epoch:541, w1:0.9451595064398147, w2:0.7601668710889607, bias:-0.782325390590164, loss:0.5947421603643712\n",
            "Epoch:542, w1:0.9453419997766713, w2:0.7602586783717125, bias:-0.7830037772006526, loss:0.5946918570847418\n",
            "Epoch:543, w1:0.9455249696168977, w2:0.7603513329896132, bias:-0.7836808530810466, loss:0.5946416992275199\n",
            "Epoch:544, w1:0.9457084140694547, w2:0.7604448311569918, bias:-0.7843566231865449, loss:0.5945916857242332\n",
            "Epoch:545, w1:0.9458923312505328, w2:0.7605391691026716, bias:-0.7850310924532682, loss:0.5945418155148293\n",
            "Epoch:546, w1:0.9460767192835282, w2:0.7606343430699238, bias:-0.7857042657983252, loss:0.5944920875476108\n",
            "Epoch:547, w1:0.946261576299018, w2:0.76073034931642, bias:-0.7863761481198777, loss:0.59444250077917\n",
            "Epoch:548, w1:0.9464469004347364, w2:0.7608271841141854, bias:-0.7870467442972057, loss:0.5943930541743252\n",
            "Epoch:549, w1:0.9466326898355508, w2:0.7609248437495517, bias:-0.7877160591907729, loss:0.5943437467060568\n",
            "Epoch:550, w1:0.946818942653437, w2:0.7610233245231107, bias:-0.7883840976422919, loss:0.5942945773554444\n",
            "Epoch:551, w1:0.9470056570474559, w2:0.761122622749667, bias:-0.7890508644747886, loss:0.5942455451116044\n",
            "Epoch:552, w1:0.9471928311837289, w2:0.7612227347581917, bias:-0.7897163644926674, loss:0.5941966489716269\n",
            "Epoch:553, w1:0.9473804632354144, w2:0.7613236568917756, bias:-0.7903806024817754, loss:0.5941478879405142\n",
            "Epoch:554, w1:0.9475685513826836, w2:0.7614253855075828, bias:-0.7910435832094677, loss:0.5940992610311203\n",
            "Epoch:555, w1:0.9477570938126968, w2:0.7615279169768038, bias:-0.7917053114246706, loss:0.5940507672640883\n",
            "Epoch:556, w1:0.9479460887195796, w2:0.7616312476846098, bias:-0.792365791857947, loss:0.5940024056677922\n",
            "Epoch:557, w1:0.948135534304399, w2:0.7617353740301058, bias:-0.7930250292215597, loss:0.5939541752782742\n",
            "Epoch:558, w1:0.9483254287751396, w2:0.7618402924262846, bias:-0.7936830282095357, loss:0.5939060751391881\n",
            "Epoch:559, w1:0.9485157703466802, w2:0.7619459992999803, bias:-0.7943397934977299, loss:0.5938581043017378\n",
            "Epoch:560, w1:0.94870655724077, w2:0.7620524910918226, bias:-0.7949953297438886, loss:0.5938102618246202\n",
            "Epoch:561, w1:0.948897787686005, w2:0.7621597642561906, bias:-0.7956496415877135, loss:0.5937625467739653\n",
            "Epoch:562, w1:0.9490894599178042, w2:0.7622678152611668, bias:-0.7963027336509243, loss:0.5937149582232807\n",
            "Epoch:563, w1:0.949281572178387, w2:0.7623766405884915, bias:-0.796954610537323, loss:0.5936674952533921\n",
            "Epoch:564, w1:0.9494741227167488, w2:0.7624862367335166, bias:-0.7976052768328558, loss:0.5936201569523871\n",
            "Epoch:565, w1:0.949667109788638, w2:0.76259660020516, bias:-0.7982547371056768, loss:0.5935729424155599\n",
            "Epoch:566, w1:0.9498605316565327, w2:0.7627077275258602, bias:-0.7989029959062109, loss:0.5935258507453521\n",
            "Epoch:567, w1:0.9500543865896174, w2:0.7628196152315309, bias:-0.799550057767216, loss:0.5934788810513006\n",
            "Epoch:568, w1:0.9502486728637595, w2:0.7629322598715146, bias:-0.8001959272038454, loss:0.5934320324499807\n",
            "Epoch:569, w1:0.9504433887614865, w2:0.7630456580085385, bias:-0.8008406087137107, loss:0.5933853040649502\n",
            "Epoch:570, w1:0.9506385325719626, w2:0.7631598062186685, bias:-0.8014841067769436, loss:0.5933386950266967\n",
            "Epoch:571, w1:0.9508341025909659, w2:0.7632747010912638, bias:-0.8021264258562584, loss:0.5932922044725822\n",
            "Epoch:572, w1:0.9510300971208648, w2:0.7633903392289325, bias:-0.8027675703970132, loss:0.5932458315467911\n",
            "Epoch:573, w1:0.9512265144705956, w2:0.7635067172474858, bias:-0.8034075448272722, loss:0.5931995754002751\n",
            "Epoch:574, w1:0.9514233529556392, w2:0.7636238317758934, bias:-0.8040463535578672, loss:0.5931534351907018\n",
            "Epoch:575, w1:0.9516206108979984, w2:0.7637416794562392, bias:-0.8046840009824591, loss:0.5931074100824012\n",
            "Epoch:576, w1:0.9518182866261752, w2:0.7638602569436752, bias:-0.8053204914775989, loss:0.5930614992463143\n",
            "Epoch:577, w1:0.9520163784751474, w2:0.7639795609063782, bias:-0.8059558294027893, loss:0.5930157018599412\n",
            "Epoch:578, w1:0.9522148847863467, w2:0.7640995880255043, bias:-0.8065900191005455, loss:0.5929700171072899\n",
            "Epoch:579, w1:0.9524138039076354, w2:0.7642203349951449, bias:-0.8072230648964559, loss:0.5929244441788254\n",
            "Epoch:580, w1:0.9526131341932841, w2:0.7643417985222819, bias:-0.807854971099243, loss:0.5928789822714191\n",
            "Epoch:581, w1:0.952812874003949, w2:0.7644639753267439, bias:-0.8084857420008239, loss:0.5928336305882987\n",
            "Epoch:582, w1:0.9530130217066494, w2:0.7645868621411617, bias:-0.8091153818763706, loss:0.5927883883389987\n",
            "Epoch:583, w1:0.9532135756747452, w2:0.7647104557109237, bias:-0.8097438949843703, loss:0.5927432547393108\n",
            "Epoch:584, w1:0.9534145342879147, w2:0.7648347527941327, bias:-0.8103712855666857, loss:0.5926982290112341\n",
            "Epoch:585, w1:0.9536158959321319, w2:0.7649597501615616, bias:-0.8109975578486145, loss:0.5926533103829285\n",
            "Epoch:586, w1:0.9538176589996445, w2:0.7650854445966093, bias:-0.8116227160389493, loss:0.5926084980886642\n",
            "Epoch:587, w1:0.9540198218889516, w2:0.7652118328952575, bias:-0.8122467643300376, loss:0.5925637913687756\n",
            "Epoch:588, w1:0.9542223830047813, w2:0.7653389118660264, bias:-0.8128697068978407, loss:0.5925191894696118\n",
            "Epoch:589, w1:0.9544253407580687, w2:0.7654666783299316, bias:-0.8134915479019933, loss:0.5924746916434914\n",
            "Epoch:590, w1:0.9546286935659339, w2:0.7655951291204407, bias:-0.8141122914858627, loss:0.5924302971486552\n",
            "Epoch:591, w1:0.95483243985166, w2:0.7657242610834293, bias:-0.8147319417766077, loss:0.592386005249218\n",
            "Epoch:592, w1:0.9550365780446707, w2:0.7658540710771384, bias:-0.8153505028852372, loss:0.5923418152151249\n",
            "Epoch:593, w1:0.955241106580509, w2:0.7659845559721312, bias:-0.8159679789066694, loss:0.5922977263221038\n",
            "Epoch:594, w1:0.9554460239008148, w2:0.7661157126512496, bias:-0.8165843739197898, loss:0.5922537378516212\n",
            "Epoch:595, w1:0.9556513284533035, w2:0.7662475380095713, bias:-0.8171996919875099, loss:0.5922098490908358\n",
            "Epoch:596, w1:0.9558570186917439, w2:0.7663800289543675, bias:-0.817813937156825, loss:0.5921660593325553\n",
            "Epoch:597, w1:0.9560630930759367, w2:0.7665131824050593, bias:-0.818427113458873, loss:0.5921223678751905\n",
            "Epoch:598, w1:0.9562695500716931, w2:0.7666469952931756, bias:-0.8190392249089913, loss:0.5920787740227118\n",
            "Epoch:599, w1:0.9564763881508126, w2:0.7667814645623103, bias:-0.8196502755067754, loss:0.5920352770846065\n",
            "Epoch:600, w1:0.9566836057910619, w2:0.7669165871680799, bias:-0.8202602692361358, loss:0.5919918763758333\n",
            "Epoch:601, w1:0.9568912014761534, w2:0.767052360078081, bias:-0.8208692100653558, loss:0.5919485712167813\n",
            "Epoch:602, w1:0.9570991736957236, w2:0.7671887802718482, bias:-0.8214771019471487, loss:0.5919053609332257\n",
            "Epoch:603, w1:0.957307520945312, w2:0.767325844740812, bias:-0.8220839488187147, loss:0.5918622448562865\n",
            "Epoch:604, w1:0.9575162417263395, w2:0.7674635504882562, bias:-0.8226897546017979, loss:0.591819222322386\n",
            "Epoch:605, w1:0.9577253345460874, w2:0.7676018945292766, bias:-0.8232945232027434, loss:0.5917762926732064\n",
            "Epoch:606, w1:0.9579347979176762, w2:0.7677408738907389, bias:-0.8238982585125533, loss:0.5917334552556497\n",
            "Epoch:607, w1:0.9581446303600442, w2:0.7678804856112365, bias:-0.8245009644069435, loss:0.5916907094217949\n",
            "Epoch:608, w1:0.9583548303979265, w2:0.7680207267410496, bias:-0.8251026447464003, loss:0.5916480545288589\n",
            "Epoch:609, w1:0.9585653965618343, w2:0.7681615943421032, bias:-0.8257033033762355, loss:0.5916054899391545\n",
            "Epoch:610, w1:0.9587763273880335, w2:0.7683030854879256, bias:-0.8263029441266438, loss:0.5915630150200514\n",
            "Epoch:611, w1:0.9589876214185243, w2:0.7684451972636073, bias:-0.8269015708127574, loss:0.5915206291439353\n",
            "Epoch:612, w1:0.9591992772010198, w2:0.7685879267657595, bias:-0.8274991872347021, loss:0.5914783316881689\n",
            "Epoch:613, w1:0.9594112932889255, w2:0.7687312711024731, bias:-0.8280957971776527, loss:0.5914361220350522\n",
            "Epoch:614, w1:0.9596236682413184, w2:0.7688752273932777, bias:-0.8286914044118887, loss:0.5913939995717847\n",
            "Epoch:615, w1:0.9598364006229266, w2:0.7690197927691007, bias:-0.8292860126928489, loss:0.5913519636904245\n",
            "Epoch:616, w1:0.9600494890041086, w2:0.7691649643722263, bias:-0.8298796257611866, loss:0.5913100137878522\n",
            "Epoch:617, w1:0.9602629319608323, w2:0.7693107393562548, bias:-0.8304722473428247, loss:0.5912681492657318\n",
            "Epoch:618, w1:0.9604767280746553, w2:0.7694571148860623, bias:-0.83106388114901, loss:0.5912263695304718\n",
            "Epoch:619, w1:0.9606908759327036, w2:0.7696040881377597, bias:-0.831654530876368, loss:0.5911846739931902\n",
            "Epoch:620, w1:0.9609053741276519, w2:0.7697516562986527, bias:-0.832244200206957, loss:0.5911430620696746\n",
            "Epoch:621, w1:0.9611202212577026, w2:0.7698998165672014, bias:-0.8328328928083224, loss:0.5911015331803479\n",
            "Epoch:622, w1:0.9613354159265662, w2:0.7700485661529799, bias:-0.8334206123335509, loss:0.5910600867502285\n",
            "Epoch:623, w1:0.9615509567434407, w2:0.7701979022766365, bias:-0.8340073624213241, loss:0.5910187222088975\n",
            "Epoch:624, w1:0.9617668423229915, w2:0.7703478221698539, bias:-0.8345931466959724, loss:0.5909774389904596\n",
            "Epoch:625, w1:0.9619830712853312, w2:0.7704983230753084, bias:-0.8351779687675285, loss:0.5909362365335088\n",
            "Epoch:626, w1:0.9621996422559999, w2:0.7706494022466314, bias:-0.8357618322317807, loss:0.5908951142810928\n",
            "Epoch:627, w1:0.9624165538659446, w2:0.7708010569483688, bias:-0.8363447406703262, loss:0.5908540716806768\n",
            "Epoch:628, w1:0.9626338047515, w2:0.7709532844559419, bias:-0.8369266976506241, loss:0.5908131081841099\n",
            "Epoch:629, w1:0.962851393554368, w2:0.7711060820556078, bias:-0.8375077067260487, loss:0.5907722232475894\n",
            "Epoch:630, w1:0.9630693189215984, w2:0.7712594470444203, bias:-0.8380877714359415, loss:0.5907314163316263\n",
            "Epoch:631, w1:0.9632875795055688, w2:0.7714133767301902, bias:-0.8386668953056643, loss:0.5906906869010112\n",
            "Epoch:632, w1:0.9635061739639649, w2:0.7715678684314466, bias:-0.8392450818466516, loss:0.5906500344247817\n",
            "Epoch:633, w1:0.9637251009597609, w2:0.771722919477398, bias:-0.8398223345564627, loss:0.5906094583761864\n",
            "Epoch:634, w1:0.9639443591612004, w2:0.7718785272078927, bias:-0.840398656918834, loss:0.5905689582326533\n",
            "Epoch:635, w1:0.9641639472417759, w2:0.772034688973381, bias:-0.8409740524037306, loss:0.5905285334757557\n",
            "Epoch:636, w1:0.9643838638802102, w2:0.7721914021348756, bias:-0.8415485244673983, loss:0.5904881835911798\n",
            "Epoch:637, w1:0.9646041077604367, w2:0.7723486640639136, bias:-0.8421220765524153, loss:0.5904479080686921\n",
            "Epoch:638, w1:0.9648246775715799, w2:0.7725064721425177, bias:-0.8426947120877436, loss:0.5904077064021063\n",
            "Epoch:639, w1:0.9650455720079361, w2:0.7726648237631583, bias:-0.8432664344887801, loss:0.5903675780892522\n",
            "Epoch:640, w1:0.9652667897689544, w2:0.7728237163287146, bias:-0.8438372471574082, loss:0.5903275226319432\n",
            "Epoch:641, w1:0.9654883295592177, w2:0.7729831472524371, bias:-0.8444071534820479, loss:0.5902875395359443\n",
            "Epoch:642, w1:0.9657101900884228, w2:0.7731431139579091, bias:-0.8449761568377077, loss:0.5902476283109417\n",
            "Epoch:643, w1:0.9659323700713622, w2:0.7733036138790091, bias:-0.8455442605860344, loss:0.5902077884705111\n",
            "Epoch:644, w1:0.9661548682279046, w2:0.7734646444598726, bias:-0.8461114680753642, loss:0.5901680195320869\n",
            "Epoch:645, w1:0.966377683282976, w2:0.7736262031548549, bias:-0.8466777826407725, loss:0.5901283210169305\n",
            "Epoch:646, w1:0.9666008139665411, w2:0.7737882874284929, bias:-0.8472432076041247, loss:0.590088692450102\n",
            "Epoch:647, w1:0.9668242590135839, w2:0.7739508947554684, bias:-0.8478077462741255, loss:0.5900491333604282\n",
            "Epoch:648, w1:0.9670480171640897, w2:0.7741140226205699, bias:-0.8483714019463692, loss:0.5900096432804735\n",
            "Epoch:649, w1:0.9672720871630256, w2:0.774277668518656, bias:-0.8489341779033894, loss:0.5899702217465094\n",
            "Epoch:650, w1:0.9674964677603225, w2:0.7744418299546175, bias:-0.8494960774147087, loss:0.5899308682984864\n",
            "Epoch:651, w1:0.967721157710856, w2:0.7746065044433413, bias:-0.8500571037368873, loss:0.5898915824800034\n",
            "Epoch:652, w1:0.9679461557744282, w2:0.7747716895096726, bias:-0.850617260113573, loss:0.5898523638382792\n",
            "Epoch:653, w1:0.968171460715749, w2:0.7749373826883784, bias:-0.8511765497755502, loss:0.589813211924123\n",
            "Epoch:654, w1:0.9683970713044178, w2:0.7751035815241111, bias:-0.8517349759407885, loss:0.5897741262919074\n",
            "Epoch:655, w1:0.9686229863149051, w2:0.7752702835713712, bias:-0.8522925418144915, loss:0.5897351064995388\n",
            "Epoch:656, w1:0.9688492045265341, w2:0.7754374863944714, bias:-0.8528492505891456, loss:0.5896961521084293\n",
            "Epoch:657, w1:0.9690757247234626, w2:0.7756051875674999, bias:-0.8534051054445683, loss:0.5896572626834687\n",
            "Epoch:658, w1:0.9693025456946646, w2:0.775773384674284, bias:-0.8539601095479563, loss:0.5896184377929982\n",
            "Epoch:659, w1:0.9695296662339122, w2:0.7759420753083546, bias:-0.854514266053934, loss:0.5895796770087803\n",
            "Epoch:660, w1:0.969757085139758, w2:0.776111257072909, bias:-0.8550675781046012, loss:0.5895409799059744\n",
            "Epoch:661, w1:0.9699848012155162, w2:0.7762809275807758, bias:-0.8556200488295809, loss:0.5895023460631074\n",
            "Epoch:662, w1:0.9702128132692454, w2:0.776451084454379, bias:-0.856171681346067, loss:0.5894637750620483\n",
            "Epoch:663, w1:0.9704411201137301, w2:0.776621725325702, bias:-0.856722478758872, loss:0.5894252664879805\n",
            "Epoch:664, w1:0.9706697205664633, w2:0.7767928478362516, bias:-0.8572724441604738, loss:0.5893868199293769\n",
            "Epoch:665, w1:0.9708986134496286, w2:0.7769644496370235, bias:-0.8578215806310635, loss:0.5893484349779721\n",
            "Epoch:666, w1:0.9711277975900822, w2:0.7771365283884659, bias:-0.858369891238592, loss:0.5893101112287368\n",
            "Epoch:667, w1:0.9713572718193354, w2:0.7773090817604447, bias:-0.8589173790388169, loss:0.5892718482798521\n",
            "Epoch:668, w1:0.9715870349735373, w2:0.777482107432208, bias:-0.8594640470753496, loss:0.5892336457326849\n",
            "Epoch:669, w1:0.9718170858934564, w2:0.7776556030923515, bias:-0.8600098983797014, loss:0.5891955031917605\n",
            "Epoch:670, w1:0.9720474234244639, w2:0.7778295664387828, bias:-0.8605549359713299, loss:0.5891574202647386\n",
            "Epoch:671, w1:0.9722780464165159, w2:0.7780039951786871, bias:-0.8610991628576857, loss:0.5891193965623885\n",
            "Epoch:672, w1:0.972508953724136, w2:0.7781788870284924, bias:-0.861642582034258, loss:0.5890814316985634\n",
            "Epoch:673, w1:0.9727401442063979, w2:0.7783542397138342, bias:-0.8621851964846209, loss:0.5890435252901767\n",
            "Epoch:674, w1:0.9729716167269081, w2:0.778530050969522, bias:-0.862727009180479, loss:0.5890056769571763\n",
            "Epoch:675, w1:0.9732033701537891, w2:0.7787063185395039, bias:-0.8632680230817128, loss:0.5889678863225226\n",
            "Epoch:676, w1:0.9734354033596616, w2:0.7788830401768327, bias:-0.8638082411364248, loss:0.5889301530121615\n",
            "Epoch:677, w1:0.9736677152216276, w2:0.7790602136436318, bias:-0.8643476662809844, loss:0.5888924766550023\n",
            "Epoch:678, w1:0.9739003046212538, w2:0.7792378367110604, bias:-0.8648863014400728, loss:0.5888548568828947\n",
            "Epoch:679, w1:0.9741331704445535, w2:0.7794159071592806, bias:-0.8654241495267289, loss:0.5888172933306034\n",
            "Epoch:680, w1:0.9743663115819711, w2:0.7795944227774224, bias:-0.8659612134423931, loss:0.5887797856357863\n",
            "Epoch:681, w1:0.9745997269283638, w2:0.7797733813635508, bias:-0.8664974960769527, loss:0.5887423334389704\n",
            "Epoch:682, w1:0.9748334153829858, w2:0.7799527807246311, bias:-0.8670330003087865, loss:0.5887049363835294\n",
            "Epoch:683, w1:0.9750673758494709, w2:0.7801326186764965, bias:-0.8675677290048087, loss:0.5886675941156612\n",
            "Epoch:684, w1:0.975301607235816, w2:0.7803128930438136, bias:-0.8681016850205138, loss:0.5886303062843645\n",
            "Epoch:685, w1:0.9755361084543646, w2:0.7804936016600493, bias:-0.8686348712000199, loss:0.5885930725414172\n",
            "Epoch:686, w1:0.9757708784217896, w2:0.7806747423674383, bias:-0.8691672903761136, loss:0.5885558925413531\n",
            "Epoch:687, w1:0.9760059160590774, w2:0.7808563130169487, bias:-0.8696989453702931, loss:0.5885187659414415\n",
            "Epoch:688, w1:0.9762412202915111, w2:0.7810383114682499, bias:-0.8702298389928121, loss:0.5884816924016637\n",
            "Epoch:689, w1:0.9764767900486538, w2:0.7812207355896792, bias:-0.8707599740427234, loss:0.588444671584692\n",
            "Epoch:690, w1:0.976712624264333, w2:0.781403583258209, bias:-0.871289353307922, loss:0.5884077031558684\n",
            "Epoch:691, w1:0.9769487218766232, w2:0.7815868523594144, bias:-0.8718179795651887, loss:0.5883707867831828\n",
            "Epoch:692, w1:0.9771850818278301, w2:0.78177054078744, bias:-0.8723458555802327, loss:0.5883339221372519\n",
            "Epoch:693, w1:0.9774217030644748, w2:0.781954646444968, bias:-0.8728729841077348, loss:0.5882971088912982\n",
            "Epoch:694, w1:0.9776585845372769, w2:0.7821391672431853, bias:-0.8733993678913903, loss:0.5882603467211291\n",
            "Epoch:695, w1:0.9778957252011389, w2:0.7823241011017514, bias:-0.8739250096639511, loss:0.5882236353051167\n",
            "Epoch:696, w1:0.9781331240151296, w2:0.7825094459487661, bias:-0.8744499121472689, loss:0.5881869743241762\n",
            "Epoch:697, w1:0.9783707799424687, w2:0.7826951997207376, bias:-0.8749740780523366, loss:0.588150363461746\n",
            "Epoch:698, w1:0.9786086919505104, w2:0.7828813603625503, bias:-0.8754975100793314, loss:0.5881138024037686\n",
            "Epoch:699, w1:0.9788468590107275, w2:0.7830679258274329, bias:-0.8760202109176561, loss:0.5880772908386687\n",
            "Epoch:700, w1:0.979085280098696, w2:0.7832548940769269, bias:-0.8765421832459815, loss:0.5880408284573341\n",
            "Epoch:701, w1:0.9793239541940787, w2:0.7834422630808546, bias:-0.8770634297322879, loss:0.5880044149530964\n",
            "Epoch:702, w1:0.9795628802806098, w2:0.7836300308172875, bias:-0.8775839530339066, loss:0.5879680500217109\n",
            "Epoch:703, w1:0.9798020573460792, w2:0.7838181952725153, bias:-0.8781037557975615, loss:0.5879317333613376\n",
            "Epoch:704, w1:0.9800414843823166, w2:0.7840067544410138, bias:-0.8786228406594104, loss:0.5878954646725209\n",
            "Epoch:705, w1:0.9802811603851764, w2:0.7841957063254144, bias:-0.879141210245086, loss:0.5878592436581715\n",
            "Epoch:706, w1:0.9805210843545218, w2:0.7843850489364723, bias:-0.879658867169737, loss:0.5878230700235477\n",
            "Epoch:707, w1:0.9807612552942091, w2:0.784574780293036, bias:-0.8801758140380691, loss:0.5877869434762352\n",
            "Epoch:708, w1:0.9810016722120729, w2:0.7847648984220157, bias:-0.8806920534443855, loss:0.5877508637261295\n",
            "Epoch:709, w1:0.9812423341199102, w2:0.7849554013583532, bias:-0.8812075879726275, loss:0.5877148304854172\n",
            "Epoch:710, w1:0.9814832400334655, w2:0.7851462871449905, bias:-0.8817224201964152, loss:0.5876788434685573\n",
            "Epoch:711, w1:0.9817243889724152, w2:0.7853375538328395, bias:-0.8822365526790874, loss:0.5876429023922634\n",
            "Epoch:712, w1:0.9819657799603524, w2:0.7855291994807515, bias:-0.882749987973742, loss:0.5876070069754853\n",
            "Epoch:713, w1:0.982207412024772, w2:0.7857212221554866, bias:-0.8832627286232759, loss:0.5875711569393909\n",
            "Epoch:714, w1:0.9824492841970554, w2:0.7859136199316832, bias:-0.883774777160425, loss:0.5875353520073493\n",
            "Epoch:715, w1:0.9826913955124552, w2:0.7861063908918282, bias:-0.8842861361078037, loss:0.5874995919049117\n",
            "Epoch:716, w1:0.9829337450100809, w2:0.7862995331262267, bias:-0.8847968079779447, loss:0.5874638763597951\n",
            "Epoch:717, w1:0.9831763317328833, w2:0.7864930447329718, bias:-0.8853067952733382, loss:0.5874282051018643\n",
            "Epoch:718, w1:0.9834191547276399, w2:0.7866869238179147, bias:-0.8858161004864716, loss:0.5873925778631149\n",
            "Epoch:719, w1:0.9836622130449397, w2:0.7868811684946352, bias:-0.8863247260998682, loss:0.587356994377656\n",
            "Epoch:720, w1:0.983905505739169, w2:0.7870757768844114, bias:-0.8868326745861266, loss:0.5873214543816935\n",
            "Epoch:721, w1:0.9841490318684962, w2:0.7872707471161908, bias:-0.887339948407959, loss:0.587285957613513\n",
            "Epoch:722, w1:0.9843927904948573, w2:0.7874660773265602, bias:-0.8878465500182309, loss:0.587250503813463\n",
            "Epoch:723, w1:0.9846367806839411, w2:0.7876617656597162, bias:-0.8883524818599987, loss:0.5872150927239388\n",
            "Epoch:724, w1:0.9848810015051748, w2:0.7878578102674367, bias:-0.8888577463665489, loss:0.5871797240893659\n",
            "Epoch:725, w1:0.9851254520317092, w2:0.7880542093090507, bias:-0.8893623459614359, loss:0.5871443976561829\n",
            "Epoch:726, w1:0.9853701313404045, w2:0.7882509609514096, bias:-0.8898662830585206, loss:0.5871091131728268\n",
            "Epoch:727, w1:0.9856150385118159, w2:0.7884480633688582, bias:-0.8903695600620081, loss:0.5870738703897156\n",
            "Epoch:728, w1:0.9858601726301787, w2:0.788645514743206, bias:-0.8908721793664859, loss:0.5870386690592327\n",
            "Epoch:729, w1:0.9861055327833946, w2:0.7888433132636978, bias:-0.8913741433569616, loss:0.5870035089357125\n",
            "Epoch:730, w1:0.9863511180630171, w2:0.7890414571269855, bias:-0.8918754544089005, loss:0.5869683897754217\n",
            "Epoch:731, w1:0.9865969275642372, w2:0.7892399445370991, bias:-0.892376114888263, loss:0.586933311336547\n",
            "Epoch:732, w1:0.9868429603858695, w2:0.7894387737054186, bias:-0.892876127151542, loss:0.586898273379178\n",
            "Epoch:733, w1:0.9870892156303377, w2:0.789637942850645, bias:-0.8933754935458004, loss:0.5868632756652916\n",
            "Epoch:734, w1:0.9873356924036607, w2:0.7898374501987725, bias:-0.8938742164087079, loss:0.5868283179587379\n",
            "Epoch:735, w1:0.9875823898154388, w2:0.7900372939830599, bias:-0.8943722980685781, loss:0.5867934000252246\n",
            "Epoch:736, w1:0.9878293069788392, w2:0.7902374724440027, bias:-0.8948697408444053, loss:0.5867585216323018\n",
            "Epoch:737, w1:0.9880764430105826, w2:0.790437983829305, bias:-0.8953665470459011, loss:0.5867236825493474\n",
            "Epoch:738, w1:0.9883237970309291, w2:0.7906388263938515, bias:-0.8958627189735313, loss:0.586688882547553\n",
            "Epoch:739, w1:0.988571368163664, w2:0.7908399983996798, bias:-0.8963582589185518, loss:0.586654121399908\n",
            "Epoch:740, w1:0.9888191555360847, w2:0.7910414981159523, bias:-0.8968531691630452, loss:0.5866193988811867\n",
            "Epoch:741, w1:0.9890671582789864, w2:0.7912433238189289, bias:-0.8973474519799572, loss:0.5865847147679326\n",
            "Epoch:742, w1:0.9893153755266488, w2:0.7914454737919396, bias:-0.8978411096331321, loss:0.5865500688384446\n",
            "Epoch:743, w1:0.9895638064168223, w2:0.7916479463253566, bias:-0.8983341443773492, loss:0.5865154608727636\n",
            "Epoch:744, w1:0.9898124500907143, w2:0.791850739716567, bias:-0.898826558458358, loss:0.5864808906526574\n",
            "Epoch:745, w1:0.9900613056929758, w2:0.792053852269946, bias:-0.8993183541129146, loss:0.5864463579616074\n",
            "Epoch:746, w1:0.9903103723716878, w2:0.7922572822968289, bias:-0.8998095335688165, loss:0.5864118625847943\n",
            "Epoch:747, w1:0.9905596492783483, w2:0.792461028115485, bias:-0.9003000990449385, loss:0.5863774043090854\n",
            "Epoch:748, w1:0.990809135567858, w2:0.7926650880510901, bias:-0.9007900527512673, loss:0.5863429829230202\n",
            "Epoch:749, w1:0.9910588303985078, w2:0.7928694604356995, bias:-0.9012793968889375, loss:0.5863085982167969\n",
            "Epoch:750, w1:0.9913087329319654, w2:0.7930741436082215, bias:-0.901768133650266, loss:0.5862742499822594\n",
            "Epoch:751, w1:0.9915588423332615, w2:0.7932791359143905, bias:-0.9022562652187868, loss:0.5862399380128845\n",
            "Epoch:752, w1:0.9918091577707772, w2:0.7934844357067405, bias:-0.9027437937692859, loss:0.5862056621037673\n",
            "Epoch:753, w1:0.9920596784162303, w2:0.7936900413445788, bias:-0.9032307214678362, loss:0.5861714220516098\n",
            "Epoch:754, w1:0.9923104034446629, w2:0.793895951193959, bias:-0.9037170504718315, loss:0.5861372176547069\n",
            "Epoch:755, w1:0.9925613320344276, w2:0.7941021636276554, bias:-0.904202782930021, loss:0.5861030487129338\n",
            "Epoch:756, w1:0.992812463367175, w2:0.7943086770251363, bias:-0.9046879209825436, loss:0.5860689150277335\n",
            "Epoch:757, w1:0.9930637966278405, w2:0.794515489772538, bias:-0.905172466760962, loss:0.5860348164021043\n",
            "Epoch:758, w1:0.9933153310046314, w2:0.794722600262639, bias:-0.9056564223882965, loss:0.5860007526405867\n",
            "Epoch:759, w1:0.9935670656890143, w2:0.7949300068948334, bias:-0.9061397899790592, loss:0.5859667235492514\n",
            "Epoch:760, w1:0.9938189998757018, w2:0.7951377080751058, bias:-0.9066225716392873, loss:0.5859327289356867\n",
            "Epoch:761, w1:0.9940711327626399, w2:0.795345702216005, bias:-0.9071047694665768, loss:0.5858987686089869\n",
            "Epoch:762, w1:0.9943234635509958, w2:0.7955539877366188, bias:-0.9075863855501163, loss:0.5858648423797393\n",
            "Epoch:763, w1:0.9945759914451443, w2:0.795762563062548, bias:-0.9080674219707199, loss:0.5858309500600126\n",
            "Epoch:764, w1:0.9948287156526558, w2:0.7959714266258812, bias:-0.9085478808008606, loss:0.5857970914633449\n",
            "Epoch:765, w1:0.9950816353842837, w2:0.7961805768651691, bias:-0.9090277641047034, loss:0.5857632664047324\n",
            "Epoch:766, w1:0.9953347498539515, w2:0.7963900122253995, bias:-0.9095070739381386, loss:0.5857294747006164\n",
            "Epoch:767, w1:0.9955880582787405, w2:0.7965997311579721, bias:-0.9099858123488137, loss:0.5856957161688732\n",
            "Epoch:768, w1:0.9958415598788775, w2:0.7968097321206731, bias:-0.9104639813761674, loss:0.5856619906288009\n",
            "Epoch:769, w1:0.9960952538777219, w2:0.7970200135776503, bias:-0.910941583051461, loss:0.5856282979011092\n",
            "Epoch:770, w1:0.9963491395017541, w2:0.7972305739993883, bias:-0.9114186193978119, loss:0.5855946378079081\n",
            "Epoch:771, w1:0.9966032159805625, w2:0.7974414118626836, bias:-0.911895092430225, loss:0.5855610101726949\n",
            "Epoch:772, w1:0.9968574825468315, w2:0.7976525256506195, bias:-0.9123710041556261, loss:0.5855274148203455\n",
            "Epoch:773, w1:0.9971119384363294, w2:0.797863913852542, bias:-0.9128463565728927, loss:0.5854938515771011\n",
            "Epoch:774, w1:0.997366582887896, w2:0.7980755749640346, bias:-0.9133211516728871, loss:0.5854603202705587\n",
            "Epoch:775, w1:0.9976214151434306, w2:0.7982875074868945, bias:-0.9137953914384875, loss:0.5854268207296591\n",
            "Epoch:776, w1:0.9978764344478799, w2:0.7984997099291076, bias:-0.9142690778446205, loss:0.5853933527846769\n",
            "Epoch:777, w1:0.9981316400492256, w2:0.7987121808048243, bias:-0.914742212858292, loss:0.5853599162672091\n",
            "Epoch:778, w1:0.9983870311984732, w2:0.7989249186343357, bias:-0.9152147984386193, loss:0.5853265110101652\n",
            "Epoch:779, w1:0.9986426071496393, w2:0.7991379219440489, bias:-0.915686836536862, loss:0.585293136847755\n",
            "Epoch:780, w1:0.9988983671597398, w2:0.7993511892664632, bias:-0.9161583290964537, loss:0.5852597936154809\n",
            "Epoch:781, w1:0.9991543104887786, w2:0.7995647191401462, bias:-0.916629278053033, loss:0.5852264811501247\n",
            "Epoch:782, w1:0.9994104363997349, w2:0.7997785101097097, bias:-0.9170996853344746, loss:0.5851931992897383\n",
            "Epoch:783, w1:0.9996667441585522, w2:0.7999925607257862, bias:-0.9175695528609202, loss:0.5851599478736346\n",
            "Epoch:784, w1:0.999923233034126, w2:0.8002068695450049, bias:-0.9180388825448094, loss:0.5851267267423751\n",
            "Epoch:785, w1:1.0001799022982927, w2:0.8004214351299683, bias:-0.91850767629091, loss:0.5850935357377616\n",
            "Epoch:786, w1:1.000436751225817, w2:0.8006362560492287, bias:-0.9189759359963492, loss:0.5850603747028257\n",
            "Epoch:787, w1:1.0006937790943815, w2:0.8008513308772645, bias:-0.9194436635506437, loss:0.585027243481819\n",
            "Epoch:788, w1:1.0009509851845741, w2:0.8010666581944569, bias:-0.91991086083573, loss:0.5849941419202017\n",
            "Epoch:789, w1:1.0012083687798774, w2:0.8012822365870669, bias:-0.9203775297259951, loss:0.5849610698646361\n",
            "Epoch:790, w1:1.001465929166656, w2:0.8014980646472118, bias:-0.9208436720883058, loss:0.5849280271629738\n",
            "Epoch:791, w1:1.0017236656341466, w2:0.8017141409728424, bias:-0.9213092897820394, loss:0.5848950136642476\n",
            "Epoch:792, w1:1.001981577474445, w2:0.8019304641677196, bias:-0.9217743846591137, loss:0.5848620292186616\n",
            "Epoch:793, w1:1.0022396639824962, w2:0.8021470328413917, bias:-0.9222389585640159, loss:0.5848290736775819\n",
            "Epoch:794, w1:1.002497924456082, w2:0.8023638456091714, bias:-0.9227030133338333, loss:0.5847961468935272\n",
            "Epoch:795, w1:1.0027563581958108, w2:0.8025809010921134, bias:-0.9231665507982822, loss:0.5847632487201596\n",
            "Epoch:796, w1:1.003014964505105, w2:0.8027981979169914, bias:-0.9236295727797377, loss:0.5847303790122744\n",
            "Epoch:797, w1:1.003273742690191, w2:0.8030157347162753, bias:-0.9240920810932626, loss:0.5846975376257931\n",
            "Epoch:798, w1:1.0035326920600878, w2:0.8032335101281092, bias:-0.9245540775466372, loss:0.5846647244177519\n",
            "Epoch:799, w1:1.0037918119265954, w2:0.8034515227962886, bias:-0.925015563940388, loss:0.5846319392462943\n",
            "Epoch:800, w1:1.0040511016042841, w2:0.8036697713702383, bias:-0.9254765420678166, loss:0.5845991819706614\n",
            "Epoch:801, w1:1.0043105604104838, w2:0.8038882545049898, bias:-0.9259370137150291, loss:0.5845664524511833\n",
            "Epoch:802, w1:1.0045701876652724, w2:0.8041069708611593, bias:-0.9263969806609645, loss:0.5845337505492705\n",
            "Epoch:803, w1:1.0048299826914655, w2:0.8043259191049258, bias:-0.9268564446774235, loss:0.5845010761274051\n",
            "Epoch:804, w1:1.005089944814605, w2:0.8045450979080087, bias:-0.9273154075290966, loss:0.5844684290491318\n",
            "Epoch:805, w1:1.0053500733629481, w2:0.804764505947646, bias:-0.9277738709735935, loss:0.5844358091790492\n",
            "Epoch:806, w1:1.0056103676674575, w2:0.8049841419065727, bias:-0.9282318367614707, loss:0.5844032163828025\n",
            "Epoch:807, w1:1.0058708270617895, w2:0.8052040044729987, bias:-0.9286893066362597, loss:0.5843706505270737\n",
            "Epoch:808, w1:1.006131450882284, w2:0.805424092340587, bias:-0.9291462823344957, loss:0.5843381114795736\n",
            "Epoch:809, w1:1.0063922384679533, w2:0.8056444042084325, bias:-0.9296027655857451, loss:0.5843055991090338\n",
            "Epoch:810, w1:1.0066531891604722, w2:0.8058649387810404, bias:-0.9300587581126335, loss:0.5842731132851983\n",
            "Epoch:811, w1:1.0069143023041662, w2:0.8060856947683042, bias:-0.9305142616308738, loss:0.5842406538788153\n",
            "Epoch:812, w1:1.0071755772460023, w2:0.8063066708854849, bias:-0.9309692778492935, loss:0.5842082207616291\n",
            "Epoch:813, w1:1.0074370133355772, w2:0.8065278658531896, bias:-0.9314238084698626, loss:0.5841758138063725\n",
            "Epoch:814, w1:1.0076986099251082, w2:0.8067492783973501, bias:-0.9318778551877208, loss:0.5841434328867574\n",
            "Epoch:815, w1:1.0079603663694214, w2:0.806970907249202, bias:-0.9323314196912053, loss:0.5841110778774687\n",
            "Epoch:816, w1:1.008222282025942, w2:0.8071927511452632, bias:-0.9327845036618775, loss:0.5840787486541552\n",
            "Epoch:817, w1:1.0084843562546841, w2:0.8074148088273136, bias:-0.9332371087745507, loss:0.5840464450934225\n",
            "Epoch:818, w1:1.0087465884182396, w2:0.8076370790423736, bias:-0.933689236697317, loss:0.584014167072825\n",
            "Epoch:819, w1:1.0090089778817688, w2:0.8078595605426835, bias:-0.9341408890915739, loss:0.5839819144708582\n",
            "Epoch:820, w1:1.0092715240129897, w2:0.8080822520856829, bias:-0.9345920676120517, loss:0.5839496871669512\n",
            "Epoch:821, w1:1.0095342261821676, w2:0.8083051524339896, bias:-0.9350427739068401, loss:0.5839174850414586\n",
            "Epoch:822, w1:1.0097970837621055, w2:0.8085282603553796, bias:-0.9354930096174146, loss:0.5838853079756544\n",
            "Epoch:823, w1:1.0100600961281334, w2:0.8087515746227661, bias:-0.9359427763786631, loss:0.5838531558517233\n",
            "Epoch:824, w1:1.0103232626580987, w2:0.8089750940141793, bias:-0.9363920758189127, loss:0.5838210285527533\n",
            "Epoch:825, w1:1.0105865827323557, w2:0.809198817312746, bias:-0.9368409095599558, loss:0.5837889259627299\n",
            "Epoch:826, w1:1.0108500557337559, w2:0.8094227433066692, bias:-0.9372892792170763, loss:0.5837568479665275\n",
            "Epoch:827, w1:1.0111136810476375, w2:0.8096468707892079, bias:-0.9377371863990756, loss:0.5837247944499017\n",
            "Epoch:828, w1:1.0113774580618167, w2:0.8098711985586575, bias:-0.938184632708299, loss:0.5836927652994839\n",
            "Epoch:829, w1:1.0116413861665763, w2:0.8100957254183289, bias:-0.9386316197406616, loss:0.5836607604027729\n",
            "Epoch:830, w1:1.0119054647546566, w2:0.8103204501765289, bias:-0.9390781490856737, loss:0.583628779648129\n",
            "Epoch:831, w1:1.0121696932212456, w2:0.8105453716465405, bias:-0.939524222326467, loss:0.5835968229247657\n",
            "Epoch:832, w1:1.012434070963969, w2:0.8107704886466028, bias:-0.9399698410398202, loss:0.5835648901227439\n",
            "Epoch:833, w1:1.0126985973828804, w2:0.8109957999998915, bias:-0.9404150067961842, loss:0.5835329811329643\n",
            "Epoch:834, w1:1.012963271880452, w2:0.8112213045344987, bias:-0.9408597211597078, loss:0.5835010958471614\n",
            "Epoch:835, w1:1.0132280938615645, w2:0.8114470010834139, bias:-0.9413039856882632, loss:0.5834692341578962\n",
            "Epoch:836, w1:1.0134930627334975, w2:0.8116728884845043, bias:-0.9417478019334709, loss:0.5834373959585496\n",
            "Epoch:837, w1:1.0137581779059202, w2:0.8118989655804949, bias:-0.9421911714407248, loss:0.5834055811433158\n",
            "Epoch:838, w1:1.0140234387908815, w2:0.8121252312189498, bias:-0.942634095749218, loss:0.5833737896071959\n",
            "Epoch:839, w1:1.0142888448028007, w2:0.8123516842522522, bias:-0.9430765763919665, loss:0.5833420212459913\n",
            "Epoch:840, w1:1.0145543953584575, w2:0.8125783235375861, bias:-0.9435186148958352, loss:0.5833102759562973\n",
            "Epoch:841, w1:1.0148200898769837, w2:0.8128051479369158, bias:-0.9439602127815622, loss:0.5832785536354961\n",
            "Epoch:842, w1:1.0150859277798523, w2:0.8130321563169682, bias:-0.9444013715637831, loss:0.5832468541817517\n",
            "Epoch:843, w1:1.0153519084908693, w2:0.8132593475492128, bias:-0.9448420927510565, loss:0.5832151774940022\n",
            "Epoch:844, w1:1.0156180314361636, w2:0.813486720509843, bias:-0.9452823778458873, loss:0.5831835234719541\n",
            "Epoch:845, w1:1.0158842960441783, w2:0.8137142740797577, bias:-0.9457222283447522, loss:0.583151892016077\n",
            "Epoch:846, w1:1.0161507017456608, w2:0.8139420071445418, bias:-0.946161645738123, loss:0.5831202830275957\n",
            "Epoch:847, w1:1.0164172479736542, w2:0.8141699185944478, bias:-0.9466006315104917, loss:0.5830886964084855\n",
            "Epoch:848, w1:1.0166839341634875, w2:0.8143980073243772, bias:-0.9470391871403937, loss:0.5830571320614655\n",
            "Epoch:849, w1:1.0169507597527667, w2:0.8146262722338616, bias:-0.9474773141004326, loss:0.5830255898899925\n",
            "Epoch:850, w1:1.0172177241813658, w2:0.8148547122270449, bias:-0.9479150138573034, loss:0.5829940697982561\n",
            "Epoch:851, w1:1.0174848268914174, w2:0.8150833262126637, bias:-0.9483522878718169, loss:0.5829625716911708\n",
            "Epoch:852, w1:1.017752067327304, w2:0.8153121131040301, bias:-0.9487891375989231, loss:0.5829310954743722\n",
            "Epoch:853, w1:1.0180194449356486, w2:0.8155410718190125, bias:-0.9492255644877349, loss:0.5828996410542099\n",
            "Epoch:854, w1:1.0182869591653059, w2:0.8157702012800179, bias:-0.9496615699815515, loss:0.5828682083377422\n",
            "Epoch:855, w1:1.0185546094673534, w2:0.8159995004139735, bias:-0.950097155517882, loss:0.5828367972327307\n",
            "Epoch:856, w1:1.0188223952950826, w2:0.8162289681523086, bias:-0.9505323225284689, loss:0.5828054076476333\n",
            "Epoch:857, w1:1.0190903161039893, w2:0.8164586034309368, bias:-0.9509670724393109, loss:0.5827740394916003\n",
            "Epoch:858, w1:1.0193583713517658, w2:0.8166884051902376, bias:-0.9514014066706865, loss:0.5827426926744675\n",
            "Epoch:859, w1:1.0196265604982917, w2:0.8169183723750388, bias:-0.9518353266371768, loss:0.5827113671067518\n",
            "Epoch:860, w1:1.0198948830056247, w2:0.8171485039345989, bias:-0.9522688337476888, loss:0.5826800626996446\n",
            "Epoch:861, w1:1.0201633383379924, w2:0.8173787988225887, bias:-0.9527019294054778, loss:0.5826487793650064\n",
            "Epoch:862, w1:1.0204319259617836, w2:0.8176092559970742, bias:-0.9531346150081709, loss:0.5826175170153628\n",
            "Epoch:863, w1:1.0207006453455387, w2:0.8178398744204988, bias:-0.9535668919477888, loss:0.5825862755638975\n",
            "Epoch:864, w1:1.0209694959599425, w2:0.8180706530596655, bias:-0.9539987616107694, loss:0.5825550549244481\n",
            "Epoch:865, w1:1.0212384772778142, w2:0.8183015908857199, bias:-0.9544302253779896, loss:0.5825238550114995\n",
            "Epoch:866, w1:1.0215075887740999, w2:0.8185326868741322, bias:-0.9548612846247883, loss:0.5824926757401805\n",
            "Epoch:867, w1:1.0217768299258632, w2:0.8187639400046803, bias:-0.9552919407209881, loss:0.5824615170262573\n",
            "Epoch:868, w1:1.0220462002122772, w2:0.8189953492614325, bias:-0.9557221950309184, loss:0.5824303787861282\n",
            "Epoch:869, w1:1.022315699114616, w2:0.8192269136327298, bias:-0.9561520489134369, loss:0.5823992609368198\n",
            "Epoch:870, w1:1.0225853261162463, w2:0.8194586321111694, bias:-0.9565815037219519, loss:0.5823681633959804\n",
            "Epoch:871, w1:1.0228550807026182, w2:0.8196905036935872, bias:-0.9570105608044448, loss:0.5823370860818763\n",
            "Epoch:872, w1:1.023124962361258, w2:0.8199225273810408, bias:-0.957439221503491, loss:0.5823060289133856\n",
            "Epoch:873, w1:1.0233949705817587, w2:0.8201547021787926, bias:-0.9578674871562829, loss:0.5822749918099942\n",
            "Epoch:874, w1:1.0236651048557728, w2:0.8203870270962931, bias:-0.9582953590946507, loss:0.5822439746917908\n",
            "Epoch:875, w1:1.0239353646770033, w2:0.8206195011471638, bias:-0.9587228386450846, loss:0.582212977479461\n",
            "Epoch:876, w1:1.0242057495411954, w2:0.8208521233491805, bias:-0.9591499271287562, loss:0.5821820000942842\n",
            "Epoch:877, w1:1.0244762589461287, w2:0.8210848927242566, bias:-0.9595766258615402, loss:0.5821510424581272\n",
            "Epoch:878, w1:1.0247468923916085, w2:0.8213178082984266, bias:-0.9600029361540356, loss:0.5821201044934405\n",
            "Epoch:879, w1:1.0250176493794585, w2:0.8215508691018295, bias:-0.9604288593115871, loss:0.5820891861232532\n",
            "Epoch:880, w1:1.0252885294135115, w2:0.8217840741686921, bias:-0.960854396634306, loss:0.5820582872711677\n",
            "Epoch:881, w1:1.025559531999602, w2:0.8220174225373128, bias:-0.9612795494170924, loss:0.5820274078613571\n",
            "Epoch:882, w1:1.0258306566455584, w2:0.822250913250045, bias:-0.9617043189496549, loss:0.5819965478185578\n",
            "Epoch:883, w1:1.0261019028611942, w2:0.8224845453532809, bias:-0.9621287065165328, loss:0.5819657070680674\n",
            "Epoch:884, w1:1.0263732701583006, w2:0.8227183178974353, bias:-0.9625527133971161, loss:0.5819348855357384\n",
            "Epoch:885, w1:1.0266447580506382, w2:0.8229522299369295, bias:-0.9629763408656669, loss:0.5819040831479748\n",
            "Epoch:886, w1:1.0269163660539293, w2:0.8231862805301748, bias:-0.9633995901913399, loss:0.5818732998317274\n",
            "Epoch:887, w1:1.02718809368585, w2:0.8234204687395569, bias:-0.9638224626382033, loss:0.5818425355144894\n",
            "Epoch:888, w1:1.0274599404660218, w2:0.8236547936314194, bias:-0.9642449594652589, loss:0.5818117901242915\n",
            "Epoch:889, w1:1.0277319059160048, w2:0.8238892542760482, bias:-0.9646670819264633, loss:0.5817810635896982\n",
            "Epoch:890, w1:1.0280039895592887, w2:0.8241238497476557, bias:-0.9650888312707477, loss:0.5817503558398034\n",
            "Epoch:891, w1:1.0282761909212856, w2:0.8243585791243648, bias:-0.9655102087420386, loss:0.5817196668042258\n",
            "Epoch:892, w1:1.0285485095293225, w2:0.8245934414881931, bias:-0.9659312155792779, loss:0.5816889964131051\n",
            "Epoch:893, w1:1.028820944912633, w2:0.8248284359250374, bias:-0.966351853016443, loss:0.5816583445970974\n",
            "Epoch:894, w1:1.02909349660235, w2:0.8250635615246578, bias:-0.9667721222825674, loss:0.5816277112873715\n",
            "Epoch:895, w1:1.0293661641314977, w2:0.8252988173806622, bias:-0.9671920246017599, loss:0.581597096415604\n",
            "Epoch:896, w1:1.0296389470349847, w2:0.8255342025904913, bias:-0.9676115611932252, loss:0.5815664999139757\n",
            "Epoch:897, w1:1.0299118448495954, w2:0.8257697162554022, bias:-0.9680307332712837, loss:0.5815359217151681\n",
            "Epoch:898, w1:1.0301848571139833, w2:0.8260053574804539, bias:-0.968449542045391, loss:0.5815053617523582\n",
            "Epoch:899, w1:1.0304579833686627, w2:0.8262411253744915, bias:-0.9688679887201577, loss:0.5814748199592152\n",
            "Epoch:900, w1:1.0307312231560015, w2:0.8264770190501308, bias:-0.9692860744953691, loss:0.5814442962698968\n",
            "Epoch:901, w1:1.0310045760202142, w2:0.8267130376237437, bias:-0.9697038005660048, loss:0.581413790619044\n",
            "Epoch:902, w1:1.0312780415073537, w2:0.8269491802154424, bias:-0.9701211681222581, loss:0.581383302941779\n",
            "Epoch:903, w1:1.0315516191653042, w2:0.8271854459490645, bias:-0.9705381783495554, loss:0.5813528331736996\n",
            "Epoch:904, w1:1.0318253085437739, w2:0.8274218339521582, bias:-0.9709548324285753, loss:0.5813223812508768\n",
            "Epoch:905, w1:1.0320991091942873, w2:0.8276583433559671, bias:-0.9713711315352683, loss:0.5812919471098499\n",
            "Epoch:906, w1:1.0323730206701784, w2:0.8278949732954153, bias:-0.9717870768408757, loss:0.5812615306876232\n",
            "Epoch:907, w1:1.032647042526583, w2:0.8281317229090925, bias:-0.9722026695119487, loss:0.5812311319216624\n",
            "Epoch:908, w1:1.0329211743204312, w2:0.8283685913392395, bias:-0.9726179107103673, loss:0.5812007507498905\n",
            "Epoch:909, w1:1.0331954156104406, w2:0.8286055777317328, bias:-0.9730328015933596, loss:0.5811703871106847\n",
            "Epoch:910, w1:1.0334697659571088, w2:0.8288426812360709, bias:-0.9734473433135201, loss:0.5811400409428714\n",
            "Epoch:911, w1:1.0337442249227067, w2:0.8290799010053586, bias:-0.9738615370188292, loss:0.5811097121857244\n",
            "Epoch:912, w1:1.0340187920712705, w2:0.8293172361962932, bias:-0.9742753838526711, loss:0.5810794007789603\n",
            "Epoch:913, w1:1.0342934669685953, w2:0.8295546859691495, bias:-0.9746888849538533, loss:0.5810491066627346\n",
            "Epoch:914, w1:1.0345682491822277, w2:0.8297922494877659, bias:-0.9751020414566245, loss:0.5810188297776389\n",
            "Epoch:915, w1:1.0348431382814582, w2:0.8300299259195293, bias:-0.9755148544906933, loss:0.580988570064697\n",
            "Epoch:916, w1:1.0351181338373154, w2:0.8302677144353612, bias:-0.9759273251812468, loss:0.5809583274653618\n",
            "Epoch:917, w1:1.035393235422558, w2:0.8305056142097034, bias:-0.9763394546489685, loss:0.580928101921511\n",
            "Epoch:918, w1:1.0356684426116676, w2:0.8307436244205036, bias:-0.9767512440100573, loss:0.5808978933754448\n",
            "Epoch:919, w1:1.0359437549808426, w2:0.8309817442492015, bias:-0.9771626943762448, loss:0.5808677017698813\n",
            "Epoch:920, w1:1.0362191721079907, w2:0.8312199728807139, bias:-0.9775738068548142, loss:0.5808375270479543\n",
            "Epoch:921, w1:1.0364946935727224, w2:0.8314583095034219, bias:-0.9779845825486179, loss:0.5808073691532091\n",
            "Epoch:922, w1:1.036770318956343, w2:0.8316967533091558, bias:-0.9783950225560955, loss:0.5807772280295995\n",
            "Epoch:923, w1:1.0370460478418475, w2:0.8319353034931817, bias:-0.978805127971292, loss:0.5807471036214845\n",
            "Epoch:924, w1:1.0373218798139123, w2:0.8321739592541872, bias:-0.9792148998838757, loss:0.5807169958736251\n",
            "Epoch:925, w1:1.0375978144588889, w2:0.8324127197942681, bias:-0.979624339379155, loss:0.5806869047311813\n",
            "Epoch:926, w1:1.0378738513647972, w2:0.832651584318914, bias:-0.9800334475380977, loss:0.5806568301397077\n",
            "Epoch:927, w1:1.0381499901213187, w2:0.8328905520369949, bias:-0.9804422254373472, loss:0.5806267720451521\n",
            "Epoch:928, w1:1.0384262303197898, w2:0.8331296221607476, bias:-0.9808506741492407, loss:0.580596730393851\n",
            "Epoch:929, w1:1.0387025715531948, w2:0.8333687939057618, bias:-0.9812587947418266, loss:0.5805667051325268\n",
            "Epoch:930, w1:1.0389790134161598, w2:0.8336080664909667, bias:-0.9816665882788822, loss:0.5805366962082852\n",
            "Epoch:931, w1:1.0392555555049456, w2:0.8338474391386175, bias:-0.9820740558199303, loss:0.5805067035686112\n",
            "Epoch:932, w1:1.0395321974174414, w2:0.8340869110742815, bias:-0.9824811984202573, loss:0.5804767271613673\n",
            "Epoch:933, w1:1.0398089387531575, w2:0.8343264815268253, bias:-0.9828880171309298, loss:0.5804467669347887\n",
            "Epoch:934, w1:1.0400857791132194, w2:0.8345661497284014, bias:-0.9832945129988121, loss:0.5804168228374821\n",
            "Epoch:935, w1:1.0403627181003614, w2:0.834805914914434, bias:-0.9837006870665833, loss:0.5803868948184218\n",
            "Epoch:936, w1:1.0406397553189195, w2:0.835045776323607, bias:-0.9841065403727539, loss:0.5803569828269465\n",
            "Epoch:937, w1:1.0409168903748254, w2:0.8352857331978497, bias:-0.984512073951683, loss:0.580327086812757\n",
            "Epoch:938, w1:1.0411941228755996, w2:0.8355257847823245, bias:-0.9849172888335955, loss:0.5802972067259131\n",
            "Epoch:939, w1:1.0414714524303454, w2:0.8357659303254131, bias:-0.9853221860445982, loss:0.5802673425168304\n",
            "Epoch:940, w1:1.041748878649742, w2:0.8360061690787038, bias:-0.9857267666066969, loss:0.5802374941362779\n",
            "Epoch:941, w1:1.0420264011460385, w2:0.8362465002969787, bias:-0.9861310315378132, loss:0.5802076615353748\n",
            "Epoch:942, w1:1.0423040195330477, w2:0.8364869232382001, bias:-0.9865349818518011, loss:0.5801778446655877\n",
            "Epoch:943, w1:1.0425817334261391, w2:0.8367274371634982, bias:-0.986938618558463, loss:0.5801480434787283\n",
            "Epoch:944, w1:1.0428595424422331, w2:0.8369680413371581, bias:-0.9873419426635668, loss:0.5801182579269494\n",
            "Epoch:945, w1:1.0431374461997944, w2:0.8372087350266068, bias:-0.9877449551688621, loss:0.5800884879627441\n",
            "Epoch:946, w1:1.0434154443188264, w2:0.8374495175024005, bias:-0.9881476570720963, loss:0.580058733538941\n",
            "Epoch:947, w1:1.043693536420864, w2:0.8376903880382123, bias:-0.9885500493670313, loss:0.580028994608703\n",
            "Epoch:948, w1:1.0439717221289677, w2:0.837931345910819, bias:-0.9889521330434592, loss:0.5799992711255241\n",
            "Epoch:949, w1:1.0442500010677185, w2:0.8381723904000887, bias:-0.9893539090872188, loss:0.5799695630432263\n",
            "Epoch:950, w1:1.0445283728632098, w2:0.8384135207889686, bias:-0.9897553784802116, loss:0.5799398703159576\n",
            "Epoch:951, w1:1.0448068371430428, w2:0.8386547363634718, bias:-0.9901565422004177, loss:0.579910192898189\n",
            "Epoch:952, w1:1.0450853935363198, w2:0.8388960364126654, bias:-0.9905574012219122, loss:0.5798805307447128\n",
            "Epoch:953, w1:1.0453640416736383, w2:0.839137420228658, bias:-0.9909579565148801, loss:0.5798508838106379\n",
            "Epoch:954, w1:1.0456427811870843, w2:0.8393788871065873, bias:-0.9913582090456331, loss:0.5798212520513898\n",
            "Epoch:955, w1:1.0459216117102275, w2:0.8396204363446076, bias:-0.991758159776625, loss:0.5797916354227064\n",
            "Epoch:956, w1:1.0462005328781137, w2:0.8398620672438778, bias:-0.9921578096664672, loss:0.5797620338806359\n",
            "Epoch:957, w1:1.0464795443272603, w2:0.8401037791085493, bias:-0.9925571596699446, loss:0.5797324473815343\n",
            "Epoch:958, w1:1.0467586456956495, w2:0.8403455712457534, bias:-0.9929562107380312, loss:0.5797028758820636\n",
            "Epoch:959, w1:1.0470378366227224, w2:0.8405874429655895, bias:-0.9933549638179052, loss:0.5796733193391882\n",
            "Epoch:960, w1:1.0473171167493736, w2:0.8408293935811132, bias:-0.993753419852965, loss:0.5796437777101734\n",
            "Epoch:961, w1:1.0475964857179443, w2:0.8410714224083238, bias:-0.994151579782844, loss:0.5796142509525816\n",
            "Epoch:962, w1:1.0478759431722175, w2:0.8413135287661526, bias:-0.9945494445434263, loss:0.5795847390242722\n",
            "Epoch:963, w1:1.0481554887574116, w2:0.8415557119764513, bias:-0.994947015066862, loss:0.5795552418833977\n",
            "Epoch:964, w1:1.0484351221201746, w2:0.8417979713639795, bias:-0.9953442922815822, loss:0.5795257594884006\n",
            "Epoch:965, w1:1.0487148429085784, w2:0.8420403062563933, bias:-0.995741277112314, loss:0.5794962917980128\n",
            "Epoch:966, w1:1.0489946507721128, w2:0.8422827159842333, bias:-0.996137970480096, loss:0.5794668387712529\n",
            "Epoch:967, w1:1.0492745453616803, w2:0.8425251998809133, bias:-0.996534373302293, loss:0.5794374003674225\n",
            "Epoch:968, w1:1.0495545263295898, w2:0.8427677572827079, bias:-0.996930486492611, loss:0.579407976546106\n",
            "Epoch:969, w1:1.0498345933295508, w2:0.8430103875287415, bias:-0.9973263109611121, loss:0.5793785672671664\n",
            "Epoch:970, w1:1.0501147460166682, w2:0.8432530899609761, bias:-0.9977218476142294, loss:0.5793491724907445\n",
            "Epoch:971, w1:1.0503949840474365, w2:0.8434958639242007, bias:-0.9981170973547817, loss:0.5793197921772557\n",
            "Epoch:972, w1:1.0506753070797339, w2:0.8437387087660188, bias:-0.9985120610819882, loss:0.5792904262873886\n",
            "Epoch:973, w1:1.050955714772817, w2:0.8439816238368373, bias:-0.9989067396914832, loss:0.5792610747821022\n",
            "Epoch:974, w1:1.0512362067873149, w2:0.8442246084898554, bias:-0.9993011340753307, loss:0.5792317376226243\n",
            "Epoch:975, w1:1.0515167827852236, w2:0.8444676620810527, bias:-0.9996952451220389, loss:0.5792024147704483\n",
            "Epoch:976, w1:1.0517974424299013, w2:0.8447107839691784, bias:-1.0000890737165746, loss:0.5791731061873322\n",
            "Epoch:977, w1:1.0520781853860612, w2:0.8449539735157396, bias:-1.000482620740378, loss:0.5791438118352962\n",
            "Epoch:978, w1:1.0523590113197678, w2:0.8451972300849905, bias:-1.0008758870713765, loss:0.5791145316766202\n",
            "Epoch:979, w1:1.0526399198984302, w2:0.8454405530439206, bias:-1.0012688735839992, loss:0.579085265673842\n",
            "Epoch:980, w1:1.052920910790797, w2:0.8456839417622443, bias:-1.0016615811491916, loss:0.579056013789755\n",
            "Epoch:981, w1:1.0532019836669513, w2:0.845927395612389, bias:-1.002054010634429, loss:0.5790267759874067\n",
            "Epoch:982, w1:1.0534831381983039, w2:0.8461709139694851, bias:-1.002446162903731, loss:0.5789975522300963\n",
            "Epoch:983, w1:1.0537643740575897, w2:0.8464144962113537, bias:-1.0028380388176759, loss:0.5789683424813724\n",
            "Epoch:984, w1:1.0540456909188614, w2:0.8466581417184966, bias:-1.0032296392334146, loss:0.5789391467050313\n",
            "Epoch:985, w1:1.0543270884574836, w2:0.8469018498740851, bias:-1.003620965004684, loss:0.5789099648651155\n",
            "Epoch:986, w1:1.0546085663501288, w2:0.8471456200639491, bias:-1.0040120169818212, loss:0.5788807969259103\n",
            "Epoch:987, w1:1.054890124274771, w2:0.8473894516765663, bias:-1.0044027960117778, loss:0.5788516428519438\n",
            "Epoch:988, w1:1.0551717619106806, w2:0.8476333441030512, bias:-1.004793302938133, loss:0.5788225026079834\n",
            "Epoch:989, w1:1.0554534789384198, w2:0.8478772967371447, bias:-1.005183538601108, loss:0.5787933761590346\n",
            "Epoch:990, w1:1.0557352750398363, w2:0.8481213089752032, bias:-1.0055735038375793, loss:0.5787642634703387\n",
            "Epoch:991, w1:1.0560171498980588, w2:0.8483653802161878, bias:-1.0059631994810918, loss:0.5787351645073714\n",
            "Epoch:992, w1:1.056299103197492, w2:0.848609509861654, bias:-1.0063526263618736, loss:0.5787060792358406\n",
            "Epoch:993, w1:1.0565811346238103, w2:0.8488536973157409, bias:-1.0067417853068488, loss:0.5786770076216846\n",
            "Epoch:994, w1:1.0568632438639538, w2:0.8490979419851608, bias:-1.0071306771396507, loss:0.57864794963107\n",
            "Epoch:995, w1:1.0571454306061228, w2:0.8493422432791885, bias:-1.0075193026806355, loss:0.5786189052303906\n",
            "Epoch:996, w1:1.057427694539772, w2:0.8495866006096511, bias:-1.0079076627468961, loss:0.5785898743862646\n",
            "Epoch:997, w1:1.0577100353556066, w2:0.8498310133909174, bias:-1.008295758152275, loss:0.578560857065534\n",
            "Epoch:998, w1:1.0579924527455764, w2:0.8500754810398875, bias:-1.0086835897073767, loss:0.5785318532352611\n",
            "Epoch:999, w1:1.0582749464028707, w2:0.8503200029759829, bias:-1.0090711582195826, loss:0.5785028628627292\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0582749464028707, 0.8503200029759829, -1.0090711582195826)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# w1 = 1.0582\n",
        "# w2 = 0.85032\n",
        "# bias = -1.0090711\n",
        "\n",
        "\n",
        "# w1 ->(array([[0.9510262],\n",
        "# w2 ->        [0.6691849]]),\n",
        "\n",
        "# bias -> array([-0.695106])"
      ],
      "metadata": {
        "id": "9RyDByrEulJ4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}